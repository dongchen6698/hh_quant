{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "import akshare as ak\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.options.display.max_rows=None\n",
    "pd.options.display.max_columns=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_indicator_info(stock_code):\n",
    "    result = ak.stock_a_indicator_lg(symbol=stock_code).rename(columns={\n",
    "        'trade_date': 'datetime'\n",
    "    })\n",
    "    result = result[['datetime', 'pe', 'pe_ttm', 'pb', 'ps', 'ps_ttm', 'total_mv']]\n",
    "    return result\n",
    "\n",
    "def get_stock_individual_info(stock_code):\n",
    "    result = pd.DataFrame([ak.stock_individual_info_em(symbol=stock_code).set_index('item').to_dict()['value']]).rename(columns={\n",
    "                    \"总市值\": \"total_market_cap\",\n",
    "                    \"流通市值\": \"circulating_market_cap\",\n",
    "                    \"行业\": \"industry\",\n",
    "                    \"上市时间\": \"listing_date\",\n",
    "                    \"股票代码\": \"stock_code\",\n",
    "                    \"股票简称\": \"stock_name\",\n",
    "                    \"总股本\": \"total_shares\",\n",
    "                    \"流通股\": \"circulating_shares\",\n",
    "                })\n",
    "    result = result[['stock_code', 'industry', 'total_shares', 'circulating_shares', 'total_market_cap', 'circulating_market_cap']]\n",
    "    return result\n",
    "\n",
    "def get_stock_history_info(stock_code):\n",
    "    result = ak.stock_zh_a_hist(symbol=stock_code, adjust='qfq').rename(\n",
    "            columns={\n",
    "                \"日期\": \"datetime\",\n",
    "                \"开盘\": \"open\",\n",
    "                \"最高\": \"high\",\n",
    "                \"最低\": \"low\",\n",
    "                \"收盘\": \"close\",\n",
    "                \"成交量\": \"volume\",\n",
    "                \"成交额\": \"turnover\",\n",
    "                \"振幅\": \"amplitude\",\n",
    "                \"涨跌幅\": \"change_pct\",\n",
    "                \"涨跌额\": \"change_amount\",\n",
    "                \"换手率\": \"turnover_rate\",\n",
    "            }\n",
    "        )\n",
    "    result['pre_close'] = result['close'].shift(1)\n",
    "    result.insert(0, 'stock_code', stock_code)\n",
    "\n",
    "    # 将昨日收盘价作为基准，计算价格相对昨日收盘价的波动指标\n",
    "    result['open'] = result['open'] / result['pre_close'] - 1\n",
    "    result['high'] = result['high'] / result['pre_close'] - 1\n",
    "    result['low'] = result['low'] / result['pre_close'] - 1\n",
    "    result['close'] = result['close'] / result['pre_close'] - 1\n",
    "    return result\n",
    "\n",
    "def get_stock_selection_label_info(history_df):\n",
    "    max_holding_period = 10\n",
    "    max_take_profit = 0.15\n",
    "    max_stop_loss = -0.05\n",
    "    dataframe = history_df[['datetime', 'close']].sort_values(by=['datetime'])\n",
    "    # 计算5日后的收益率\n",
    "    dataframe[\"close_in_5_days\"] = dataframe[\"close\"].shift(-max_holding_period)\n",
    "    dataframe[\"return_5_days\"] = dataframe[\"close_in_5_days\"] / dataframe[\"close\"] - 1\n",
    "    # 计算5日内的最小值\n",
    "    dataframe['min_5_days'] = dataframe[\"close\"].rolling(max_holding_period).min()\n",
    "    dataframe['neg_return_5_days'] = dataframe['min_5_days'] / dataframe[\"close\"] - 1\n",
    "    # 计算Label\n",
    "    dataframe['label'] = 0\n",
    "    condition_1 = dataframe[\"return_5_days\"] > max_take_profit\n",
    "    condition_2 = dataframe['neg_return_5_days'] > max_stop_loss\n",
    "    dataframe.loc[condition_1 & condition_2, \"label\"] = 1 # 买入\n",
    "    return dataframe[['datetime', 'label']]\n",
    "\n",
    "def get_datetime_info(history_df):\n",
    "    dataframe = pd.DataFrame(history_df['datetime'])\n",
    "    datetime_series = pd.to_datetime(dataframe['datetime'])\n",
    "    dataframe['weekday'] = datetime_series.dt.weekday  # 星期几（0=星期一，6=星期日）\n",
    "    dataframe['day_of_week'] = datetime_series.dt.day_name()  # 星期几的名称\n",
    "    dataframe['day_of_month'] = datetime_series.dt.day  # 一个月中的第几天\n",
    "    dataframe['month'] = datetime_series.dt.month  # 月份\n",
    "    dataframe['season'] = datetime_series.dt.month.map(lambda x: {\n",
    "        1: 'Winter', 2: 'Winter', 3: 'Spring', 4: 'Spring', 5: 'Spring',\n",
    "        6: 'Summer', 7: 'Summer', 8: 'Summer', 9: 'Autumn', 10: 'Autumn',\n",
    "        11: 'Autumn', 12: 'Winter'\n",
    "    }.get(x))\n",
    "    return dataframe\n",
    "\n",
    "def get_factor_info(history_df):\n",
    "    # help(ta.donchian)\n",
    "    base_columns = ['open', 'high', 'low', 'close', 'volume']\n",
    "    dataframe = history_df[base_columns]\n",
    "    dataframe['datetime'] = history_df['datetime']\n",
    "    dataframe.set_index(pd.DatetimeIndex(dataframe[\"datetime\"]), inplace=True)\n",
    "    # Create your own Custom Strategy\n",
    "    CustomStrategy = ta.Strategy(\n",
    "        name=\"CustomStrategy\",\n",
    "        description=\"\",\n",
    "        ta=[\n",
    "            {\"kind\": \"sma\", \"length\": 10},\n",
    "            {\"kind\": \"sma\", \"length\": 20},\n",
    "            {\"kind\": \"ema\", \"length\": 10},\n",
    "            {\"kind\": \"ema\", \"length\": 20},\n",
    "            {\"kind\": \"bbands\", \"length\": 20, \"std\": 2},\n",
    "            {\"kind\": \"rsi\", \"length\": 14},\n",
    "            {\"kind\": \"macd\", \"fast\": 12, \"slow\": 26, \"signal\": 9},\n",
    "            {\"kind\": \"donchian\", \"length\": 20},\n",
    "        ]\n",
    "    )\n",
    "    # To run your \"Custom Strategy\"\n",
    "    dataframe.ta.cores = 0\n",
    "    dataframe.ta.strategy(CustomStrategy)\n",
    "    dataframe = dataframe[[i for i in dataframe.columns if i not in base_columns]]\n",
    "    dataframe = dataframe.reset_index(drop=True)\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame().ta.indicators()\n",
    "# help(ta.donchian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Stock...: 100%|██████████| 50/50 [01:59<00:00,  2.39s/it]\n"
     ]
    }
   ],
   "source": [
    "# 1. 获取中证50（000016）的股票列表, '600011'\n",
    "stock_code_list = ak.index_stock_cons('000016')['品种代码'].to_list()\n",
    "\n",
    "for stock_code in tqdm(stock_code_list, desc='Processing Stock...'):\n",
    "    # 获取基础数据\n",
    "    m1_info = get_stock_individual_info(stock_code)\n",
    "    m2_info = get_stock_history_info(stock_code)\n",
    "    m3_info = get_stock_indicator_info(stock_code)\n",
    "    m4_info = get_stock_selection_label_info(m2_info)\n",
    "    m5_info = get_datetime_info(m2_info)\n",
    "    m6_info = get_factor_info(m2_info)\n",
    "\n",
    "    # 整合处理数据\n",
    "    wide_info = m1_info.merge(m2_info, on=['stock_code']).merge(m3_info, on=['datetime']).merge(m4_info, on=['datetime']).merge(m5_info, on=['datetime']).merge(m6_info, on=['datetime'])\n",
    "    wide_info['datetime'] = pd.to_datetime(wide_info['datetime'])\n",
    "    wide_info.dropna(inplace=True)\n",
    "\n",
    "    # 保存数据\n",
    "    wide_info.to_pickle(f'./wide_data/{stock_code}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Stock...: 100%|██████████| 50/50 [00:00<00:00, 282.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# 1. 获取中证50（000016）的股票列表, '600011'\n",
    "stock_code_list = ak.index_stock_cons('000016')['品种代码'].to_list()\n",
    "\n",
    "stock_wide_list = []\n",
    "for stock_code in tqdm(stock_code_list, desc='Loading Stock...'):\n",
    "    stock_wide_list.append(pd.read_pickle(f'./wide_data/{stock_code}.pkl'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(stock_wide_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.0\n"
     ]
    }
   ],
   "source": [
    "# 使用tensorflow处理原始数据\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 选择固定时间区间的数据\n",
    "train_start_date = pd.to_datetime('2000-01-01')\n",
    "train_end_date = pd.to_datetime('2020-12-31')\n",
    "val_start_date = pd.to_datetime('2021-01-01')\n",
    "val_end_date = pd.to_datetime('2021-12-31')\n",
    "test_start_date = pd.to_datetime('2022-01-01')\n",
    "test_end_date = pd.to_datetime('2022-12-31')\n",
    "\n",
    "train_data = df[(df['datetime'] >= train_start_date) & (df['datetime'] <= train_end_date)]\n",
    "validation_data = df[(df['datetime'] >= val_start_date) & (df['datetime'] <= val_end_date)]\n",
    "test_data = df[(df['datetime'] >= test_start_date) & (df['datetime'] <= test_end_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "Total: 93749, Normal: 84546, Positive: 9203 \n",
      "\n",
      "Validation:\n",
      "Total: 7207, Normal: 6467,Positive: 740 \n",
      "\n",
      "Test:\n",
      "Total: 7563, Normal: 6689,Positive: 874 \n",
      "\n",
      "Weight for class 0: 0.55\n",
      "Weight for class 1: 5.09\n"
     ]
    }
   ],
   "source": [
    "label_column = 'label'\n",
    "\n",
    "train_0, train_1 = np.bincount(train_data[label_column])\n",
    "train_total = train_0 + train_1\n",
    "print('Train:\\nTotal: {}, Normal: {}, Positive: {} \\n'.format(train_total, train_0, train_1))\n",
    "val_0, val_1 = np.bincount(validation_data[label_column])\n",
    "val_total = val_0 + val_1\n",
    "print('Validation:\\nTotal: {}, Normal: {},Positive: {} \\n'.format(val_total, val_0, val_1))\n",
    "test_0, test_1 = np.bincount(test_data[label_column])\n",
    "test_total = test_0 + test_1\n",
    "print('Test:\\nTotal: {}, Normal: {},Positive: {} \\n'.format(test_total, test_0, test_1))\n",
    "\n",
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "# The sum of the weights of all examples stays the same.\n",
    "weight_for_0 = (1 / train_0) * (train_total / 2.0)\n",
    "weight_for_1 = (1 / train_1) * (train_total / 2.0)\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numeric_boundaries(series, num_bins=40):\n",
    "    return pd.qcut(series, num_bins, retbins=True, duplicates='drop')[1].tolist()\n",
    "\n",
    "TARGET_FEATURE_NAME = \"label\"\n",
    "\n",
    "# 连续特征分桶\n",
    "NUMERIC_FEATURES = {\n",
    "    'total_shares': get_numeric_boundaries(train_data['total_shares']),\n",
    "    'circulating_shares': get_numeric_boundaries(train_data['circulating_shares']),\n",
    "    'total_market_cap': get_numeric_boundaries(train_data['total_market_cap']),\n",
    "    'circulating_market_cap': get_numeric_boundaries(train_data['circulating_market_cap']),\n",
    "    'open': get_numeric_boundaries(train_data['open']),\n",
    "    'close': get_numeric_boundaries(train_data['close']),\n",
    "    'high': get_numeric_boundaries(train_data['high']),\n",
    "    'low': get_numeric_boundaries(train_data['low']),\n",
    "    'volume': get_numeric_boundaries(train_data['volume']),\n",
    "    'turnover': get_numeric_boundaries(train_data['turnover']),\n",
    "    'amplitude': get_numeric_boundaries(train_data['amplitude']),\n",
    "    'change_pct': get_numeric_boundaries(train_data['change_pct']),\n",
    "    'change_amount': get_numeric_boundaries(train_data['change_amount']),\n",
    "    'turnover_rate': get_numeric_boundaries(train_data['turnover_rate']),\n",
    "    'pe': get_numeric_boundaries(train_data['pe']),\n",
    "    'pe_ttm': get_numeric_boundaries(train_data['pe_ttm']),\n",
    "    'pb': get_numeric_boundaries(train_data['pb']),\n",
    "    'ps': get_numeric_boundaries(train_data['ps']),\n",
    "    'ps_ttm': get_numeric_boundaries(train_data['ps_ttm']),\n",
    "    'total_mv': get_numeric_boundaries(train_data['total_mv']),\n",
    "    'SMA_10': get_numeric_boundaries(train_data['SMA_10']),\n",
    "    'SMA_20': get_numeric_boundaries(train_data['SMA_20']),\n",
    "    'EMA_10': get_numeric_boundaries(train_data['EMA_10']),\n",
    "    'EMA_20': get_numeric_boundaries(train_data['EMA_20']),\n",
    "    'BBL_20_2.0': get_numeric_boundaries(train_data['BBL_20_2.0']),\n",
    "    'BBM_20_2.0': get_numeric_boundaries(train_data['BBM_20_2.0']),\n",
    "    'BBU_20_2.0': get_numeric_boundaries(train_data['BBU_20_2.0']),\n",
    "    'BBB_20_2.0': get_numeric_boundaries(train_data['BBB_20_2.0']),\n",
    "    'BBP_20_2.0': get_numeric_boundaries(train_data['BBP_20_2.0']),\n",
    "    'RSI_14': get_numeric_boundaries(train_data['RSI_14']),\n",
    "    'MACD_12_26_9': get_numeric_boundaries(train_data['MACD_12_26_9']),\n",
    "    'MACDh_12_26_9': get_numeric_boundaries(train_data['MACDh_12_26_9']),\n",
    "    'MACDs_12_26_9': get_numeric_boundaries(train_data['MACDs_12_26_9']),\n",
    "    'DCL_20_20': get_numeric_boundaries(train_data['DCL_20_20']),\n",
    "    'DCM_20_20': get_numeric_boundaries(train_data['DCM_20_20']),\n",
    "    'DCU_20_20': get_numeric_boundaries(train_data['DCU_20_20']),\n",
    "}\n",
    "\n",
    "# 离散特征embedding\n",
    "INTEGER_CATEGORICAL_FEATURES = {\n",
    "    'weekday': train_data['weekday'].unique().tolist(),\n",
    "    'day_of_month': train_data['day_of_month'].unique().tolist(),\n",
    "    'month': train_data['month'].unique().tolist(),\n",
    "}\n",
    "STRING_CATEGORICAL_FEATURES = {\n",
    "    'industry': train_data['industry'].unique().tolist(),\n",
    "    'day_of_week': train_data['day_of_week'].unique().tolist(),\n",
    "    'season': train_data['season'].unique().tolist(),\n",
    "}\n",
    "\n",
    "\n",
    "FEATURE_NAMES = list(NUMERIC_FEATURES.keys()) + list(INTEGER_CATEGORICAL_FEATURES.keys()) + list(STRING_CATEGORICAL_FEATURES.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "def df_to_dataset(dataframe, shuffle=True):\n",
    "  # dataframe = dataframe.drop('datetime', axis=1)\n",
    "  labels = dataframe[TARGET_FEATURE_NAME]\n",
    "  dataframe = dataframe[FEATURE_NAMES]\n",
    "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "  ds = ds.batch(BATCH_SIZE)\n",
    "  return ds\n",
    "\n",
    "train_ds = df_to_dataset(train_data, shuffle=True)\n",
    "val_ds = df_to_dataset(validation_data, shuffle=False)\n",
    "test_ds = df_to_dataset(test_data, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_inputs():\n",
    "    inputs = {}\n",
    "    for feature_name in FEATURE_NAMES:\n",
    "        if feature_name in NUMERIC_FEATURES:\n",
    "            inputs[feature_name] = tf.keras.layers.Input(\n",
    "                name=feature_name, shape=(), dtype=\"float32\"\n",
    "            )\n",
    "        elif feature_name in INTEGER_CATEGORICAL_FEATURES:\n",
    "            inputs[feature_name] = tf.keras.layers.Input(\n",
    "                name=feature_name, shape=(), dtype=\"int32\"\n",
    "            )\n",
    "        else:\n",
    "            inputs[feature_name] = tf.keras.layers.Input(\n",
    "                name=feature_name, shape=(), dtype=\"string\"\n",
    "            )\n",
    "    return inputs\n",
    "\n",
    "def encode_inputs(inputs):\n",
    "    encoded_features = []\n",
    "    embedding_dim = 6\n",
    "    is_embedding = True\n",
    "\n",
    "    # 处理连续特征\n",
    "    for feature_name, boundaries in NUMERIC_FEATURES.items():\n",
    "        if is_embedding:\n",
    "            lookup_layer = tf.keras.layers.Discretization(bin_boundaries=boundaries,output_mode='int')\n",
    "            embedding = tf.keras.layers.Embedding(\n",
    "                input_dim=len(boundaries) * 2, output_dim=embedding_dim\n",
    "            )\n",
    "            encoded_feature = embedding(lookup_layer(inputs[feature_name]))\n",
    "        else:\n",
    "            lookup_layer = tf.keras.layers.Discretization(bin_boundaries=boundaries,output_mode='one_hot')\n",
    "            encoded_feature = lookup_layer(inputs[feature_name])\n",
    "        encoded_features.append(encoded_feature)\n",
    "\n",
    "    # 处理INTEGER离散特征\n",
    "    for feature_name, integer_vocab in INTEGER_CATEGORICAL_FEATURES.items():\n",
    "        lookup_layer = tf.keras.layers.IntegerLookup(vocabulary=integer_vocab)\n",
    "        embedding = tf.keras.layers.Embedding(\n",
    "            input_dim=len(integer_vocab) * 2, output_dim=embedding_dim\n",
    "        )\n",
    "        encoded_feature = embedding(lookup_layer(inputs[feature_name]))\n",
    "        encoded_features.append(encoded_feature)\n",
    "    \n",
    "    # 处理STRING离散特征\n",
    "    for feature_name, string_vocab in STRING_CATEGORICAL_FEATURES.items():\n",
    "        lookup_layer = tf.keras.layers.StringLookup(vocabulary=string_vocab)\n",
    "        embedding = tf.keras.layers.Embedding(\n",
    "            input_dim=len(string_vocab) * 2, output_dim=embedding_dim\n",
    "        )\n",
    "        encoded_feature = embedding(lookup_layer(inputs[feature_name]))\n",
    "        encoded_features.append(encoded_feature)\n",
    "    \n",
    "    print(f\"Total Features Size:: {len(encoded_features)}\")\n",
    "    all_features = tf.keras.layers.concatenate(encoded_features)\n",
    "    return all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-3\n",
    "NUM_EPOCH = 20\n",
    "\n",
    "def run_experiment(model, train_ds, val_ds, test_ds):\n",
    "    # optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=LEARNING_RATE) # for mac M1/M2\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE) # for mac M1/M2\n",
    "    \n",
    "    loss = tf.keras.losses.BinaryCrossentropy()\n",
    "    metrics = [\n",
    "        tf.keras.metrics.TruePositives(name='tp'),\n",
    "        tf.keras.metrics.FalsePositives(name='fp'),\n",
    "        tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "        tf.keras.metrics.FalseNegatives(name='fn'), \n",
    "        tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall'),\n",
    "        tf.keras.metrics.AUC(name='auc'),\n",
    "    ]\n",
    "        \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=metrics,\n",
    "    )\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='auc',\n",
    "        verbose=1,\n",
    "        patience=10,\n",
    "        mode='max',\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "    print(\"Start training the model...\")\n",
    "    history = model.fit(\n",
    "        train_ds, \n",
    "        epochs=NUM_EPOCH,\n",
    "        validation_data=val_ds, \n",
    "        verbose=2,\n",
    "        callbacks=[early_stopping],\n",
    "        class_weight=class_weight\n",
    "    )\n",
    "    print(\"Model training finished\")\n",
    "\n",
    "    # loss, auc = model.evaluate(test_ds, verbose=0)\n",
    "    # print(f\"Test AUC::{round(auc * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_rate = 0.2\n",
    "hidden_units = [128, 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Features Size:: 42\n",
      "Start training the model...\n",
      "Epoch 1/20\n",
      "733/733 - 13s - loss: 0.4361 - tp: 8444.0000 - fp: 28259.0000 - tn: 56287.0000 - fn: 759.0000 - accuracy: 0.6905 - precision: 0.2301 - recall: 0.9175 - auc: 0.8528 - val_loss: 0.4368 - val_tp: 697.0000 - val_fp: 2037.0000 - val_tn: 4430.0000 - val_fn: 43.0000 - val_accuracy: 0.7114 - val_precision: 0.2549 - val_recall: 0.9419 - val_auc: 0.8841 - 13s/epoch - 18ms/step\n",
      "Epoch 2/20\n",
      "733/733 - 6s - loss: 0.3819 - tp: 8657.0000 - fp: 25014.0000 - tn: 59532.0000 - fn: 546.0000 - accuracy: 0.7274 - precision: 0.2571 - recall: 0.9407 - auc: 0.8808 - val_loss: 0.4182 - val_tp: 683.0000 - val_fp: 1855.0000 - val_tn: 4612.0000 - val_fn: 57.0000 - val_accuracy: 0.7347 - val_precision: 0.2691 - val_recall: 0.9230 - val_auc: 0.8854 - 6s/epoch - 8ms/step\n",
      "Epoch 3/20\n",
      "733/733 - 6s - loss: 0.3727 - tp: 8671.0000 - fp: 24348.0000 - tn: 60198.0000 - fn: 532.0000 - accuracy: 0.7346 - precision: 0.2626 - recall: 0.9422 - auc: 0.8870 - val_loss: 0.4153 - val_tp: 684.0000 - val_fp: 1913.0000 - val_tn: 4554.0000 - val_fn: 56.0000 - val_accuracy: 0.7268 - val_precision: 0.2634 - val_recall: 0.9243 - val_auc: 0.8825 - 6s/epoch - 8ms/step\n",
      "Epoch 4/20\n",
      "733/733 - 6s - loss: 0.3657 - tp: 8715.0000 - fp: 23854.0000 - tn: 60692.0000 - fn: 488.0000 - accuracy: 0.7403 - precision: 0.2676 - recall: 0.9470 - auc: 0.8910 - val_loss: 0.4345 - val_tp: 675.0000 - val_fp: 1818.0000 - val_tn: 4649.0000 - val_fn: 65.0000 - val_accuracy: 0.7387 - val_precision: 0.2708 - val_recall: 0.9122 - val_auc: 0.8821 - 6s/epoch - 8ms/step\n",
      "Epoch 5/20\n",
      "733/733 - 6s - loss: 0.3574 - tp: 8737.0000 - fp: 23189.0000 - tn: 61357.0000 - fn: 466.0000 - accuracy: 0.7477 - precision: 0.2737 - recall: 0.9494 - auc: 0.8965 - val_loss: 0.4195 - val_tp: 679.0000 - val_fp: 1798.0000 - val_tn: 4669.0000 - val_fn: 61.0000 - val_accuracy: 0.7421 - val_precision: 0.2741 - val_recall: 0.9176 - val_auc: 0.8799 - 6s/epoch - 8ms/step\n",
      "Epoch 6/20\n",
      "733/733 - 6s - loss: 0.3465 - tp: 8757.0000 - fp: 22275.0000 - tn: 62271.0000 - fn: 446.0000 - accuracy: 0.7576 - precision: 0.2822 - recall: 0.9515 - auc: 0.9035 - val_loss: 0.4076 - val_tp: 661.0000 - val_fp: 1710.0000 - val_tn: 4757.0000 - val_fn: 79.0000 - val_accuracy: 0.7518 - val_precision: 0.2788 - val_recall: 0.8932 - val_auc: 0.8767 - 6s/epoch - 8ms/step\n",
      "Epoch 7/20\n",
      "733/733 - 7s - loss: 0.3376 - tp: 8727.0000 - fp: 21346.0000 - tn: 63200.0000 - fn: 476.0000 - accuracy: 0.7672 - precision: 0.2902 - recall: 0.9483 - auc: 0.9092 - val_loss: 0.4182 - val_tp: 658.0000 - val_fp: 1705.0000 - val_tn: 4762.0000 - val_fn: 82.0000 - val_accuracy: 0.7520 - val_precision: 0.2785 - val_recall: 0.8892 - val_auc: 0.8758 - 7s/epoch - 9ms/step\n",
      "Epoch 8/20\n",
      "733/733 - 6s - loss: 0.3239 - tp: 8775.0000 - fp: 20230.0000 - tn: 64316.0000 - fn: 428.0000 - accuracy: 0.7796 - precision: 0.3025 - recall: 0.9535 - auc: 0.9173 - val_loss: 0.4125 - val_tp: 641.0000 - val_fp: 1626.0000 - val_tn: 4841.0000 - val_fn: 99.0000 - val_accuracy: 0.7606 - val_precision: 0.2828 - val_recall: 0.8662 - val_auc: 0.8711 - 6s/epoch - 9ms/step\n",
      "Epoch 9/20\n",
      "733/733 - 6s - loss: 0.3111 - tp: 8739.0000 - fp: 18855.0000 - tn: 65691.0000 - fn: 464.0000 - accuracy: 0.7939 - precision: 0.3167 - recall: 0.9496 - auc: 0.9242 - val_loss: 0.4063 - val_tp: 626.0000 - val_fp: 1540.0000 - val_tn: 4927.0000 - val_fn: 114.0000 - val_accuracy: 0.7705 - val_precision: 0.2890 - val_recall: 0.8459 - val_auc: 0.8687 - 6s/epoch - 9ms/step\n",
      "Epoch 10/20\n",
      "733/733 - 6s - loss: 0.3003 - tp: 8755.0000 - fp: 17877.0000 - tn: 66669.0000 - fn: 448.0000 - accuracy: 0.8045 - precision: 0.3287 - recall: 0.9513 - auc: 0.9296 - val_loss: 0.4165 - val_tp: 623.0000 - val_fp: 1481.0000 - val_tn: 4986.0000 - val_fn: 117.0000 - val_accuracy: 0.7783 - val_precision: 0.2961 - val_recall: 0.8419 - val_auc: 0.8657 - 6s/epoch - 9ms/step\n",
      "Epoch 11/20\n",
      "733/733 - 6s - loss: 0.2870 - tp: 8770.0000 - fp: 16711.0000 - tn: 67835.0000 - fn: 433.0000 - accuracy: 0.8171 - precision: 0.3442 - recall: 0.9530 - auc: 0.9365 - val_loss: 0.4300 - val_tp: 608.0000 - val_fp: 1479.0000 - val_tn: 4988.0000 - val_fn: 132.0000 - val_accuracy: 0.7765 - val_precision: 0.2913 - val_recall: 0.8216 - val_auc: 0.8597 - 6s/epoch - 9ms/step\n",
      "Epoch 12/20\n",
      "733/733 - 6s - loss: 0.2773 - tp: 8761.0000 - fp: 15903.0000 - tn: 68643.0000 - fn: 442.0000 - accuracy: 0.8257 - precision: 0.3552 - recall: 0.9520 - auc: 0.9405 - val_loss: 0.4252 - val_tp: 587.0000 - val_fp: 1398.0000 - val_tn: 5069.0000 - val_fn: 153.0000 - val_accuracy: 0.7848 - val_precision: 0.2957 - val_recall: 0.7932 - val_auc: 0.8560 - 6s/epoch - 9ms/step\n",
      "Epoch 13/20\n",
      "733/733 - 6s - loss: 0.2676 - tp: 8793.0000 - fp: 15102.0000 - tn: 69444.0000 - fn: 410.0000 - accuracy: 0.8345 - precision: 0.3680 - recall: 0.9554 - auc: 0.9447 - val_loss: 0.4267 - val_tp: 586.0000 - val_fp: 1374.0000 - val_tn: 5093.0000 - val_fn: 154.0000 - val_accuracy: 0.7880 - val_precision: 0.2990 - val_recall: 0.7919 - val_auc: 0.8547 - 6s/epoch - 9ms/step\n",
      "Epoch 14/20\n",
      "733/733 - 6s - loss: 0.2614 - tp: 8807.0000 - fp: 14485.0000 - tn: 70061.0000 - fn: 396.0000 - accuracy: 0.8413 - precision: 0.3781 - recall: 0.9570 - auc: 0.9476 - val_loss: 0.4241 - val_tp: 563.0000 - val_fp: 1298.0000 - val_tn: 5169.0000 - val_fn: 177.0000 - val_accuracy: 0.7953 - val_precision: 0.3025 - val_recall: 0.7608 - val_auc: 0.8519 - 6s/epoch - 9ms/step\n",
      "Epoch 15/20\n",
      "733/733 - 7s - loss: 0.2493 - tp: 8790.0000 - fp: 13668.0000 - tn: 70878.0000 - fn: 413.0000 - accuracy: 0.8498 - precision: 0.3914 - recall: 0.9551 - auc: 0.9525 - val_loss: 0.4232 - val_tp: 541.0000 - val_fp: 1229.0000 - val_tn: 5238.0000 - val_fn: 199.0000 - val_accuracy: 0.8019 - val_precision: 0.3056 - val_recall: 0.7311 - val_auc: 0.8529 - 7s/epoch - 9ms/step\n",
      "Epoch 16/20\n",
      "733/733 - 6s - loss: 0.2415 - tp: 8798.0000 - fp: 13056.0000 - tn: 71490.0000 - fn: 405.0000 - accuracy: 0.8564 - precision: 0.4026 - recall: 0.9560 - auc: 0.9549 - val_loss: 0.4608 - val_tp: 562.0000 - val_fp: 1300.0000 - val_tn: 5167.0000 - val_fn: 178.0000 - val_accuracy: 0.7949 - val_precision: 0.3018 - val_recall: 0.7595 - val_auc: 0.8488 - 6s/epoch - 9ms/step\n",
      "Epoch 17/20\n",
      "733/733 - 6s - loss: 0.2348 - tp: 8843.0000 - fp: 12676.0000 - tn: 71870.0000 - fn: 360.0000 - accuracy: 0.8609 - precision: 0.4109 - recall: 0.9609 - auc: 0.9578 - val_loss: 0.4471 - val_tp: 529.0000 - val_fp: 1197.0000 - val_tn: 5270.0000 - val_fn: 211.0000 - val_accuracy: 0.8046 - val_precision: 0.3065 - val_recall: 0.7149 - val_auc: 0.8453 - 6s/epoch - 9ms/step\n",
      "Epoch 18/20\n",
      "733/733 - 7s - loss: 0.2279 - tp: 8824.0000 - fp: 12077.0000 - tn: 72469.0000 - fn: 379.0000 - accuracy: 0.8671 - precision: 0.4222 - recall: 0.9588 - auc: 0.9602 - val_loss: 0.4507 - val_tp: 525.0000 - val_fp: 1219.0000 - val_tn: 5248.0000 - val_fn: 215.0000 - val_accuracy: 0.8010 - val_precision: 0.3010 - val_recall: 0.7095 - val_auc: 0.8433 - 7s/epoch - 9ms/step\n",
      "Epoch 19/20\n",
      "733/733 - 7s - loss: 0.2223 - tp: 8849.0000 - fp: 11617.0000 - tn: 72929.0000 - fn: 354.0000 - accuracy: 0.8723 - precision: 0.4324 - recall: 0.9615 - auc: 0.9619 - val_loss: 0.4478 - val_tp: 511.0000 - val_fp: 1174.0000 - val_tn: 5293.0000 - val_fn: 229.0000 - val_accuracy: 0.8053 - val_precision: 0.3033 - val_recall: 0.6905 - val_auc: 0.8457 - 7s/epoch - 9ms/step\n",
      "Epoch 20/20\n",
      "733/733 - 7s - loss: 0.2184 - tp: 8841.0000 - fp: 11301.0000 - tn: 73245.0000 - fn: 362.0000 - accuracy: 0.8756 - precision: 0.4389 - recall: 0.9607 - auc: 0.9633 - val_loss: 0.4652 - val_tp: 509.0000 - val_fp: 1129.0000 - val_tn: 5338.0000 - val_fn: 231.0000 - val_accuracy: 0.8113 - val_precision: 0.3107 - val_recall: 0.6878 - val_auc: 0.8361 - 7s/epoch - 9ms/step\n",
      "Model training finished\n"
     ]
    }
   ],
   "source": [
    "def create_baseline_model():\n",
    "    inputs = create_model_inputs()\n",
    "    features = encode_inputs(inputs)\n",
    "\n",
    "    for units in hidden_units:\n",
    "        features = tf.keras.layers.Dense(units)(features)\n",
    "        features = tf.keras.layers.BatchNormalization()(features)\n",
    "        features = tf.keras.layers.ReLU()(features)\n",
    "        features = tf.keras.layers.Dropout(dropout_rate)(features)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(units=1, activation=\"sigmoid\")(features)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "baseline_model = create_baseline_model()\n",
    "# tf.keras.utils.plot_model(baseline_model, show_shapes=True, rankdir=\"LR\")\n",
    "run_experiment(baseline_model, train_ds, val_ds, test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline_model.save('./stock_selection_base_model')\n",
    "# reloaded_model = tf.keras.models.load_model('./stock_selection_base_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples = df_to_dataset(test_data.iloc[:100, :], shuffle=False, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 1s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "test_labels = []\n",
    "for _, labels in test_ds:\n",
    "    test_labels.extend(labels.numpy())\n",
    "\n",
    "test_predictions = baseline_model.predict(test_ds).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame()\n",
    "test_df['true_label'] = test_labels\n",
    "test_df['prediction'] = test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_label</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6270</th>\n",
       "      <td>0</td>\n",
       "      <td>0.830863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6469</th>\n",
       "      <td>0</td>\n",
       "      <td>0.823276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8235</th>\n",
       "      <td>0</td>\n",
       "      <td>0.822755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0</td>\n",
       "      <td>0.822437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6269</th>\n",
       "      <td>0</td>\n",
       "      <td>0.811164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10423</th>\n",
       "      <td>0</td>\n",
       "      <td>0.807427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8004</th>\n",
       "      <td>0</td>\n",
       "      <td>0.780388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5631</th>\n",
       "      <td>0</td>\n",
       "      <td>0.779011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10715</th>\n",
       "      <td>0</td>\n",
       "      <td>0.748647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8043</th>\n",
       "      <td>0</td>\n",
       "      <td>0.744034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10714</th>\n",
       "      <td>0</td>\n",
       "      <td>0.742632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3286</th>\n",
       "      <td>1</td>\n",
       "      <td>0.737755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6468</th>\n",
       "      <td>0</td>\n",
       "      <td>0.736491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6486</th>\n",
       "      <td>0</td>\n",
       "      <td>0.730334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>0</td>\n",
       "      <td>0.725362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>0</td>\n",
       "      <td>0.722626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8045</th>\n",
       "      <td>0</td>\n",
       "      <td>0.704486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7907</th>\n",
       "      <td>0</td>\n",
       "      <td>0.701240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4884</th>\n",
       "      <td>0</td>\n",
       "      <td>0.700571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7906</th>\n",
       "      <td>0</td>\n",
       "      <td>0.697077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       true_label  prediction\n",
       "6270            0    0.830863\n",
       "6469            0    0.823276\n",
       "8235            0    0.822755\n",
       "123             0    0.822437\n",
       "6269            0    0.811164\n",
       "10423           0    0.807427\n",
       "8004            0    0.780388\n",
       "5631            0    0.779011\n",
       "10715           0    0.748647\n",
       "8043            0    0.744034\n",
       "10714           0    0.742632\n",
       "3286            1    0.737755\n",
       "6468            0    0.736491\n",
       "6486            0    0.730334\n",
       "1054            0    0.725362\n",
       "1149            0    0.722626\n",
       "8045            0    0.704486\n",
       "7907            0    0.701240\n",
       "4884            0    0.700571\n",
       "7906            0    0.697077"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 预测最高的打分，实际label都不是1\n",
    "test_df.sort_values(by='prediction', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.hist(true_positives_scores, bins=50, alpha=0.5, label='True Positives')\n",
    "# plt.hist(false_positives_scores, bins=50, alpha=0.5, label='False Positives')\n",
    "# plt.xlabel('Scores')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legitimate Transactions Detected (True Negatives):  11597\n",
      "Legitimate Transactions Incorrectly Detected (False Positives):  93\n",
      "Fraudulent Transactions Missed (False Negatives):  221\n",
      "Fraudulent Transactions Detected (True Positives):  7\n",
      "Total Fraudulent Transactions:  228\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_cm(labels, predictions, p=0.5):\n",
    "    cm = confusion_matrix(labels, predictions > p)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "    plt.title('Confusion matrix @{:.2f}'.format(p))\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "    print('Legitimate Transactions Detected (True Negatives): ', cm[0][0])\n",
    "    print('Legitimate Transactions Incorrectly Detected (False Positives): ', cm[0][1])\n",
    "    print('Fraudulent Transactions Missed (False Negatives): ', cm[1][0])\n",
    "    print('Fraudulent Transactions Detected (True Positives): ', cm[1][1])\n",
    "    print('Total Fraudulent Transactions: ', np.sum(cm[1]))\n",
    "\n",
    "plot_cm(test_labels, test_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
