{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import akshare as ak\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "\n",
    "from AlphaFactor import calculate_alpha_expression\n",
    "\n",
    "pd.options.display.max_rows=None\n",
    "pd.options.display.max_columns=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    000001\n",
       "1    000002\n",
       "2    000004\n",
       "3    000005\n",
       "4    000006\n",
       "Name: code, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 获取A股所有股票列表\n",
    "stock_code_list = ak.stock_info_a_code_name()['code']\n",
    "stock_code_list[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 获取基础原始数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_indicator_info(stock_code):\n",
    "    result = ak.stock_a_indicator_lg(symbol=stock_code).rename(columns={\n",
    "        'trade_date': 'datetime'\n",
    "    })\n",
    "    result = result[['datetime', 'pe', 'pe_ttm', 'pb', 'ps', 'ps_ttm', 'total_mv']]\n",
    "    return result\n",
    "\n",
    "def get_stock_individual_info(stock_code):\n",
    "    result = pd.DataFrame([ak.stock_individual_info_em(symbol=stock_code).set_index('item').to_dict()['value']]).rename(columns={\n",
    "                    \"总市值\": \"total_market_cap\",\n",
    "                    \"流通市值\": \"circulating_market_cap\",\n",
    "                    \"行业\": \"industry\",\n",
    "                    \"上市时间\": \"listing_date\",\n",
    "                    \"股票代码\": \"stock_code\",\n",
    "                    \"股票简称\": \"stock_name\",\n",
    "                    \"总股本\": \"total_shares\",\n",
    "                    \"流通股\": \"circulating_shares\",\n",
    "                })\n",
    "    result = result[['stock_code', 'industry', 'total_shares', 'circulating_shares', 'total_market_cap', 'circulating_market_cap']]\n",
    "    return result\n",
    "\n",
    "def get_stock_history_info(stock_code):\n",
    "    \"\"\"\n",
    "    前复权（Forward Adjusted）:\n",
    "    前复权数据将历史价格向前调整，使得最近的价格不变，而历史价格按照股票的分红、送股和转增等因素进行了调整。这种方式使得历史价格反映了如果投资者持有股票至今所应该得到的收益。前复权数据通常用于图表分析，使得价格连续性更好，并且更适用于基于趋势分析的投资策略。\n",
    "\n",
    "    后复权（Backward Adjusted）:\n",
    "    后复权数据将历史价格向后调整，使得历史价格保持不变，而最新的价格根据历史的分红和股权变动进行调整。后复权数据通常用于回测，因为它更贴近实际的交易价格，可以较准确地反映历史的交易情况。\n",
    "\n",
    "    不复权（Unadjusted）:\n",
    "    不复权数据是指没有经过任何调整的原始交易数据。不复权数据反映了实际的市场成交价格，但由于不考虑分红和股权变动，因此它不适合用于长期的价格分析。\n",
    "    \"\"\"\n",
    "    result = ak.stock_zh_a_hist(symbol=stock_code, adjust='hfq').rename(\n",
    "            columns={\n",
    "                \"日期\": \"datetime\",\n",
    "                \"开盘\": \"open\",\n",
    "                \"最高\": \"high\",\n",
    "                \"最低\": \"low\",\n",
    "                \"收盘\": \"close\",\n",
    "                \"成交量\": \"volume\",\n",
    "                \"成交额\": \"turnover\",\n",
    "                \"振幅\": \"amplitude\",\n",
    "                \"涨跌幅\": \"change_pct\",\n",
    "                \"涨跌额\": \"change_amount\",\n",
    "                \"换手率\": \"turnover_rate\",\n",
    "            }\n",
    "        )\n",
    "    result = result[['datetime', 'open', 'high', 'low', 'close', 'volume']]\n",
    "    result.insert(0, 'stock_code', stock_code)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init_start_date = '20240226'\n",
    "raw_data_dir = './raw_data'\n",
    "for stock_code in tqdm(stock_code_list, desc='Raw Data Extraction...'):\n",
    "    try:\n",
    "        save_file_name = f'{stock_code}.pkl'\n",
    "        if save_file_name not in os.listdir(raw_data_dir):\n",
    "            r1_info = get_stock_individual_info(stock_code)\n",
    "            time.sleep(0.1)\n",
    "            r2_info = get_stock_history_info(stock_code)\n",
    "            time.sleep(0.1)\n",
    "            r3_info = get_stock_indicator_info(stock_code)\n",
    "            time.sleep(0.1)\n",
    "            if not r1_info.empty and not r2_info.empty and not r3_info.empty:\n",
    "                merge_info = r1_info.merge(r2_info, on=['stock_code']).merge(r3_info, on=['datetime'])\n",
    "                merge_info.to_pickle(f'{raw_data_dir}/{save_file_name}')\n",
    "    except:\n",
    "        print(f\"Stock {stock_code}, build ERROR ...\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 原始数据特征变换 & 特征抽取 & 特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_info(dataframe):\n",
    "    dataframe = dataframe.sort_values(by=['datetime'])\n",
    "    # 配置参数\n",
    "    max_holding_period = 30\n",
    "    take_profix_threshold = 0.15\n",
    "    stop_loss_threshold = -0.03\n",
    "    # 标签初始化\n",
    "    dataframe['buy_signal'] = 0\n",
    "    dataframe['buy_take_profix'] = 0\n",
    "    dataframe['buy_stop_loss'] = 0\n",
    "    # 标签计算\n",
    "    for ind in range(len(dataframe) - max_holding_period):\n",
    "        # 获取当前价格\n",
    "        current_price = dataframe.iloc[ind]['close']\n",
    "        \n",
    "        # 买入点判断\n",
    "        future_prices = dataframe.iloc[ind + 1:ind + 1 + max_holding_period]['close']\n",
    "        max_future_return = future_prices.max() / current_price - 1\n",
    "        min_future_return = future_prices.min() / current_price - 1\n",
    "        dataframe.at[ind, 'buy_take_profix'] = max_future_return\n",
    "        dataframe.at[ind, 'buy_stop_loss'] = min_future_return\n",
    "        if max_future_return >= take_profix_threshold and min_future_return > stop_loss_threshold:\n",
    "            dataframe.at[ind, 'buy_signal'] = 1\n",
    "    return dataframe\n",
    "\n",
    "def get_datetime_info(dataframe):\n",
    "    datetime_series = pd.to_datetime(dataframe['datetime'])\n",
    "    dataframe['weekday'] = datetime_series.dt.weekday  # 星期几（0=星期一，6=星期日）\n",
    "    dataframe['day_of_week'] = datetime_series.dt.day_name()  # 星期几的名称\n",
    "    dataframe['day_of_month'] = datetime_series.dt.day  # 一个月中的第几天\n",
    "    dataframe['month'] = datetime_series.dt.month  # 月份\n",
    "    dataframe['season'] = datetime_series.dt.month.map(lambda x: {\n",
    "        1: 'Winter', 2: 'Winter', 3: 'Spring', 4: 'Spring', 5: 'Spring',\n",
    "        6: 'Summer', 7: 'Summer', 8: 'Summer', 9: 'Autumn', 10: 'Autumn',\n",
    "        11: 'Autumn', 12: 'Winter'\n",
    "    }.get(x))\n",
    "    return dataframe\n",
    "\n",
    "def get_vwap_col(dataframe):\n",
    "    tp = (dataframe['high'] + dataframe['low'] + dataframe['close']) / 3\n",
    "    tpv = tp * dataframe['volume']\n",
    "    dataframe['vwap'] = tpv.cumsum() / dataframe['volume'].cumsum()\n",
    "    return dataframe\n",
    "\n",
    "def get_factor_info(dataframe, alpha_dict):\n",
    "    for alpha_name, alpha_expression in alpha_dict.items():\n",
    "        dataframe[alpha_name] = calculate_alpha_expression(dataframe, alpha_expression)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Processing...:   0%|          | 0/4586 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Processing...:   7%|▋         | 327/4586 [46:50<10:10:03,  8.59s/it]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m df \u001b[38;5;241m=\u001b[39m get_datetime_info(df)\n\u001b[1;32m      9\u001b[0m df \u001b[38;5;241m=\u001b[39m get_vwap_col(df)\n\u001b[0;32m---> 10\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mget_factor_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m df\u001b[38;5;241m.\u001b[39mto_pickle(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwide_data_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[12], line 47\u001b[0m, in \u001b[0;36mget_factor_info\u001b[0;34m(dataframe, alpha_dict)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_factor_info\u001b[39m(dataframe, alpha_dict):\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m alpha_name, alpha_expression \u001b[38;5;129;01min\u001b[39;00m alpha_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 47\u001b[0m         dataframe[alpha_name] \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_alpha_expression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha_expression\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dataframe\n",
      "File \u001b[0;32m~/VscodeProject/hh_quant/0_Common/notebooks/AlphaFactor.py:344\u001b[0m, in \u001b[0;36mcalculate_alpha_expression\u001b[0;34m(df, expression)\u001b[0m\n\u001b[1;32m    342\u001b[0m expression \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb[A-Za-z_][A-Za-z0-9_]*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mlambda\u001b[39;00m match: match\u001b[38;5;241m.\u001b[39mgroup()\u001b[38;5;241m.\u001b[39mlower(), expression)  \u001b[38;5;66;03m# 全部小写替换\u001b[39;00m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;66;03m# print(f'Updated Expression: {expression}')\u001b[39;00m\n\u001b[0;32m--> 344\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexpression\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<string>:1\u001b[0m\n",
      "File \u001b[0;32m~/VscodeProject/hh_quant/0_Common/notebooks/AlphaFactor.py:117\u001b[0m, in \u001b[0;36mAlphaBaseOperations.resi\u001b[0;34m(series, window)\u001b[0m\n\u001b[1;32m    114\u001b[0m     residuals \u001b[38;5;241m=\u001b[39m y \u001b[38;5;241m-\u001b[39m y_fit  \u001b[38;5;66;03m# 残差\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m residuals[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# 返回窗口中最后一个残差值\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mseries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrolling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompute_residuals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/VscodeProject/hh_quant/.venv/lib/python3.10/site-packages/pandas/core/window/rolling.py:2049\u001b[0m, in \u001b[0;36mRolling.apply\u001b[0;34m(self, func, raw, engine, engine_kwargs, args, kwargs)\u001b[0m\n\u001b[1;32m   2016\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[1;32m   2017\u001b[0m     template_header,\n\u001b[1;32m   2018\u001b[0m     create_section_header(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameters\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2047\u001b[0m     kwargs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2048\u001b[0m ):\n\u001b[0;32m-> 2049\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2050\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2051\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2052\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2056\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/VscodeProject/hh_quant/.venv/lib/python3.10/site-packages/pandas/core/window/rolling.py:1508\u001b[0m, in \u001b[0;36mRollingAndExpandingMixin.apply\u001b[0;34m(self, func, raw, engine, engine_kwargs, args, kwargs)\u001b[0m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1506\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine must be either \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumba\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcython\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1508\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapply_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mapply\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnumba_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumba_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1512\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/VscodeProject/hh_quant/.venv/lib/python3.10/site-packages/pandas/core/window/rolling.py:619\u001b[0m, in \u001b[0;36mBaseWindow._apply\u001b[0;34m(self, func, name, numeric_only, numba_args, **kwargs)\u001b[0m\n\u001b[1;32m    616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 619\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_columnwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhomogeneous_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_tablewise(homogeneous_func, name, numeric_only)\n",
      "File \u001b[0;32m~/VscodeProject/hh_quant/.venv/lib/python3.10/site-packages/pandas/core/window/rolling.py:472\u001b[0m, in \u001b[0;36mBaseWindow._apply_columnwise\u001b[0;34m(self, homogeneous_func, name, numeric_only)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_numeric_only(name, numeric_only)\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selected_obj\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 472\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhomogeneous_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selected_obj, numeric_only)\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;66;03m# GH 12541: Special case for count where we support date-like types\u001b[39;00m\n",
      "File \u001b[0;32m~/VscodeProject/hh_quant/.venv/lib/python3.10/site-packages/pandas/core/window/rolling.py:456\u001b[0m, in \u001b[0;36mBaseWindow._apply_series\u001b[0;34m(self, homogeneous_func, name)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mNotImplementedError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DataError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo numeric types to aggregate\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m--> 456\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mhomogeneous_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    457\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_axis_for_step(obj\u001b[38;5;241m.\u001b[39mindex, result)\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor(result, index\u001b[38;5;241m=\u001b[39mindex, name\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mname)\n",
      "File \u001b[0;32m~/VscodeProject/hh_quant/.venv/lib/python3.10/site-packages/pandas/core/window/rolling.py:614\u001b[0m, in \u001b[0;36mBaseWindow._apply.<locals>.homogeneous_func\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(x, start, end, min_periods, \u001b[38;5;241m*\u001b[39mnumba_args)\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 614\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mcalc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/VscodeProject/hh_quant/.venv/lib/python3.10/site-packages/pandas/core/window/rolling.py:611\u001b[0m, in \u001b[0;36mBaseWindow._apply.<locals>.homogeneous_func.<locals>.calc\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    602\u001b[0m start, end \u001b[38;5;241m=\u001b[39m window_indexer\u001b[38;5;241m.\u001b[39mget_window_bounds(\n\u001b[1;32m    603\u001b[0m     num_values\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(x),\n\u001b[1;32m    604\u001b[0m     min_periods\u001b[38;5;241m=\u001b[39mmin_periods,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    607\u001b[0m     step\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep,\n\u001b[1;32m    608\u001b[0m )\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_window_bounds(start, end, \u001b[38;5;28mlen\u001b[39m(x))\n\u001b[0;32m--> 611\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_periods\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnumba_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/VscodeProject/hh_quant/.venv/lib/python3.10/site-packages/pandas/core/window/rolling.py:1535\u001b[0m, in \u001b[0;36mRollingAndExpandingMixin._generate_cython_apply_func.<locals>.apply_func\u001b[0;34m(values, begin, end, min_periods, raw)\u001b[0m\n\u001b[1;32m   1532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw:\n\u001b[1;32m   1533\u001b[0m     \u001b[38;5;66;03m# GH 45912\u001b[39;00m\n\u001b[1;32m   1534\u001b[0m     values \u001b[38;5;241m=\u001b[39m Series(values, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 1535\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwindow_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_periods\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32maggregations.pyx:1420\u001b[0m, in \u001b[0;36mpandas._libs.window.aggregations.roll_apply\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/VscodeProject/hh_quant/0_Common/notebooks/AlphaFactor.py:112\u001b[0m, in \u001b[0;36mAlphaBaseOperations.resi.<locals>.compute_residuals\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    110\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(y))\n\u001b[1;32m    111\u001b[0m A \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack([x, np\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mlen\u001b[39m(x))])\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m--> 112\u001b[0m m, c \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstsq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrcond\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    113\u001b[0m y_fit \u001b[38;5;241m=\u001b[39m m \u001b[38;5;241m*\u001b[39m x \u001b[38;5;241m+\u001b[39m c  \u001b[38;5;66;03m# 线性拟合值\u001b[39;00m\n\u001b[1;32m    114\u001b[0m residuals \u001b[38;5;241m=\u001b[39m y \u001b[38;5;241m-\u001b[39m y_fit  \u001b[38;5;66;03m# 残差\u001b[39;00m\n",
      "File \u001b[0;32m~/VscodeProject/hh_quant/.venv/lib/python3.10/site-packages/numpy/linalg/linalg.py:2346\u001b[0m, in \u001b[0;36mlstsq\u001b[0;34m(a, b, rcond)\u001b[0m\n\u001b[1;32m   2344\u001b[0m \u001b[38;5;66;03m# coerce output arrays\u001b[39;00m\n\u001b[1;32m   2345\u001b[0m s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mastype(result_real_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 2346\u001b[0m resids \u001b[38;5;241m=\u001b[39m \u001b[43mresids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult_real_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2347\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Copying lets the memory in r_parts be freed\u001b[39;00m\n\u001b[1;32m   2348\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(x), wrap(resids), rank, s\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "wide_data_dir = './wide_data'\n",
    "alpha_dict = json.loads(open('./alpha_lib.json', \"r\").read())\n",
    "\n",
    "for file_name in tqdm(sorted(os.listdir('./raw_data')), desc='Feature Processing...'):\n",
    "    if file_name not in os.listdir(wide_data_dir):\n",
    "        df = pd.read_pickle(f'./raw_data/{file_name}')\n",
    "        df = get_label_info(df)\n",
    "        df = get_datetime_info(df)\n",
    "        df = get_vwap_col(df)\n",
    "        df = get_factor_info(df, alpha_dict)\n",
    "        df.to_pickle(f'{wide_data_dir}/{file_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 特征数据整合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Stock...:   0%|          | 0/327 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Stock...: 100%|██████████| 327/327 [00:07<00:00, 45.75it/s]\n"
     ]
    }
   ],
   "source": [
    "stock_wide_list = []\n",
    "for file_name in tqdm(os.listdir('./wide_data'), desc='Loading Stock...'):\n",
    "    stock_data = pd.read_pickle(f'./wide_data/{file_name}')\n",
    "    stock_wide_list.append(stock_data)\n",
    "df = pd.concat(stock_wide_list)\n",
    "df = df.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timedelta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 选择固定时间区间的数据\n",
    "train_start_date = pd.to_datetime('2018-01-01')\n",
    "train_end_date = pd.to_datetime('2021-12-31')\n",
    "val_start_date = pd.to_datetime('2022-01-01')\n",
    "val_end_date = pd.to_datetime('2022-04-01')\n",
    "\n",
    "train_data = df[(df['datetime'] >= train_start_date) & (df['datetime'] <= train_end_date)]\n",
    "validation_data = df[(df['datetime'] >= val_start_date) & (df['datetime'] <= val_end_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "Total: 254742, Normal: 218772, Positive: 35970 \n",
      "\n",
      "Validation:\n",
      "Total: 14023, Normal: 13276,Positive: 747 \n",
      "\n",
      "Weight for class 0: 0.58\n",
      "Weight for class 1: 3.54\n"
     ]
    }
   ],
   "source": [
    "label_column = 'buy_signal'\n",
    "\n",
    "train_0, train_1 = np.bincount(train_data[label_column])\n",
    "train_total = train_0 + train_1\n",
    "print('Train:\\nTotal: {}, Normal: {}, Positive: {} \\n'.format(train_total, train_0, train_1))\n",
    "val_0, val_1 = np.bincount(validation_data[label_column])\n",
    "val_total = val_0 + val_1\n",
    "print('Validation:\\nTotal: {}, Normal: {},Positive: {} \\n'.format(val_total, val_0, val_1))\n",
    "\n",
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "# The sum of the weights of all examples stays the same.\n",
    "weight_for_0 = (1 / train_0) * (train_total / 2.0)\n",
    "weight_for_1 = (1 / train_1) * (train_total / 2.0)\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 尝试使用LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lgb_train_data = train_data.copy()\n",
    "lgb_val_data = validation_data.copy()\n",
    "\n",
    "label_col = 'buy_signal'\n",
    "numeric_features = [\"KMID\", \"KLEN\", \"KMID2\", \"KUP\", \"KUP2\", \"KLOW\", \"KLOW2\", \"KSFT\", \"KSFT2\", \"OPEN0\", \"OPEN1\", \"OPEN2\", \"OPEN3\", \"OPEN4\", \"HIGH0\", \"HIGH1\", \"HIGH2\", \"HIGH3\", \"HIGH4\", \"LOW0\", \"LOW1\", \"LOW2\", \"LOW3\", \"LOW4\", \"CLOSE0\", \"CLOSE1\", \"CLOSE2\", \"CLOSE3\", \"CLOSE4\", \"VWAP0\", \"VWAP1\", \"VWAP2\", \"VWAP3\", \"VWAP4\", \"VOLUME0\", \"VOLUME1\", \"VOLUME2\", \"VOLUME3\", \"VOLUME4\", \"ROC5\", \"ROC10\", \"ROC20\", \"ROC30\", \"ROC60\", \"MAX5\", \"MAX10\", \"MAX20\", \"MAX30\", \"MAX60\", \"MIN5\", \"MIN10\", \"MIN20\", \"MIN30\", \"MIN60\", \"MA5\", \"MA10\", \"MA20\", \"MA30\", \"MA60\", \"STD5\", \"STD10\", \"STD20\", \"STD30\", \"STD60\", \"BETA5\", \"BETA10\", \"BETA20\", \"BETA30\", \"BETA60\", 'TSRANK5', 'TSRANK10', 'TSRANK20', 'TSRANK30', 'TSRANK60', \"RSQR5\", \"RSQR10\", \"RSQR20\", \"RSQR30\", \"RSQR60\", \"RESI5\", \"RESI10\", \"RESI20\", \"RESI30\", \"RESI60\", \"QTLU5\", \"QTLU10\", \"QTLU20\", \"QTLU30\", \"QTLU60\", \"QTLD5\", \"QTLD10\", \"QTLD20\", \"QTLD30\", \"QTLD60\", \"RSV5\", \"RSV10\", \"RSV20\", \"RSV30\", \"RSV60\", \"IMAX5\", \"IMAX10\", \"IMAX20\", \"IMAX30\", \"IMAX60\", \"IMIN5\", \"IMIN10\", \"IMIN20\", \"IMIN30\", \"IMIN60\", \"IMXD5\", \"IMXD10\", \"IMXD20\", \"IMXD30\", \"IMXD60\", \"CORR5\", \"CORR10\", \"CORR20\", \"CORR30\", \"CORR60\", \"CORD5\", \"CORD10\", \"CORD20\", \"CORD30\", \"CORD60\", \"CNTP5\", \"CNTP10\", \"CNTP20\", \"CNTP30\", \"CNTP60\", \"CNTN5\", \"CNTN10\", \"CNTN20\", \"CNTN30\", \"CNTN60\", \"CNTD5\", \"CNTD10\", \"CNTD20\", \"CNTD30\", \"CNTD60\", \"SUMP5\", \"SUMP10\", \"SUMP20\", \"SUMP30\", \"SUMP60\", \"SUMN5\", \"SUMN10\", \"SUMN20\", \"SUMN30\", \"SUMN60\", \"SUMD5\", \"SUMD10\", \"SUMD20\", \"SUMD30\", \"SUMD60\", \"VMA5\", \"VMA10\", \"VMA20\", \"VMA30\", \"VMA60\", \"VSTD5\", \"VSTD10\", \"VSTD20\", \"VSTD30\", \"VSTD60\", \"WVMA5\", \"WVMA10\", \"WVMA20\", \"WVMA30\", \"WVMA60\", \"VSUMP5\", \"VSUMP10\", \"VSUMP20\", \"VSUMP30\", \"VSUMP60\", \"VSUMN5\", \"VSUMN10\", \"VSUMN20\", \"VSUMN30\", \"VSUMN60\", \"VSUMD5\", \"VSUMD10\", \"VSUMD20\", \"VSUMD30\", \"VSUMD60\"]\n",
    "# category_features = ['industry', 'day_of_week', 'season', 'weekday', 'day_of_month', 'month']\n",
    "category_features = []\n",
    "feature_names = category_features + numeric_features\n",
    "\n",
    "for cat_feas in category_features:\n",
    "    lgb_train_data[cat_feas] = lgb_train_data[cat_feas].astype('category')\n",
    "    lgb_val_data[cat_feas] = lgb_val_data[cat_feas].astype('category')\n",
    "\n",
    "X_train, y_train = lgb_train_data[feature_names], lgb_train_data[label_col]\n",
    "X_val, y_val = lgb_val_data[feature_names], lgb_val_data[label_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# poly = PolynomialFeatures(2, interaction_only=True)\n",
    "# X_poly_train = poly.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 35970, number of negative: 218772\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.142389 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 38640\n",
      "[LightGBM] [Info] Number of data points in the train set: 254742, number of used features: 182\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.141202 -> initscore=-1.805345\n",
      "[LightGBM] [Info] Start training from score -1.805345\n",
      "Accuracy: 0.7514084004849176\n",
      "Precision: 0.08512571947894577\n",
      "Recall: 0.37617135207496655\n",
      "AUC: 0.6178427680794485\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# 网格搜索，参数优化\n",
    "# estimator = LGBMClassifier(num_leaves=201, class_weight=class_weight)\n",
    "# param_grid = {\n",
    "#     'learning_rate': [0.01, 0.1, 1],\n",
    "#     'n_estimators': [300, 500, 1000]\n",
    "# }\n",
    "# gbm = GridSearchCV(estimator, param_grid)\n",
    "# gbm.fit(X_train, y_train)\n",
    "# print('Best parameters found by grid search are:', gbm.best_params_)\n",
    "\n",
    "# 模型训练\n",
    "gbm = LGBMClassifier(num_leaves=201, learning_rate=0.01, n_estimators=1000, is_unbalance=True, random_state=42)\n",
    "# gbm.fit(X_train, y_train, eval_set=[(X_val, y_val)], eval_metric='auc', callbacks=[lgb.early_stopping(1000)])\n",
    "gbm.fit(X_train, y_train, eval_set=[(X_val, y_val)], eval_metric='auc')\n",
    "\n",
    "# 使用 predict 方法获取预测的类别标签\n",
    "y_val_pred = gbm.predict(X_val, num_iteration=gbm.best_iteration_)\n",
    "# 使用 predict_proba 方法获取属于正类的预测概率\n",
    "y_val_prob = gbm.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# 计算准确率\n",
    "print(f'Accuracy: {accuracy_score(y_val, y_val_pred)}')\n",
    "print(f'Precision: {precision_score(y_val, y_val_pred)}')\n",
    "print(f'Recall: {recall_score(y_val, y_val_pred)}')\n",
    "print(f'AUC: {roc_auc_score(y_val, y_val_prob)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buy_signal</th>\n",
       "      <th>buy_take_profix</th>\n",
       "      <th>buy_stop_loss</th>\n",
       "      <th>pred</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5006</th>\n",
       "      <td>0</td>\n",
       "      <td>0.198582</td>\n",
       "      <td>-0.117730</td>\n",
       "      <td>1</td>\n",
       "      <td>0.875562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4983</th>\n",
       "      <td>1</td>\n",
       "      <td>0.649165</td>\n",
       "      <td>0.068417</td>\n",
       "      <td>1</td>\n",
       "      <td>0.872675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4982</th>\n",
       "      <td>1</td>\n",
       "      <td>0.656941</td>\n",
       "      <td>0.068272</td>\n",
       "      <td>1</td>\n",
       "      <td>0.868918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5127</th>\n",
       "      <td>0</td>\n",
       "      <td>0.086993</td>\n",
       "      <td>-0.173000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.861583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5104</th>\n",
       "      <td>0</td>\n",
       "      <td>0.091569</td>\n",
       "      <td>-0.084543</td>\n",
       "      <td>1</td>\n",
       "      <td>0.854561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5100</th>\n",
       "      <td>0</td>\n",
       "      <td>0.092888</td>\n",
       "      <td>-0.098694</td>\n",
       "      <td>1</td>\n",
       "      <td>0.849968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5132</th>\n",
       "      <td>0</td>\n",
       "      <td>0.043965</td>\n",
       "      <td>-0.241890</td>\n",
       "      <td>1</td>\n",
       "      <td>0.835068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5104</th>\n",
       "      <td>0</td>\n",
       "      <td>0.083647</td>\n",
       "      <td>-0.265161</td>\n",
       "      <td>1</td>\n",
       "      <td>0.834318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5099</th>\n",
       "      <td>0</td>\n",
       "      <td>0.159353</td>\n",
       "      <td>-0.043880</td>\n",
       "      <td>1</td>\n",
       "      <td>0.828681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4882</th>\n",
       "      <td>0</td>\n",
       "      <td>0.196259</td>\n",
       "      <td>-0.126593</td>\n",
       "      <td>1</td>\n",
       "      <td>0.823394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5076</th>\n",
       "      <td>0</td>\n",
       "      <td>0.037668</td>\n",
       "      <td>-0.064126</td>\n",
       "      <td>1</td>\n",
       "      <td>0.820637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5133</th>\n",
       "      <td>0</td>\n",
       "      <td>0.036964</td>\n",
       "      <td>-0.246974</td>\n",
       "      <td>1</td>\n",
       "      <td>0.820198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5127</th>\n",
       "      <td>0</td>\n",
       "      <td>0.253328</td>\n",
       "      <td>-0.124946</td>\n",
       "      <td>1</td>\n",
       "      <td>0.816893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5103</th>\n",
       "      <td>0</td>\n",
       "      <td>0.104502</td>\n",
       "      <td>-0.073697</td>\n",
       "      <td>1</td>\n",
       "      <td>0.815384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5107</th>\n",
       "      <td>1</td>\n",
       "      <td>0.671445</td>\n",
       "      <td>0.047269</td>\n",
       "      <td>1</td>\n",
       "      <td>0.811711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5085</th>\n",
       "      <td>0</td>\n",
       "      <td>0.009760</td>\n",
       "      <td>-0.242680</td>\n",
       "      <td>1</td>\n",
       "      <td>0.809468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5108</th>\n",
       "      <td>1</td>\n",
       "      <td>0.212984</td>\n",
       "      <td>-0.005125</td>\n",
       "      <td>1</td>\n",
       "      <td>0.808799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5100</th>\n",
       "      <td>1</td>\n",
       "      <td>0.224036</td>\n",
       "      <td>-0.024481</td>\n",
       "      <td>1</td>\n",
       "      <td>0.798922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5099</th>\n",
       "      <td>1</td>\n",
       "      <td>0.287051</td>\n",
       "      <td>0.025741</td>\n",
       "      <td>1</td>\n",
       "      <td>0.798202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5050</th>\n",
       "      <td>1</td>\n",
       "      <td>0.224233</td>\n",
       "      <td>0.028658</td>\n",
       "      <td>1</td>\n",
       "      <td>0.797368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      buy_signal  buy_take_profix  buy_stop_loss  pred      prob\n",
       "5006           0         0.198582      -0.117730     1  0.875562\n",
       "4983           1         0.649165       0.068417     1  0.872675\n",
       "4982           1         0.656941       0.068272     1  0.868918\n",
       "5127           0         0.086993      -0.173000     1  0.861583\n",
       "5104           0         0.091569      -0.084543     1  0.854561\n",
       "5100           0         0.092888      -0.098694     1  0.849968\n",
       "5132           0         0.043965      -0.241890     1  0.835068\n",
       "5104           0         0.083647      -0.265161     1  0.834318\n",
       "5099           0         0.159353      -0.043880     1  0.828681\n",
       "4882           0         0.196259      -0.126593     1  0.823394\n",
       "5076           0         0.037668      -0.064126     1  0.820637\n",
       "5133           0         0.036964      -0.246974     1  0.820198\n",
       "5127           0         0.253328      -0.124946     1  0.816893\n",
       "5103           0         0.104502      -0.073697     1  0.815384\n",
       "5107           1         0.671445       0.047269     1  0.811711\n",
       "5085           0         0.009760      -0.242680     1  0.809468\n",
       "5108           1         0.212984      -0.005125     1  0.808799\n",
       "5100           1         0.224036      -0.024481     1  0.798922\n",
       "5099           1         0.287051       0.025741     1  0.798202\n",
       "5050           1         0.224233       0.028658     1  0.797368"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = validation_data[['buy_signal', 'buy_take_profix', 'buy_stop_loss']]\n",
    "test_df['pred'] = y_val_pred\n",
    "test_df['prob'] = y_val_prob\n",
    "test_df.sort_values(by='prob', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances: [('CORR60', 14), ('WVMA60', 12), ('STD60', 10), ('CORD60', 10), ('IMXD60', 8), ('STD20', 7), ('RSQR60', 7), ('IMIN60', 7), ('VWAP0', 6), ('WVMA20', 6), ('CORD20', 5), ('CORD30', 5), ('BETA60', 4), ('QTLD60', 4), ('IMIN20', 4), ('CORR20', 4), ('SUMN60', 4), ('VWAP1', 3), ('VWAP4', 3), ('MAX20', 3), ('MIN60', 3), ('BETA30', 3), ('QTLU60', 3), ('VSTD30', 3), ('VWAP3', 2), ('ROC60', 2), ('MAX30', 2), ('MIN20', 2), ('STD5', 2), ('STD10', 2), ('STD30', 2), ('BETA20', 2), ('RESI60', 2), ('QTLU20', 2), ('CORR30', 2), ('CORD10', 2), ('CNTD60', 2), ('VSTD60', 2), ('VSUMP60', 2), ('VSUMN60', 2), ('LOW3', 1), ('VWAP2', 1), ('MAX10', 1), ('MAX60', 1), ('MIN5', 1), ('MIN30', 1), ('MA10', 1), ('MA20', 1), ('MA30', 1), ('MA60', 1), ('RSQR20', 1), ('RSQR30', 1), ('RESI30', 1), ('QTLD10', 1), ('QTLD20', 1), ('IMAX30', 1), ('IMIN30', 1), ('CNTP20', 1), ('CNTP60', 1), ('CNTN60', 1), ('CNTD30', 1), ('SUMP60', 1), ('SUMD30', 1), ('SUMD60', 1), ('VMA30', 1), ('VSTD10', 1), ('WVMA10', 1), ('WVMA30', 1), ('VSUMN30', 1), ('VSUMD60', 1), ('KMID', 0), ('KLEN', 0), ('KMID2', 0), ('KUP', 0), ('KUP2', 0), ('KLOW', 0), ('KLOW2', 0), ('KSFT', 0), ('KSFT2', 0), ('OPEN0', 0), ('OPEN1', 0), ('OPEN2', 0), ('OPEN3', 0), ('OPEN4', 0), ('HIGH0', 0), ('HIGH1', 0), ('HIGH2', 0), ('HIGH3', 0), ('HIGH4', 0), ('LOW0', 0), ('LOW1', 0), ('LOW2', 0), ('LOW4', 0), ('CLOSE0', 0), ('CLOSE1', 0), ('CLOSE2', 0), ('CLOSE3', 0), ('CLOSE4', 0), ('VOLUME0', 0), ('VOLUME1', 0), ('VOLUME2', 0), ('VOLUME3', 0), ('VOLUME4', 0), ('ROC5', 0), ('ROC10', 0), ('ROC20', 0), ('ROC30', 0), ('MAX5', 0), ('MIN10', 0), ('MA5', 0), ('BETA5', 0), ('BETA10', 0), ('TSRANK5', 0), ('TSRANK10', 0), ('TSRANK20', 0), ('TSRANK30', 0), ('TSRANK60', 0), ('RSQR5', 0), ('RSQR10', 0), ('RESI5', 0), ('RESI10', 0), ('RESI20', 0), ('QTLU5', 0), ('QTLU10', 0), ('QTLU30', 0), ('QTLD5', 0), ('QTLD30', 0), ('RSV5', 0), ('RSV10', 0), ('RSV20', 0), ('RSV30', 0), ('RSV60', 0), ('IMAX5', 0), ('IMAX10', 0), ('IMAX20', 0), ('IMAX60', 0), ('IMIN5', 0), ('IMIN10', 0), ('IMXD5', 0), ('IMXD10', 0), ('IMXD20', 0), ('IMXD30', 0), ('CORR5', 0), ('CORR10', 0), ('CORD5', 0), ('CNTP5', 0), ('CNTP10', 0), ('CNTP30', 0), ('CNTN5', 0), ('CNTN10', 0), ('CNTN20', 0), ('CNTN30', 0), ('CNTD5', 0), ('CNTD10', 0), ('CNTD20', 0), ('SUMP5', 0), ('SUMP10', 0), ('SUMP20', 0), ('SUMP30', 0), ('SUMN5', 0), ('SUMN10', 0), ('SUMN20', 0), ('SUMN30', 0), ('SUMD5', 0), ('SUMD10', 0), ('SUMD20', 0), ('VMA5', 0), ('VMA10', 0), ('VMA20', 0), ('VMA60', 0), ('VSTD5', 0), ('VSTD20', 0), ('WVMA5', 0), ('VSUMP5', 0), ('VSUMP10', 0), ('VSUMP20', 0), ('VSUMP30', 0), ('VSUMN5', 0), ('VSUMN10', 0), ('VSUMN20', 0), ('VSUMD5', 0), ('VSUMD10', 0), ('VSUMD20', 0), ('VSUMD30', 0)]\n"
     ]
    }
   ],
   "source": [
    "# 特征重要度\n",
    "feature_importance = sorted(zip(feature_names, gbm.feature_importances_), key=lambda x:x[1], reverse=True)\n",
    "print('Feature importances:',feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用tensorflow处理原始数据\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numeric_boundaries(series, num_bins=40):\n",
    "    boundaries = pd.qcut(series, num_bins, retbins=True, duplicates='drop')[1].tolist()\n",
    "    return boundaries\n",
    "\n",
    "TARGET_FEATURE_NAME = \"label1\"\n",
    "\n",
    "# 连续特征分桶\n",
    "NUMERIC_FEATURES = {\n",
    "    'total_shares': get_numeric_boundaries(train_data['total_shares']),\n",
    "    'circulating_shares': get_numeric_boundaries(train_data['circulating_shares']),\n",
    "    'total_market_cap': get_numeric_boundaries(train_data['total_market_cap']),\n",
    "    'circulating_market_cap': get_numeric_boundaries(train_data['circulating_market_cap']),\n",
    "    'turnover_rate': get_numeric_boundaries(train_data['turnover_rate']),\n",
    "    'pe': get_numeric_boundaries(train_data['pe']),\n",
    "    'pe_ttm': get_numeric_boundaries(train_data['pe_ttm']),\n",
    "    'pb': get_numeric_boundaries(train_data['pb']),\n",
    "    'ps': get_numeric_boundaries(train_data['ps']),\n",
    "    'ps_ttm': get_numeric_boundaries(train_data['ps_ttm']),\n",
    "    'total_mv': get_numeric_boundaries(train_data['total_mv']),\n",
    "    \"KMID\": get_numeric_boundaries(train_data[\"KMID\"]),\n",
    "    \"KLEN\": get_numeric_boundaries(train_data[\"KLEN\"]),\n",
    "    \"KMID2\": get_numeric_boundaries(train_data[\"KMID2\"]),\n",
    "    \"KUP\": get_numeric_boundaries(train_data[\"KUP\"]),\n",
    "    \"KUP2\": get_numeric_boundaries(train_data[\"KUP2\"]),\n",
    "    \"KLOW\": get_numeric_boundaries(train_data[\"KLOW\"]),\n",
    "    \"KLOW2\": get_numeric_boundaries(train_data[\"KLOW2\"]),\n",
    "    \"KSFT\": get_numeric_boundaries(train_data[\"KSFT\"]),\n",
    "    \"KSFT2\": get_numeric_boundaries(train_data[\"KSFT2\"]),\n",
    "    \"OPEN0\": get_numeric_boundaries(train_data[\"OPEN0\"]),\n",
    "    \"OPEN1\": get_numeric_boundaries(train_data[\"OPEN1\"]),\n",
    "    \"OPEN2\": get_numeric_boundaries(train_data[\"OPEN2\"]),\n",
    "    \"OPEN3\": get_numeric_boundaries(train_data[\"OPEN3\"]),\n",
    "    \"OPEN4\": get_numeric_boundaries(train_data[\"OPEN4\"]),\n",
    "    \"HIGH0\": get_numeric_boundaries(train_data[\"HIGH0\"]),\n",
    "    \"HIGH1\": get_numeric_boundaries(train_data[\"HIGH1\"]),\n",
    "    \"HIGH2\": get_numeric_boundaries(train_data[\"HIGH2\"]),\n",
    "    \"HIGH3\": get_numeric_boundaries(train_data[\"HIGH3\"]),\n",
    "    \"HIGH4\": get_numeric_boundaries(train_data[\"HIGH4\"]),\n",
    "    \"LOW0\": get_numeric_boundaries(train_data[\"LOW0\"]),\n",
    "    \"LOW1\": get_numeric_boundaries(train_data[\"LOW1\"]),\n",
    "    \"LOW2\": get_numeric_boundaries(train_data[\"LOW2\"]),\n",
    "    \"LOW3\": get_numeric_boundaries(train_data[\"LOW3\"]),\n",
    "    \"LOW4\": get_numeric_boundaries(train_data[\"LOW4\"]),\n",
    "    \"CLOSE0\": get_numeric_boundaries(train_data[\"CLOSE0\"]),\n",
    "    \"CLOSE1\": get_numeric_boundaries(train_data[\"CLOSE1\"]),\n",
    "    \"CLOSE2\": get_numeric_boundaries(train_data[\"CLOSE2\"]),\n",
    "    \"CLOSE3\": get_numeric_boundaries(train_data[\"CLOSE3\"]),\n",
    "    \"CLOSE4\": get_numeric_boundaries(train_data[\"CLOSE4\"]),\n",
    "    \"VWAP0\": get_numeric_boundaries(train_data[\"VWAP0\"]),\n",
    "    \"VWAP1\": get_numeric_boundaries(train_data[\"VWAP1\"]),\n",
    "    \"VWAP2\": get_numeric_boundaries(train_data[\"VWAP2\"]),\n",
    "    \"VWAP3\": get_numeric_boundaries(train_data[\"VWAP3\"]),\n",
    "    \"VWAP4\": get_numeric_boundaries(train_data[\"VWAP4\"]),\n",
    "    \"VOLUME0\": get_numeric_boundaries(train_data[\"VOLUME0\"]),\n",
    "    \"VOLUME1\": get_numeric_boundaries(train_data[\"VOLUME1\"]),\n",
    "    \"VOLUME2\": get_numeric_boundaries(train_data[\"VOLUME2\"]),\n",
    "    \"VOLUME3\": get_numeric_boundaries(train_data[\"VOLUME3\"]),\n",
    "    \"VOLUME4\": get_numeric_boundaries(train_data[\"VOLUME4\"]),\n",
    "    \"ROC5\": get_numeric_boundaries(train_data[\"ROC5\"]),\n",
    "    \"ROC10\": get_numeric_boundaries(train_data[\"ROC10\"]),\n",
    "    \"ROC20\": get_numeric_boundaries(train_data[\"ROC20\"]),\n",
    "    \"ROC30\": get_numeric_boundaries(train_data[\"ROC30\"]),\n",
    "    \"ROC60\": get_numeric_boundaries(train_data[\"ROC60\"]),\n",
    "    \"MAX5\": get_numeric_boundaries(train_data[\"MAX5\"]),\n",
    "    \"MAX10\": get_numeric_boundaries(train_data[\"MAX10\"]),\n",
    "    \"MAX20\": get_numeric_boundaries(train_data[\"MAX20\"]),\n",
    "    \"MAX30\": get_numeric_boundaries(train_data[\"MAX30\"]),\n",
    "    \"MAX60\": get_numeric_boundaries(train_data[\"MAX60\"]),\n",
    "    \"MIN5\": get_numeric_boundaries(train_data[\"MIN5\"]),\n",
    "    \"MIN10\": get_numeric_boundaries(train_data[\"MIN10\"]),\n",
    "    \"MIN20\": get_numeric_boundaries(train_data[\"MIN20\"]),\n",
    "    \"MIN30\": get_numeric_boundaries(train_data[\"MIN30\"]),\n",
    "    \"MIN60\": get_numeric_boundaries(train_data[\"MIN60\"]),\n",
    "    \"MA5\": get_numeric_boundaries(train_data[\"MA5\"]),\n",
    "    \"MA10\": get_numeric_boundaries(train_data[\"MA10\"]),\n",
    "    \"MA20\": get_numeric_boundaries(train_data[\"MA20\"]),\n",
    "    \"MA30\": get_numeric_boundaries(train_data[\"MA30\"]),\n",
    "    \"MA60\": get_numeric_boundaries(train_data[\"MA60\"]),\n",
    "    \"STD5\": get_numeric_boundaries(train_data[\"STD5\"]),\n",
    "    \"STD10\": get_numeric_boundaries(train_data[\"STD10\"]),\n",
    "    \"STD20\": get_numeric_boundaries(train_data[\"STD20\"]),\n",
    "    \"STD30\": get_numeric_boundaries(train_data[\"STD30\"]),\n",
    "    \"STD60\": get_numeric_boundaries(train_data[\"STD60\"]),\n",
    "    \"BETA5\": get_numeric_boundaries(train_data[\"BETA5\"]),\n",
    "    \"BETA10\": get_numeric_boundaries(train_data[\"BETA10\"]),\n",
    "    \"BETA20\": get_numeric_boundaries(train_data[\"BETA20\"]),\n",
    "    \"BETA30\": get_numeric_boundaries(train_data[\"BETA30\"]),\n",
    "    \"BETA60\": get_numeric_boundaries(train_data[\"BETA60\"]),\n",
    "    \"RSQR5\": get_numeric_boundaries(train_data[\"RSQR5\"]),\n",
    "    \"RSQR10\": get_numeric_boundaries(train_data[\"RSQR10\"]),\n",
    "    \"RSQR20\": get_numeric_boundaries(train_data[\"RSQR20\"]),\n",
    "    \"RSQR30\": get_numeric_boundaries(train_data[\"RSQR30\"]),\n",
    "    \"RSQR60\": get_numeric_boundaries(train_data[\"RSQR60\"]),\n",
    "    \"RESI5\": get_numeric_boundaries(train_data[\"RESI5\"]),\n",
    "    \"RESI10\": get_numeric_boundaries(train_data[\"RESI10\"]),\n",
    "    \"RESI20\": get_numeric_boundaries(train_data[\"RESI20\"]),\n",
    "    \"RESI30\": get_numeric_boundaries(train_data[\"RESI30\"]),\n",
    "    \"RESI60\": get_numeric_boundaries(train_data[\"RESI60\"]),\n",
    "    \"QTLU5\": get_numeric_boundaries(train_data[\"QTLU5\"]),\n",
    "    \"QTLU10\": get_numeric_boundaries(train_data[\"QTLU10\"]),\n",
    "    \"QTLU20\": get_numeric_boundaries(train_data[\"QTLU20\"]),\n",
    "    \"QTLU30\": get_numeric_boundaries(train_data[\"QTLU30\"]),\n",
    "    \"QTLU60\": get_numeric_boundaries(train_data[\"QTLU60\"]),\n",
    "    \"QTLD5\": get_numeric_boundaries(train_data[\"QTLD5\"]),\n",
    "    \"QTLD10\": get_numeric_boundaries(train_data[\"QTLD10\"]),\n",
    "    \"QTLD20\": get_numeric_boundaries(train_data[\"QTLD20\"]),\n",
    "    \"QTLD30\": get_numeric_boundaries(train_data[\"QTLD30\"]),\n",
    "    \"QTLD60\": get_numeric_boundaries(train_data[\"QTLD60\"]),\n",
    "    # \"TSRANK5\": get_numeric_boundaries(train_data[\"TSRANK5\"]),\n",
    "    # \"TSRANK10\": get_numeric_boundaries(train_data[\"TSRANK10\"]),\n",
    "    # \"TSRANK20\": get_numeric_boundaries(train_data[\"TSRANK20\"]),\n",
    "    # \"TSRANK30\": get_numeric_boundaries(train_data[\"TSRANK30\"]),\n",
    "    # \"TSRANK60\": get_numeric_boundaries(train_data[\"TSRANK60\"]),\n",
    "    \"RSV5\": get_numeric_boundaries(train_data[\"RSV5\"]),\n",
    "    \"RSV10\": get_numeric_boundaries(train_data[\"RSV10\"]),\n",
    "    \"RSV20\": get_numeric_boundaries(train_data[\"RSV20\"]),\n",
    "    \"RSV30\": get_numeric_boundaries(train_data[\"RSV30\"]),\n",
    "    \"RSV60\": get_numeric_boundaries(train_data[\"RSV60\"]),\n",
    "    \"IMAX5\": get_numeric_boundaries(train_data[\"IMAX5\"]),\n",
    "    \"IMAX10\": get_numeric_boundaries(train_data[\"IMAX10\"]),\n",
    "    \"IMAX20\": get_numeric_boundaries(train_data[\"IMAX20\"]),\n",
    "    \"IMAX30\": get_numeric_boundaries(train_data[\"IMAX30\"]),\n",
    "    \"IMAX60\": get_numeric_boundaries(train_data[\"IMAX60\"]),\n",
    "    \"IMIN5\": get_numeric_boundaries(train_data[\"IMIN5\"]),\n",
    "    \"IMIN10\": get_numeric_boundaries(train_data[\"IMIN10\"]),\n",
    "    \"IMIN20\": get_numeric_boundaries(train_data[\"IMIN20\"]),\n",
    "    \"IMIN30\": get_numeric_boundaries(train_data[\"IMIN30\"]),\n",
    "    \"IMIN60\": get_numeric_boundaries(train_data[\"IMIN60\"]),\n",
    "    \"IMXD5\": get_numeric_boundaries(train_data[\"IMXD5\"]),\n",
    "    \"IMXD10\": get_numeric_boundaries(train_data[\"IMXD10\"]),\n",
    "    \"IMXD20\": get_numeric_boundaries(train_data[\"IMXD20\"]),\n",
    "    \"IMXD30\": get_numeric_boundaries(train_data[\"IMXD30\"]),\n",
    "    \"IMXD60\": get_numeric_boundaries(train_data[\"IMXD60\"]),\n",
    "    \"CORR5\": get_numeric_boundaries(train_data[\"CORR5\"]),\n",
    "    \"CORR10\": get_numeric_boundaries(train_data[\"CORR10\"]),\n",
    "    \"CORR20\": get_numeric_boundaries(train_data[\"CORR20\"]),\n",
    "    \"CORR30\": get_numeric_boundaries(train_data[\"CORR30\"]),\n",
    "    \"CORR60\": get_numeric_boundaries(train_data[\"CORR60\"]),\n",
    "    \"CORD5\": get_numeric_boundaries(train_data[\"CORD5\"]),\n",
    "    \"CORD10\": get_numeric_boundaries(train_data[\"CORD10\"]),\n",
    "    \"CORD20\": get_numeric_boundaries(train_data[\"CORD20\"]),\n",
    "    \"CORD30\": get_numeric_boundaries(train_data[\"CORD30\"]),\n",
    "    \"CORD60\": get_numeric_boundaries(train_data[\"CORD60\"]),\n",
    "    \"CNTP5\": get_numeric_boundaries(train_data[\"CNTP5\"]),\n",
    "    \"CNTP10\": get_numeric_boundaries(train_data[\"CNTP10\"]),\n",
    "    \"CNTP20\": get_numeric_boundaries(train_data[\"CNTP20\"]),\n",
    "    \"CNTP30\": get_numeric_boundaries(train_data[\"CNTP30\"]),\n",
    "    \"CNTP60\": get_numeric_boundaries(train_data[\"CNTP60\"]),\n",
    "    \"CNTN5\": get_numeric_boundaries(train_data[\"CNTN5\"]),\n",
    "    \"CNTN10\": get_numeric_boundaries(train_data[\"CNTN10\"]),\n",
    "    \"CNTN20\": get_numeric_boundaries(train_data[\"CNTN20\"]),\n",
    "    \"CNTN30\": get_numeric_boundaries(train_data[\"CNTN30\"]),\n",
    "    \"CNTN60\": get_numeric_boundaries(train_data[\"CNTN60\"]),\n",
    "    \"CNTD5\": get_numeric_boundaries(train_data[\"CNTD5\"]),\n",
    "    \"CNTD10\": get_numeric_boundaries(train_data[\"CNTD10\"]),\n",
    "    \"CNTD20\": get_numeric_boundaries(train_data[\"CNTD20\"]),\n",
    "    \"CNTD30\": get_numeric_boundaries(train_data[\"CNTD30\"]),\n",
    "    \"CNTD60\": get_numeric_boundaries(train_data[\"CNTD60\"]),\n",
    "    \"SUMP5\": get_numeric_boundaries(train_data[\"SUMP5\"]),\n",
    "    \"SUMP10\": get_numeric_boundaries(train_data[\"SUMP10\"]),\n",
    "    \"SUMP20\": get_numeric_boundaries(train_data[\"SUMP20\"]),\n",
    "    \"SUMP30\": get_numeric_boundaries(train_data[\"SUMP30\"]),\n",
    "    \"SUMP60\": get_numeric_boundaries(train_data[\"SUMP60\"]),\n",
    "    \"SUMN5\": get_numeric_boundaries(train_data[\"SUMN5\"]),\n",
    "    \"SUMN10\": get_numeric_boundaries(train_data[\"SUMN10\"]),\n",
    "    \"SUMN20\": get_numeric_boundaries(train_data[\"SUMN20\"]),\n",
    "    \"SUMN30\": get_numeric_boundaries(train_data[\"SUMN30\"]),\n",
    "    \"SUMN60\": get_numeric_boundaries(train_data[\"SUMN60\"]),\n",
    "    \"SUMD5\": get_numeric_boundaries(train_data[\"SUMD5\"]),\n",
    "    \"SUMD10\": get_numeric_boundaries(train_data[\"SUMD10\"]),\n",
    "    \"SUMD20\": get_numeric_boundaries(train_data[\"SUMD20\"]),\n",
    "    \"SUMD30\": get_numeric_boundaries(train_data[\"SUMD30\"]),\n",
    "    \"SUMD60\": get_numeric_boundaries(train_data[\"SUMD60\"]),\n",
    "    \"VMA5\": get_numeric_boundaries(train_data[\"VMA5\"]),\n",
    "    \"VMA10\": get_numeric_boundaries(train_data[\"VMA10\"]),\n",
    "    \"VMA20\": get_numeric_boundaries(train_data[\"VMA20\"]),\n",
    "    \"VMA30\": get_numeric_boundaries(train_data[\"VMA30\"]),\n",
    "    \"VMA60\": get_numeric_boundaries(train_data[\"VMA60\"]),\n",
    "    \"VSTD5\": get_numeric_boundaries(train_data[\"VSTD5\"]),\n",
    "    \"VSTD10\": get_numeric_boundaries(train_data[\"VSTD10\"]),\n",
    "    \"VSTD20\": get_numeric_boundaries(train_data[\"VSTD20\"]),\n",
    "    \"VSTD30\": get_numeric_boundaries(train_data[\"VSTD30\"]),\n",
    "    \"VSTD60\": get_numeric_boundaries(train_data[\"VSTD60\"]),\n",
    "    \"WVMA5\": get_numeric_boundaries(train_data[\"WVMA5\"]),\n",
    "    \"WVMA10\": get_numeric_boundaries(train_data[\"WVMA10\"]),\n",
    "    \"WVMA20\": get_numeric_boundaries(train_data[\"WVMA20\"]),\n",
    "    \"WVMA30\": get_numeric_boundaries(train_data[\"WVMA30\"]),\n",
    "    \"WVMA60\": get_numeric_boundaries(train_data[\"WVMA60\"]),\n",
    "    \"VSUMP5\": get_numeric_boundaries(train_data[\"VSUMP5\"]),\n",
    "    \"VSUMP10\": get_numeric_boundaries(train_data[\"VSUMP10\"]),\n",
    "    \"VSUMP20\": get_numeric_boundaries(train_data[\"VSUMP20\"]),\n",
    "    \"VSUMP30\": get_numeric_boundaries(train_data[\"VSUMP30\"]),\n",
    "    \"VSUMP60\": get_numeric_boundaries(train_data[\"VSUMP60\"]),\n",
    "    \"VSUMN5\": get_numeric_boundaries(train_data[\"VSUMN5\"]),\n",
    "    \"VSUMN10\": get_numeric_boundaries(train_data[\"VSUMN10\"]),\n",
    "    \"VSUMN20\": get_numeric_boundaries(train_data[\"VSUMN20\"]),\n",
    "    \"VSUMN30\": get_numeric_boundaries(train_data[\"VSUMN30\"]),\n",
    "    \"VSUMN60\": get_numeric_boundaries(train_data[\"VSUMN60\"]),\n",
    "    \"VSUMD5\": get_numeric_boundaries(train_data[\"VSUMD5\"]),\n",
    "    \"VSUMD10\": get_numeric_boundaries(train_data[\"VSUMD10\"]),\n",
    "    \"VSUMD20\": get_numeric_boundaries(train_data[\"VSUMD20\"]),\n",
    "    \"VSUMD30\": get_numeric_boundaries(train_data[\"VSUMD30\"]),\n",
    "    \"VSUMD60\": get_numeric_boundaries(train_data[\"VSUMD60\"]),\n",
    "}\n",
    "\n",
    "# 离散特征embedding\n",
    "INTEGER_CATEGORICAL_FEATURES = {\n",
    "    'weekday': train_data['weekday'].unique().tolist(),\n",
    "    'day_of_month': train_data['day_of_month'].unique().tolist(),\n",
    "    'month': train_data['month'].unique().tolist(),\n",
    "    # 'TSRANK5': train_data['TSRANK5'].unique().tolist(),\n",
    "    # 'TSRANK10': train_data['TSRANK10'].unique().tolist(),\n",
    "    # 'TSRANK20': train_data['TSRANK20'].unique().tolist(),\n",
    "    # 'TSRANK30': train_data['TSRANK30'].unique().tolist(),\n",
    "    # 'TSRANK60': train_data['TSRANK60'].unique().tolist(),\n",
    "}\n",
    "STRING_CATEGORICAL_FEATURES = {\n",
    "    'industry': train_data['industry'].unique().tolist(),\n",
    "    'day_of_week': train_data['day_of_week'].unique().tolist(),\n",
    "    'season': train_data['season'].unique().tolist(),\n",
    "}\n",
    "\n",
    "\n",
    "FEATURE_NAMES = list(NUMERIC_FEATURES.keys()) + list(INTEGER_CATEGORICAL_FEATURES.keys()) + list(STRING_CATEGORICAL_FEATURES.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "def df_to_dataset(dataframe, shuffle=True):\n",
    "  # dataframe = dataframe.drop('datetime', axis=1)\n",
    "  labels = dataframe[TARGET_FEATURE_NAME]\n",
    "  dataframe = dataframe[FEATURE_NAMES]\n",
    "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "  ds = ds.batch(BATCH_SIZE)\n",
    "  return ds\n",
    "\n",
    "train_ds = df_to_dataset(train_data, shuffle=True)\n",
    "val_ds = df_to_dataset(validation_data, shuffle=False)\n",
    "test_ds = df_to_dataset(test_data, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_inputs():\n",
    "    inputs = {}\n",
    "    for feature_name in FEATURE_NAMES:\n",
    "        if feature_name in NUMERIC_FEATURES:\n",
    "            inputs[feature_name] = tf.keras.layers.Input(\n",
    "                name=feature_name, shape=(), dtype=\"float32\"\n",
    "            )\n",
    "        elif feature_name in INTEGER_CATEGORICAL_FEATURES:\n",
    "            inputs[feature_name] = tf.keras.layers.Input(\n",
    "                name=feature_name, shape=(), dtype=\"int32\"\n",
    "            )\n",
    "        else:\n",
    "            inputs[feature_name] = tf.keras.layers.Input(\n",
    "                name=feature_name, shape=(), dtype=\"string\"\n",
    "            )\n",
    "    return inputs\n",
    "\n",
    "def encode_inputs(inputs):\n",
    "    encoded_features = []\n",
    "    embedding_dim = 6\n",
    "    is_embedding = True\n",
    "\n",
    "    # 处理连续特征\n",
    "    for feature_name, boundaries in NUMERIC_FEATURES.items():\n",
    "        if is_embedding:\n",
    "            lookup_layer = tf.keras.layers.Discretization(bin_boundaries=boundaries,output_mode='int')\n",
    "            embedding = tf.keras.layers.Embedding(\n",
    "                input_dim=len(boundaries) + 1, output_dim=embedding_dim\n",
    "            )\n",
    "            encoded_feature = embedding(lookup_layer(inputs[feature_name]))\n",
    "        else:\n",
    "            lookup_layer = tf.keras.layers.Discretization(bin_boundaries=boundaries,output_mode='one_hot')\n",
    "            encoded_feature = lookup_layer(inputs[feature_name])\n",
    "        encoded_features.append(encoded_feature)\n",
    "\n",
    "    # 处理INTEGER离散特征\n",
    "    for feature_name, integer_vocab in INTEGER_CATEGORICAL_FEATURES.items():\n",
    "        lookup_layer = tf.keras.layers.IntegerLookup(vocabulary=integer_vocab)\n",
    "        embedding = tf.keras.layers.Embedding(\n",
    "            input_dim=len(integer_vocab) + 1, output_dim=embedding_dim\n",
    "        )\n",
    "        encoded_feature = embedding(lookup_layer(inputs[feature_name]))\n",
    "        encoded_features.append(encoded_feature)\n",
    "    \n",
    "    # 处理STRING离散特征\n",
    "    for feature_name, string_vocab in STRING_CATEGORICAL_FEATURES.items():\n",
    "        lookup_layer = tf.keras.layers.StringLookup(vocabulary=string_vocab)\n",
    "        embedding = tf.keras.layers.Embedding(\n",
    "            input_dim=len(string_vocab) + 1, output_dim=embedding_dim\n",
    "        )\n",
    "        encoded_feature = embedding(lookup_layer(inputs[feature_name]))\n",
    "        encoded_features.append(encoded_feature)\n",
    "    \n",
    "    print(f\"Total Features Size:: {len(encoded_features)}\")\n",
    "    all_features = tf.keras.layers.concatenate(encoded_features)\n",
    "    return all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 5e-3\n",
    "NUM_EPOCH = 20\n",
    "\n",
    "def run_experiment(model, train_ds, val_ds, test_ds):\n",
    "    # optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=LEARNING_RATE) # for mac M1/M2\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE) # for mac M1/M2\n",
    "    \n",
    "    loss = tf.keras.losses.BinaryCrossentropy()\n",
    "    metrics = [\n",
    "        tf.keras.metrics.TruePositives(name='tp'),\n",
    "        tf.keras.metrics.FalsePositives(name='fp'),\n",
    "        tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "        tf.keras.metrics.FalseNegatives(name='fn'), \n",
    "        tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall'),\n",
    "        tf.keras.metrics.AUC(name='auc'),\n",
    "    ]\n",
    "        \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=metrics,\n",
    "    )\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_auc',\n",
    "        verbose=1,\n",
    "        patience=10,\n",
    "        mode='max',\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "    print(\"Start training the model...\")\n",
    "    history = model.fit(\n",
    "        train_ds, \n",
    "        epochs=NUM_EPOCH,\n",
    "        validation_data=val_ds, \n",
    "        verbose=2,\n",
    "        callbacks=[early_stopping],\n",
    "        class_weight=class_weight\n",
    "    )\n",
    "    print(\"Model training finished\")\n",
    "\n",
    "    # loss, auc = model.evaluate(test_ds, verbose=0)\n",
    "    # print(f\"Test AUC::{round(auc * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_rate = 0.2\n",
    "hidden_units = [128, 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Features Size:: 196\n",
      "Start training the model...\n",
      "Epoch 1/20\n",
      "879/879 - 53s - loss: 0.6766 - tp: 19124.0000 - fp: 34636.0000 - tn: 45405.0000 - fn: 13300.0000 - accuracy: 0.5738 - precision: 0.3557 - recall: 0.5898 - auc: 0.6080 - val_loss: 0.6920 - val_tp: 1801.0000 - val_fp: 4452.0000 - val_tn: 4455.0000 - val_fn: 1178.0000 - val_accuracy: 0.5263 - val_precision: 0.2880 - val_recall: 0.6046 - val_auc: 0.5721 - 53s/epoch - 60ms/step\n",
      "Epoch 2/20\n",
      "879/879 - 24s - loss: 0.6381 - tp: 21462.0000 - fp: 31439.0000 - tn: 48602.0000 - fn: 10962.0000 - accuracy: 0.6230 - precision: 0.4057 - recall: 0.6619 - auc: 0.6850 - val_loss: 0.7583 - val_tp: 1899.0000 - val_fp: 4828.0000 - val_tn: 4079.0000 - val_fn: 1080.0000 - val_accuracy: 0.5029 - val_precision: 0.2823 - val_recall: 0.6375 - val_auc: 0.5596 - 24s/epoch - 28ms/step\n",
      "Epoch 3/20\n",
      "879/879 - 25s - loss: 0.6027 - tp: 22606.0000 - fp: 28416.0000 - tn: 51625.0000 - fn: 9818.0000 - accuracy: 0.6600 - precision: 0.4431 - recall: 0.6972 - auc: 0.7352 - val_loss: 0.7394 - val_tp: 1678.0000 - val_fp: 4147.0000 - val_tn: 4760.0000 - val_fn: 1301.0000 - val_accuracy: 0.5416 - val_precision: 0.2881 - val_recall: 0.5633 - val_auc: 0.5603 - 25s/epoch - 29ms/step\n",
      "Epoch 4/20\n",
      "879/879 - 29s - loss: 0.5593 - tp: 23897.0000 - fp: 25518.0000 - tn: 54523.0000 - fn: 8527.0000 - accuracy: 0.6973 - precision: 0.4836 - recall: 0.7370 - auc: 0.7829 - val_loss: 0.7319 - val_tp: 1463.0000 - val_fp: 3666.0000 - val_tn: 5241.0000 - val_fn: 1516.0000 - val_accuracy: 0.5640 - val_precision: 0.2852 - val_recall: 0.4911 - val_auc: 0.5588 - 29s/epoch - 34ms/step\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-23 16:41:25.714555: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] ShuffleDatasetV3:17: Filling up shuffle buffer (this may take a while): 102318 of 112465\n",
      "2024-02-23 16:41:26.773264: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:452] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "879/879 - 29s - loss: 0.5095 - tp: 25253.0000 - fp: 22573.0000 - tn: 57468.0000 - fn: 7171.0000 - accuracy: 0.7355 - precision: 0.5280 - recall: 0.7788 - auc: 0.8266 - val_loss: 0.7876 - val_tp: 1569.0000 - val_fp: 3948.0000 - val_tn: 4959.0000 - val_fn: 1410.0000 - val_accuracy: 0.5492 - val_precision: 0.2844 - val_recall: 0.5267 - val_auc: 0.5581 - 29s/epoch - 33ms/step\n",
      "Epoch 6/20\n",
      "879/879 - 27s - loss: 0.4581 - tp: 26309.0000 - fp: 19606.0000 - tn: 60435.0000 - fn: 6115.0000 - accuracy: 0.7713 - precision: 0.5730 - recall: 0.8114 - auc: 0.8641 - val_loss: 0.8215 - val_tp: 1571.0000 - val_fp: 3954.0000 - val_tn: 4953.0000 - val_fn: 1408.0000 - val_accuracy: 0.5489 - val_precision: 0.2843 - val_recall: 0.5274 - val_auc: 0.5575 - 27s/epoch - 30ms/step\n",
      "Epoch 7/20\n",
      "879/879 - 27s - loss: 0.4109 - tp: 27103.0000 - fp: 16927.0000 - tn: 63114.0000 - fn: 5321.0000 - accuracy: 0.8022 - precision: 0.6156 - recall: 0.8359 - auc: 0.8931 - val_loss: 0.8674 - val_tp: 1448.0000 - val_fp: 3820.0000 - val_tn: 5087.0000 - val_fn: 1531.0000 - val_accuracy: 0.5498 - val_precision: 0.2749 - val_recall: 0.4861 - val_auc: 0.5417 - 27s/epoch - 31ms/step\n",
      "Epoch 8/20\n",
      "879/879 - 27s - loss: 0.3699 - tp: 27885.0000 - fp: 15113.0000 - tn: 64928.0000 - fn: 4539.0000 - accuracy: 0.8253 - precision: 0.6485 - recall: 0.8600 - auc: 0.9143 - val_loss: 0.9091 - val_tp: 1335.0000 - val_fp: 3407.0000 - val_tn: 5500.0000 - val_fn: 1644.0000 - val_accuracy: 0.5750 - val_precision: 0.2815 - val_recall: 0.4481 - val_auc: 0.5470 - 27s/epoch - 30ms/step\n",
      "Epoch 9/20\n",
      "879/879 - 26s - loss: 0.3368 - tp: 28253.0000 - fp: 13072.0000 - tn: 66969.0000 - fn: 4171.0000 - accuracy: 0.8467 - precision: 0.6837 - recall: 0.8714 - auc: 0.9298 - val_loss: 0.9346 - val_tp: 1303.0000 - val_fp: 3276.0000 - val_tn: 5631.0000 - val_fn: 1676.0000 - val_accuracy: 0.5834 - val_precision: 0.2846 - val_recall: 0.4374 - val_auc: 0.5491 - 26s/epoch - 29ms/step\n",
      "Epoch 10/20\n",
      "879/879 - 25s - loss: 0.3053 - tp: 28695.0000 - fp: 11621.0000 - tn: 68420.0000 - fn: 3729.0000 - accuracy: 0.8635 - precision: 0.7118 - recall: 0.8850 - auc: 0.9425 - val_loss: 1.0570 - val_tp: 1347.0000 - val_fp: 3458.0000 - val_tn: 5449.0000 - val_fn: 1632.0000 - val_accuracy: 0.5718 - val_precision: 0.2803 - val_recall: 0.4522 - val_auc: 0.5478 - 25s/epoch - 29ms/step\n",
      "Epoch 11/20\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "879/879 - 25s - loss: 0.2825 - tp: 29007.0000 - fp: 10296.0000 - tn: 69745.0000 - fn: 3417.0000 - accuracy: 0.8781 - precision: 0.7380 - recall: 0.8946 - auc: 0.9511 - val_loss: 1.0590 - val_tp: 1247.0000 - val_fp: 3193.0000 - val_tn: 5714.0000 - val_fn: 1732.0000 - val_accuracy: 0.5856 - val_precision: 0.2809 - val_recall: 0.4186 - val_auc: 0.5449 - 25s/epoch - 28ms/step\n",
      "Epoch 11: early stopping\n",
      "Model training finished\n"
     ]
    }
   ],
   "source": [
    "def create_baseline_model():\n",
    "    inputs = create_model_inputs()\n",
    "    features = encode_inputs(inputs)\n",
    "\n",
    "    for units in hidden_units:\n",
    "        features = tf.keras.layers.Dense(units)(features)\n",
    "        features = tf.keras.layers.BatchNormalization()(features)\n",
    "        features = tf.keras.layers.ReLU()(features)\n",
    "        features = tf.keras.layers.Dropout(dropout_rate)(features)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(units=1, activation=\"sigmoid\")(features)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "baseline_model = create_baseline_model()\n",
    "# tf.keras.utils.plot_model(baseline_model, show_shapes=True, rankdir=\"LR\")\n",
    "run_experiment(baseline_model, train_ds, val_ds, test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline_model.save('./stock_selection_base_model')\n",
    "# reloaded_model = tf.keras.models.load_model('./stock_selection_base_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples = df_to_dataset(test_data.iloc[:100, :], shuffle=False, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 4s 20ms/step\n"
     ]
    }
   ],
   "source": [
    "test_labels = []\n",
    "for _, labels in test_ds:\n",
    "    test_labels.extend(labels.numpy())\n",
    "\n",
    "test_predictions = baseline_model.predict(test_ds).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame()\n",
    "test_df['true_label'] = test_labels\n",
    "test_df['prediction'] = test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_label</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5441</th>\n",
       "      <td>1</td>\n",
       "      <td>0.846764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>0</td>\n",
       "      <td>0.793685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5702</th>\n",
       "      <td>0</td>\n",
       "      <td>0.782062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10277</th>\n",
       "      <td>0</td>\n",
       "      <td>0.778084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7699</th>\n",
       "      <td>1</td>\n",
       "      <td>0.776973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8181</th>\n",
       "      <td>1</td>\n",
       "      <td>0.772075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6754</th>\n",
       "      <td>0</td>\n",
       "      <td>0.771943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7842</th>\n",
       "      <td>1</td>\n",
       "      <td>0.766099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6718</th>\n",
       "      <td>0</td>\n",
       "      <td>0.765828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7936</th>\n",
       "      <td>0</td>\n",
       "      <td>0.763873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7487</th>\n",
       "      <td>0</td>\n",
       "      <td>0.762679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11155</th>\n",
       "      <td>1</td>\n",
       "      <td>0.761576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2519</th>\n",
       "      <td>0</td>\n",
       "      <td>0.761016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1</td>\n",
       "      <td>0.757074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6883</th>\n",
       "      <td>1</td>\n",
       "      <td>0.754397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2636</th>\n",
       "      <td>1</td>\n",
       "      <td>0.752272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2087</th>\n",
       "      <td>0</td>\n",
       "      <td>0.751774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4384</th>\n",
       "      <td>1</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4936</th>\n",
       "      <td>0</td>\n",
       "      <td>0.748669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7195</th>\n",
       "      <td>0</td>\n",
       "      <td>0.743114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       true_label  prediction\n",
       "5441            1    0.846764\n",
       "1407            0    0.793685\n",
       "5702            0    0.782062\n",
       "10277           0    0.778084\n",
       "7699            1    0.776973\n",
       "8181            1    0.772075\n",
       "6754            0    0.771943\n",
       "7842            1    0.766099\n",
       "6718            0    0.765828\n",
       "7936            0    0.763873\n",
       "7487            0    0.762679\n",
       "11155           1    0.761576\n",
       "2519            0    0.761016\n",
       "417             1    0.757074\n",
       "6883            1    0.754397\n",
       "2636            1    0.752272\n",
       "2087            0    0.751774\n",
       "4384            1    0.750000\n",
       "4936            0    0.748669\n",
       "7195            0    0.743114"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 预测最高的打分，实际label都不是1\n",
    "test_df.sort_values(by='prediction', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.hist(true_positives_scores, bins=50, alpha=0.5, label='True Positives')\n",
    "# plt.hist(false_positives_scores, bins=50, alpha=0.5, label='False Positives')\n",
    "# plt.xlabel('Scores')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legitimate Transactions Detected (True Negatives):  3647\n",
      "Legitimate Transactions Incorrectly Detected (False Positives):  5345\n",
      "Fraudulent Transactions Missed (False Negatives):  946\n",
      "Fraudulent Transactions Detected (True Positives):  2069\n",
      "Total Fraudulent Transactions:  3015\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_cm(labels, predictions, p=0.5):\n",
    "    cm = confusion_matrix(labels, predictions > p)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "    plt.title('Confusion matrix @{:.2f}'.format(p))\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "    print('Legitimate Transactions Detected (True Negatives): ', cm[0][0])\n",
    "    print('Legitimate Transactions Incorrectly Detected (False Positives): ', cm[0][1])\n",
    "    print('Fraudulent Transactions Missed (False Negatives): ', cm[1][0])\n",
    "    print('Fraudulent Transactions Detected (True Positives): ', cm[1][1])\n",
    "    print('Total Fraudulent Transactions: ', np.sum(cm[1]))\n",
    "\n",
    "plot_cm(test_labels, test_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
