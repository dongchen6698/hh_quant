{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.10\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import akshare as ak\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from tqdm import tqdm\n",
    "\n",
    "from database_auto.db_data_downloader.downloader_base import DownloaderBase\n",
    "import database_auto.database_config as db_config\n",
    "\n",
    "pd.options.display.max_rows=None\n",
    "pd.options.display.max_columns=None\n",
    "\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-31 07:44:05.217454: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-31 07:44:05.997075: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version: 2.13.1\n",
      "TensorFlow GPU version is installed\n",
      "GPU devices available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 只使用CPU进行训练\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "# 打印Tensorflow版本\n",
    "print(f\"Tensorflow Version: {tf.__version__}\")\n",
    "\n",
    "# 检查是否有可用的GPU设备\n",
    "if tf.test.is_built_with_cuda():\n",
    "    print(\"TensorFlow GPU version is installed\")\n",
    "else:\n",
    "    print(\"TensorFlow CPU version is installed\")\n",
    "\n",
    "# 检查TensorFlow是否能够访问GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(\"GPU devices available:\", gpus)\n",
    "else:\n",
    "    print(\"No GPU devices found. Running on CPU.\")\n",
    "\n",
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (12, 10)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "# 绘图相关函数\n",
    "def plot_series_dist(series):\n",
    "    data = series\n",
    "    plt.figure(figsize=(5,5))\n",
    "    # 使用matplotlib画直方图\n",
    "    plt.hist(data, bins=60, edgecolor='k', alpha=0.7)\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Data')\n",
    "    plt.show()\n",
    "\n",
    "def plot_metrics(history):\n",
    "  metrics = ['loss', 'mean_squared_error']\n",
    "  for n, metric in enumerate(metrics):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    plt.subplot(2,2,n+1)\n",
    "    plt.plot(history.epoch, history.history[metric], color=colors[0], label='Train')\n",
    "    plt.plot(history.epoch, history.history['val_'+metric],\n",
    "             color=colors[0], linestyle=\"--\", label='Val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(name)\n",
    "    plt.ylim([0, plt.ylim()[1]])\n",
    "    plt.legend()\n",
    "\n",
    "def plot_cm(true_labels, pred_labels):\n",
    "    cm = confusion_matrix(true_labels, pred_labels)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"g\", cmap='Blues')\n",
    "    plt.title('Confusion matrix')\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, pred_labels)\n",
    "    precision = precision_score(true_labels, pred_labels)\n",
    "    recall = recall_score(true_labels, pred_labels)\n",
    "    print(f\"Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreProcessing:\n",
    "    def __init__(self, db_downloader:DownloaderBase) -> None:\n",
    "        self.db_downloader = db_downloader\n",
    "\n",
    "    def _build_reg_label(self, stock_dataframe, N=15):\n",
    "        stock_df = stock_dataframe.copy()\n",
    "        # 计算未来N日内的最高收益率\n",
    "        stock_df['max_return'] = stock_df['close'].rolling(window=N).max().shift(-N) / stock_df['close'] - 1\n",
    "        # 计算未来N日内的最低收益率\n",
    "        stock_df['min_return'] = stock_df['close'].rolling(window=N).min().shift(-N) / stock_df['close'] - 1\n",
    "        # 计算未来N日内的收益率和（期望最高收益率越高越好，最低收益率也越高越好，由于最低收益率是负数，因此使用最高+最低来作为综合收益指标）\n",
    "        stock_df['return_sum'] = stock_df['max_return'] + stock_df['min_return']\n",
    "        stock_df['label'] = stock_df['return_sum']\n",
    "        # 过滤第二天一字涨停股票\n",
    "        stock_df = stock_df[stock_df['high'].shift(-1) != stock_df['low'].shift(-1)]\n",
    "        return stock_df[['datetime', 'label']]\n",
    "\n",
    "    def _process_one_stock(self, stock_code, start_date, end_date):\n",
    "        stock_history = self.db_downloader._download_history_base_info(stock_code, start_date, end_date)\n",
    "        stock_profile = self.db_downloader._download_all_stock_info(stock_code)\n",
    "        stock_indicator = self.db_downloader._download_history_indicator_info(stock_code, start_date, end_date)\n",
    "        stock_indicator = stock_indicator.replace(\"\", np.NaN).ffill()\n",
    "        stock_factor_date = self.db_downloader._download_history_date_factor_info(start_date, end_date)\n",
    "        stock_factor_alpha158 = self.db_downloader._download_history_alpha184_factor_info(stock_code, start_date, end_date)\n",
    "        stock_label = self._build_reg_label(stock_history)\n",
    "\n",
    "        stock_df = stock_history.merge(stock_profile, on=['code']) \\\n",
    "                .merge(stock_indicator, on=['code', 'datetime']) \\\n",
    "                .merge(stock_factor_alpha158, on=['code', 'datetime']) \\\n",
    "                .merge(stock_factor_date, on=['datetime']) \\\n",
    "                .merge(stock_label, on=['datetime'])\n",
    "        stock_df = stock_df.dropna()\n",
    "        return stock_df\n",
    "\n",
    "    # def _get_index_hist_cons(self, benchmark, start_date, end_date):\n",
    "    #     import baostock as bs\n",
    "    #     bs.login()\n",
    "    #     index_stock_cons_set = set()\n",
    "    #     for cur_date in tqdm(pd.date_range(start=start_date, end=end_date, freq='B')):\n",
    "    #         cur_date = datetime.strftime(cur_date, '%Y-%m-%d')\n",
    "    #         if benchmark == '000016':\n",
    "    #             # print(\"开始处理上证50...\")\n",
    "    #             dataframe = bs.query_sz50_stocks(date=cur_date).get_data()\n",
    "    #         elif benchmark == '000300':\n",
    "    #             # print(\"开始处理沪深300...\")\n",
    "    #             dataframe = bs.query_hs300_stocks(date=cur_date).get_data()\n",
    "    #         elif benchmark == '000905':\n",
    "    #             # print(\"开始处理中证500...\")\n",
    "    #             dataframe = bs.query_zz500_stocks(date=cur_date).get_data()\n",
    "    #         if not dataframe.empty:\n",
    "    #             index_stock_cons_set.update(\n",
    "    #                 dataframe['code'].unique()\n",
    "    #             )\n",
    "    #     bs.logout()\n",
    "    #     return index_stock_cons_set\n",
    "    \n",
    "    def _get_index_latest_cons(self, benchmark):\n",
    "        import baostock as bs\n",
    "        bs.login()\n",
    "        if benchmark == '000016':\n",
    "            dataframe = bs.query_sz50_stocks().get_data()\n",
    "        elif benchmark == '000300':\n",
    "            dataframe = bs.query_hs300_stocks().get_data()\n",
    "        return dataframe['code'].unique()\n",
    "\n",
    "    def _process_all_stock(self, benchmark, start_date, end_date):\n",
    "        # 获取区间内benchmark的所有成份股\n",
    "        # stock_code_list = self._get_index_hist_cons(benchmark, start_date, end_date)\n",
    "        stock_code_list = self._get_index_latest_cons(benchmark)\n",
    "        stock_df_list = []\n",
    "        for stock_code in tqdm(stock_code_list, desc=f'Process: {benchmark} ...'):\n",
    "            stock_df = self._process_one_stock(stock_code, start_date, end_date)\n",
    "            if not stock_df.empty:\n",
    "                stock_df_list.append(stock_df)\n",
    "        return pd.concat(stock_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rolling_data_period(backtest_start_date, backtest_duration=5, train_period=6, val_period=0.5, test_period=0.5):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        backtest_start_date (_type_): _description_\n",
    "        backtest_duration (int, optional): _description_. Defaults to 5.\n",
    "        train_period (int, optional): _description_. Defaults to 6.\n",
    "        val_period (float, optional): _description_. Defaults to 0.5.\n",
    "        test_period (float, optional): _description_. Defaults to 0.5.\n",
    "    Returns:\n",
    "        result: _description_\n",
    "    \"\"\"\n",
    "    backtest_start_date = datetime.strptime(backtest_start_date, '%Y%m%d')\n",
    "    backtest_end_date = backtest_start_date + relativedelta(years=backtest_duration) # 回测5年数据\n",
    "    train_period = relativedelta(years=train_period) # 使用6年的训练数据\n",
    "    val_period = relativedelta(months=(12 * val_period)) # 使用半年的验证数据\n",
    "    test_period = relativedelta(months=(12 * test_period)) # 使用半年的测试数据(半年模型一更新)\n",
    "\n",
    "    result = []\n",
    "    rolling_flag = True\n",
    "    bench_date = backtest_start_date\n",
    "    while rolling_flag:\n",
    "        if bench_date < backtest_end_date:\n",
    "            test_start, test_end = bench_date, (bench_date + test_period - relativedelta(days=1))\n",
    "            val_start, val_end = (test_start - relativedelta(days=1) - val_period), (test_start - relativedelta(days=1))\n",
    "            train_start, train_end =(val_start - relativedelta(days=1) - train_period), (val_start - relativedelta(days=1))\n",
    "            result.append({\n",
    "                \"train\": [train_start.strftime(\"%Y%m%d\"), train_end.strftime(\"%Y%m%d\")],\n",
    "                \"val\": [val_start.strftime(\"%Y%m%d\"), val_end.strftime(\"%Y%m%d\")],\n",
    "                \"test\": [test_start.strftime(\"%Y%m%d\"), test_end.strftime(\"%Y%m%d\")]\n",
    "            })\n",
    "            bench_date += test_period\n",
    "        else:\n",
    "            rolling_flag = False \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_train_val_data(df, train_start_date, train_end_date, val_start_date, val_end_date, test_start_date, test_end_date):\n",
    "    train_start_date = pd.to_datetime(train_start_date)\n",
    "    train_end_date = pd.to_datetime(train_end_date)\n",
    "    val_start_date = pd.to_datetime(val_start_date)\n",
    "    val_end_date = pd.to_datetime(val_end_date)\n",
    "    test_start_date = pd.to_datetime(test_start_date)\n",
    "    test_end_date = pd.to_datetime(test_end_date)\n",
    "\n",
    "    train_data = df[(pd.to_datetime(df['datetime']) >= train_start_date) & (pd.to_datetime(df['datetime']) <= train_end_date)]\n",
    "    val_data = df[(pd.to_datetime(df['datetime']) >= val_start_date) & (pd.to_datetime(df['datetime']) <= val_end_date)]\n",
    "    test_data = df[(pd.to_datetime(df['datetime']) >= test_start_date) & (pd.to_datetime(df['datetime']) <= test_end_date)]\n",
    "\n",
    "    print(f\"train_data_size: {train_data.shape}\")\n",
    "    print(f\"validation_data_size: {val_data.shape}\")\n",
    "    print(f\"test_data_size: {test_data.shape}\")\n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "def df_to_dataset(dataframe, feature_cols, label_cols, shuffle=False, batch_size=32):\n",
    "    features = dataframe[feature_cols]\n",
    "    labels = dataframe[label_cols]\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=min(len(features), 10000), seed=1024)\n",
    "    ds = ds.cache().batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, QuantileTransformer\n",
    "\n",
    "\n",
    "class QuantileClipTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, lower_quantile=0.01, upper_quantile=0.99):\n",
    "        self.lower_quantile = lower_quantile\n",
    "        self.upper_quantile = upper_quantile\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        # 计算给定分位数的分界值\n",
    "        self.lower_bound_ = np.nanquantile(X, self.lower_quantile, axis=0)\n",
    "        self.upper_bound_ = np.nanquantile(X, self.upper_quantile, axis=0)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        # 对整个数组应用剪辑操作\n",
    "        return np.clip(X, self.lower_bound_, self.upper_bound_)\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        return self.fit(X, y).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "关闭滚动回测...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'train': ['2009-01-01', '2016-12-31'],\n",
       "  'val': ['2017-01-01', '2018-12-31'],\n",
       "  'test': ['2019-01-01', '2024-12-31']}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据库初始化\n",
    "db_conn = sqlite3.connect('../database_auto/hh_quant_auto.db')\n",
    "db_downloader = DownloaderBase(db_conn, db_config)\n",
    "proprocessor = PreProcessing(db_downloader=db_downloader)\n",
    "\n",
    "# 相关配置\n",
    "rolling_flag = False\n",
    "# benchmark = '000905'\n",
    "benchmark = '000016'  # 上证50\n",
    "# benchmark = '000300' # 沪深300\n",
    "\n",
    "feature_config = {\n",
    "    \"target_features\": ['label'],\n",
    "    \"numeric_features\": ['turnover_rate', 'pe_ttm', 'ps_ttm', 'pcf_ncf_ttm', 'pb_mrq', 'KMID', 'KLEN', 'KMID2', 'KUP', 'KUP2', 'KLOW', 'KLOW2', 'KSFT', 'KSFT2', 'OPEN0', 'OPEN1', 'OPEN2', 'OPEN3', 'OPEN4', 'HIGH0', 'HIGH1', 'HIGH2', 'HIGH3', 'HIGH4', 'LOW0', 'LOW1', 'LOW2', 'LOW3', 'LOW4', 'CLOSE1', 'CLOSE2', 'CLOSE3', 'CLOSE4', 'VOLUME1', 'VOLUME2', 'VOLUME3', 'VOLUME4', 'ROC5', 'ROC10', 'ROC20', 'ROC30', 'ROC60', 'MAX5', 'MAX10', 'MAX20', 'MAX30', 'MAX60', 'MIN5', 'MIN10', 'MIN20', 'MIN30', 'MIN60', 'MA5', 'MA10', 'MA20', 'MA30', 'MA60', 'STD5', 'STD10', 'STD20', 'STD30', 'STD60', 'BETA5', 'BETA10', 'BETA20', 'BETA30', 'BETA60', 'RSQR5', 'RSQR10', 'RSQR20', 'RSQR30', 'RSQR60', 'RESI5', 'RESI10', 'RESI20', 'RESI30', 'RESI60', 'QTLU5', 'QTLU10', 'QTLU20', 'QTLU30', 'QTLU60', 'QTLD5', 'QTLD10', 'QTLD20', 'QTLD30', 'QTLD60', 'TSRANK5', 'TSRANK10', 'TSRANK20', 'TSRANK30', 'TSRANK60', 'RSV5', 'RSV10', 'RSV20', 'RSV30', 'RSV60', 'IMAX5', 'IMAX10', 'IMAX20', 'IMAX30', 'IMAX60', 'IMIN5', 'IMIN10', 'IMIN20', 'IMIN30', 'IMIN60', 'IMXD5', 'IMXD10', 'IMXD20', 'IMXD30', 'IMXD60', 'CORR5', 'CORR10', 'CORR20', 'CORR30', 'CORR60', 'CORD5', 'CORD10', 'CORD20', 'CORD30', 'CORD60', 'CNTP5', 'CNTP10', 'CNTP20', 'CNTP30', 'CNTP60', 'CNTN5', 'CNTN10', 'CNTN20', 'CNTN30', 'CNTN60', 'CNTD5', 'CNTD10', 'CNTD20', 'CNTD30', 'CNTD60', 'SUMP5', 'SUMP10', 'SUMP20', 'SUMP30', 'SUMP60', 'SUMN5', 'SUMN10', 'SUMN20', 'SUMN30', 'SUMN60', 'SUMD5', 'SUMD10', 'SUMD20', 'SUMD30', 'SUMD60', 'VMA5', 'VMA10', 'VMA20', 'VMA30', 'VMA60', 'VSTD5', 'VSTD10', 'VSTD20', 'VSTD30', 'VSTD60', 'WVMA5', 'WVMA10', 'WVMA20', 'WVMA30', 'WVMA60', 'VSUMP5', 'VSUMP10', 'VSUMP20', 'VSUMP30', 'VSUMP60', 'VSUMN5', 'VSUMN10', 'VSUMN20', 'VSUMN30', 'VSUMN60', 'VSUMD5', 'VSUMD10', 'VSUMD20', 'VSUMD30', 'VSUMD60'],\n",
    "    \"integer_categorical_features\": ['month'],\n",
    "    \"string_categorical_features\": ['industry', 'season'],\n",
    "}\n",
    "batch_size = 1024\n",
    "\n",
    "# 是否开启滚动训练&回测\n",
    "if rolling_flag:\n",
    "    print(\"开启滚动回测...\")\n",
    "    backtest_period = get_rolling_data_period(\n",
    "        backtest_start_date='20200101', # 回测开始日期\n",
    "        backtest_duration=4, # 一共回测多久的数据（单位：年）\n",
    "        train_period=6, # 使用过去多久的时间进行训练（单位：年）\n",
    "        val_period=1, # 验证数据周期（单位：年）\n",
    "        test_period=1, # 测试数据周期（单位：年）\n",
    "    )\n",
    "else:\n",
    "    print(\"关闭滚动回测...\")\n",
    "    backtest_period = [\n",
    "        {\n",
    "            'train': ['2009-01-01', '2016-12-31'], # 8年训练\n",
    "            'val': ['2017-01-01', '2018-12-31'], # 2年验证\n",
    "            'test': ['2019-01-01', '2024-12-31'] # 5年+预测\n",
    "        }\n",
    "    ]\n",
    "\n",
    "backtest_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = proprocessor._process_all_stock('000016', '2024-01-01', '2024-12-31')\n",
    "# df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': ['2009-01-01', '2016-12-31'], 'val': ['2017-01-01', '2018-12-31'], 'test': ['2019-01-01', '2024-12-31']}\n",
      "开始加载原始数据...\n",
      "login success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process: 000016 ...: 100%|██████████| 50/50 [00:08<00:00,  6.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始拆分训练、验证、测试集合...\n",
      "train_data_size: (50924, 204)\n",
      "validation_data_size: (18461, 204)\n",
      "test_data_size: (59552, 204)\n",
      "开始抽取特征数据...\n",
      "开始对特征进行预处理...\n",
      "开始对标签进行预处理...\n"
     ]
    }
   ],
   "source": [
    "date_period_params = backtest_period[0]\n",
    "print(date_period_params)\n",
    "train_start_date, train_end_date = date_period_params['train']\n",
    "val_start_date, val_end_date = date_period_params['val']\n",
    "test_start_date, test_end_date = date_period_params['test']\n",
    "# 获取全区间数据\n",
    "print(\"开始加载原始数据...\")\n",
    "df = proprocessor._process_all_stock(benchmark=benchmark, start_date=train_start_date, end_date=test_end_date)\n",
    "# 抽取训练验证数据\n",
    "print(\"开始拆分训练、验证、测试集合...\")\n",
    "train_data, val_data, test_data = extract_train_val_data(df, *[train_start_date, train_end_date, val_start_date, val_end_date, test_start_date, test_end_date])\n",
    "# 从data中抽取相关特征数据\n",
    "print(\"开始抽取特征数据...\")\n",
    "feature_columns = feature_config.get('numeric_features', []) + feature_config.get('integer_categorical_features', []) + feature_config.get('string_categorical_features', [])\n",
    "label_columns = feature_config.get('target_features', [])\n",
    "full_feature_columns = feature_columns + label_columns\n",
    "train_df, val_df, test_df = train_data[full_feature_columns], val_data[full_feature_columns], test_data[full_feature_columns]\n",
    "# 对相关特征进行特征工程\n",
    "print(\"开始对特征进行预处理...\")\n",
    "feature_preprocess_pipeline = Pipeline(steps=[\n",
    "    ('robust_scaler', RobustScaler()),\n",
    "    # ('quantile_transformer', QuantileTransformer(n_quantiles=5000, output_distribution='uniform', random_state=42)),\n",
    "    ('minmax_scaler', MinMaxScaler()),\n",
    "])\n",
    "preprocess_feature_columns = feature_config.get('numeric_features', [])\n",
    "train_df[preprocess_feature_columns] = feature_preprocess_pipeline.fit_transform(train_df[preprocess_feature_columns])\n",
    "val_df[preprocess_feature_columns] = feature_preprocess_pipeline.transform(val_df[preprocess_feature_columns])\n",
    "test_df[preprocess_feature_columns] = feature_preprocess_pipeline.transform(test_df[preprocess_feature_columns])\n",
    "\n",
    "print(\"开始对标签进行预处理...\")\n",
    "label_preprocess_pipeline = Pipeline(steps=[\n",
    "    ('quantile_clipper', QuantileClipTransformer()),\n",
    "    ('robust_scaler', RobustScaler()),\n",
    "    # ('quantile_transformer', QuantileTransformer(n_quantiles=1000, output_distribution='normal', random_state=42)),\n",
    "    ('minmax_scaler', MinMaxScaler()),\n",
    "])\n",
    "preprocess_target_columns = feature_config.get('target_features', [])\n",
    "train_df[preprocess_target_columns] = label_preprocess_pipeline.fit_transform(train_df[preprocess_target_columns])\n",
    "val_df[preprocess_target_columns] = label_preprocess_pipeline.transform(val_df[preprocess_target_columns])\n",
    "test_df[preprocess_target_columns] = label_preprocess_pipeline.transform(test_df[preprocess_target_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdcAAAHWCAYAAAAl2MNkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA9TUlEQVR4nO3de3zP9f//8fvGDjYz5DBUEuGTw0TFIgpTUukgKZ8y9CmVT0gRP6eOPpVDwodizTkqqRwnWQ619Gm+H60cPsghYxttZufN3s/fH328P942h7295n3Y7Xq5PC95P1/P92uP1yvt3uv0fPlIMgIAAJbxdXUBAAB4G8IVAACLEa4AAFiMcAUAwGKEKwAAFiNcAQCwGOEKAIDFCFcAACxGuAIAYDHCFXDCgQMHFBMT4+oyvN5LL72k/fv36/Tp0/q///s/V5cDXDLCFeVev379ZIxRmzZtSlweFxenxMTEy/453bt31/jx4y97PeVFZGSk3n33XX333Xfq37+/Ro8efd6xMTExMsbYW2Zmpvbv369PP/1UDz30kHx8fJyu47HHHtOQIUOc/j7Kp4quLgDwRE2aNJHNZivVd+655x4NHjxYr776ahlV5V06d+6soqIiDRw4UIWFhRcdn5eXp6eeekqSVKlSJdWvX1/33Xefli9frri4OPXs2VOZmZmlruPxxx9X8+bNNW3atFJ/F+UX4Qo4oaCgwNUllFpQUJBycnJcXcYlq1WrlnJzcy8pWCXp9OnTWrx4sUPf2LFjNXLkSP3jH//QnDlz1KdPn7IoFSiRodHKc+vXr58xxpg2bdqUuDwuLs4kJiY69B04cMDExMTYP1esWNGMGzfO/Oc//zG5ubnmxIkTZsuWLaZr165GkomJiTElOfP9oKAgM2nSJHP48GGTl5dndu/ebYYPH16slsDAQDNt2jRz/Phxc+rUKfPll1+aunXrGmOMGT9+vH3c+PHjjTHG/OUvfzGLFy82aWlpZvv27UaSadGihYmJiTH79+83ubm55tixYyY6OtpUr17d4WedWccNN9xgFi5caE6ePGlSU1PNa6+9ZiSZq6++2nzxxRcmIyPDHDt2zLz44ouXtL8rVKhgxowZY/bt22fy8vLMgQMHzJtvvmn8/f3tY0rSr1+/864zJibGZGZmnnf5unXrTFFRkbnhhhvsfffff79ZtWqVSUpKMnl5eWbfvn1mzJgxxtfX1+Hf/bkOHDhgJBk/Pz/z6quvmp9++smcPHnSZGVlmc2bN5s77rjD5X+naa5vHLkC/xUaGqqrrrqqWL+fn99FvzthwgSNGjVKc+fO1Y8//qgqVaro5ptvVuvWrbVhwwZ98MEHqlu3rrp166a//vWvxb7/1Vdf6c4771R0dLT+/e9/66677tKkSZNUr149vfjii/Zx8+bN06OPPqoFCxbohx9+UKdOnbR69erz1vXpp59q7969Gj16tP26Y2RkpK6//nrFxMQoOTlZzZo109NPP61mzZqpXbt2xdaxbNky7dq1S6+88op69OihsWPHKi0tTc8884w2btyokSNHqm/fvpo8ebL+9a9/acuWLRfcV3PnzlVUVJQ+/fRTTZ48WW3bttXo0aP1l7/8RQ899JAk6a9//auefvpp3XrrrfZTvd9///1F/z2cz8KFC3XXXXcpMjJSe/fulSRFRUUpKytLU6ZMUVZWljp37qzXX39dVapU0YgRIyRJb775pkJDQ3X11Vdr2LBhkqSsrCxJUpUqVfTUU0/p448/1pw5cxQSEqKBAwcqNjZWt956q3bs2OF0vfAOLk94Gs2V7cyR64Vc7Mj1//7v/8zKlSsv+HOmT5/ucLR6pt1///3GGGNGjx7t0P/JJ5+YoqIic/311xtJ5qabbjLGGDNlyhSHcR999NF5j1wXL15c7OcFBgYW63v00UeNMcZ06NCh2Dpmz55t7/P19TWHDx82RUVFZsSIEfb+0NBQk52d7bBPSmotW7Y0xhjz4YcfOvS/8847xhjjcNR3saPRs9vFxoaHhxtjjJk8efIF98OsWbNMVlaWw1H0ypUr7UerZzdfX1/j5+fn0BcaGmqOHTtm5s6d6/K/1zTXNu4WBv7rueeeU9euXYu1SzkCOXnypJo1a6ZGjRqV+ufec889On36tN5//32H/smTJ8vX11fdu3eXJN19992SpH/+858O46ZPn37edc+ePbtYX15env3PAQEBuuqqq/TDDz9Iklq3bl1s/Ny5c+1/ttls+umnn+Tr66vo6Gh7f0ZGhvbs2aPrr7/+vLVIf26rJE2ZMsWhf/LkyZKkHj16XPD7zjpztBkSEmLvO3s/VK5cWVdddZW2bNmi4OBgNW3a9KLrtNls9uvBPj4+qlatmipWrKiffvqpxP2I8oXTwsB//fjjj0pISCjWn56erho1alzwu+PGjdOXX36pvXv3KjExUevWrdPChQsv6RGe+vXr6+jRo/YAOGPXrl325Wf+WVRUpAMHDjiM27dv33nXfe5YSapWrZrGjx+vPn36qHbt2g7LQkNDi40/fPiww+eMjAzl5ubqjz/+KNZf0mn1s53ZhnNrTklJUXp6un1brVa5cmVJcrhb+MYbb9Qbb7yhzp07F9vukvZDSZ588kkNHz5cTZs2lb+/v73/t99+s6BqeDKOXAELbNmyRQ0bNlT//v31yy+/6KmnntL27ds1cOBAl9aVm5tbrO+TTz7R3/72N82ePVsPPvigIiMjddddd0mSfH2L/0ooKiq6pD5Jl/w86Z9nx6+c5s2bS/rf/4iEhoZq06ZNCg8P17hx43Tvvfeqa9eu9mutJe2Hc/Xt21fz58/X/v37NXDgQN11113q2rWrvvnmm0v6PrwbR66ARdLT0zVv3jzNmzdPwcHB2rx5syZMmGA/fXq+QDl06JC6du2qypUrOxy9njk1eejQIfs/K1SooAYNGjgc+ZXmVHTVqlXVtWtXjRs3Tq+//rpT67gcZ7bhhhtu0O7du+39tWrVUrVq1ezbarUnnnhCNptNX3/9tSTpjjvuUI0aNfTQQw853IDVoEGDYt8937+3Xr16af/+/fabsM7gOWZIHLkClqhevbrD5+zsbO3bt08BAQEOfVLxU45r1qxRxYoVNXjwYIf+YcOGyWazae3atZKk2NhYSX9eGz7b3//+90uu88wR57lHmEOHDr3kdVyONWvWlPjzztwRfaE7n501cuRI3XXXXVq2bJn9f0pK2g9+fn7F9q3057+3kk4Tl7SOW2+9VREREZbWD8/EkStggZ07d+rbb79VQkKC0tLSdPPNN6tXr16aMWOGfcyZ67nvv/++YmNjVVRUpGXLlmnlypXauHGj3nzzTV133XXasWOHunXrpgceeEBTp061X7/bvn27PvvsMw0bNsx+E1KnTp3UuHFjSZd2qjUzM1ObNm3SiBEj5Ofnp6SkJHXr1q3EI7ay8PPPP2vevHl65plnVLVqVW3atEm33nqroqKitGLFCn377bdOr7tixYrq27evJCkwMFD169fX/fffr/DwcG3cuFFPP/20fez333+vtLQ0zZ8/X++//76MMXriiSdKPK2dkJCgPn362B81ysrK0qpVq7Rq1So9/PDDWrFihVavXq0GDRpo0KBB2rlzp/0aL8o3l9+yTKO5slkxicTo0aPNDz/8YNLS0kx2drbZuXOnGTVqlKlYsaJ9jK+vr5k2bZpJSUkxRUVFDo/lBAcHm8mTJ5sjR46Y/Px8s2fPnhInkahUqZKZPn26OXHihDl16pT5/PPPzQ033GCMMQ6Pxpx5jOaqq64qto66deua5cuXm7S0NJOenm6WLVtmwsLCzvs4z7nrON9jLyXtp5JahQoVzNixY83+/ftNfn6+OXToULFJJC70c0pq507SkZWVZX777Tfz6aefmoceesj4+PgU+05ERIT5/vvvTXZ2tjly5Ij5xz/+YSIjI40xxnTq1Mk+LigoyCxatMikpaU5TCIhybzyyivmwIEDJjc31yQkJJh77rnHxMTElPjoDq18NZ///gGAhwoPD9e///1v9e3bV0uWLHF1OQDENVfAowQGBhbrGzp0qIqKirR582YXVASgJFxzBTzIiBEj1KZNG8XFxen06dPq3r277rnnHn3wwQc6cuSIq8sDcBaXn5um0WiX1rp27Wq2bNli/vjjD5Ofn2/27t1rxo0bZypUqODy2mg02v8a11wBALAY11wBALAY4QoAgMW4oekS1a1b12HSbwBA+RQSEqKjR49ecAzhegnq1q2rpKQkV5cBAHAT9erVu2DAEq6X4MwRa7169Th6BYByLCQkRElJSRfNAsK1FDIzMwlXAMBFcUMTAAAWI1wBALAY4QoAgMUIVwAALEa4AgBgMcIVAACLEa4AAFiMcAUAwGKEKwAAFiNcAQCwGOEKAIDFCFcAACxGuAIAYDHCFQAAixGuAABYjPe5Am4ioHKwAoIqFevPz8lVfla2CyoC4CzCFXATAUGV1L5PLwVXDbX3ZZ/M0HdLPyNcAQ9DuAJuJLhqqKrUrOHqMgBcJq65AgBgMcIVAACLEa4AAFiMcAUAwGKEKwAAFiNcAQCwGOEKuDmbzebqEgCUEs+5Am4sPztHpsimKrWKP/vKzE2A+yJcATdWmJ8v/0qBatfrAWZuAjwI4Qp4gJJmbuJ0MeC+CFfAA3G6GHBvhCvggThdDLg3whXwYEz0D7gnlz6K88orr+jHH3/UqVOnlJKSohUrVqhx48YOY+Li4mSMcWizZs1yGHPNNddo1apVys7OVkpKit555x1VqFDBYUynTp2UkJCgvLw87d27V/369Svz7QMAlE8uDddOnTpp5syZateunSIjI+Xn56f169crKCjIYdyHH36osLAwexsxYoR9ma+vr1avXi1/f3/ddttt6tevn6KiovTaa6/Zx1x33XVavXq14uLi1KpVK7333nuaO3euunXrdsW2FQBQfrj0tHD37t0dPkdFRen48eNq06aNtmzZYu/PyclRSkpKievo1q2bbrzxRnXt2lWpqanasWOHxo4dq7ffflsTJkxQYWGhBg0apAMHDuill16SJO3evVsdOnTQsGHDtH79+rLbQABAueRWMzSFhv55Y0ZaWppDf9++fXX8+HElJibqrbfeUqVKlezLIiIilJiYqNTUVHtfbGysQkND1axZM/uYDRs2OKwzNjZWERERJdbh7++vkJAQhwYAwKVymxuafHx89N5772nr1q369ddf7f1LlizRoUOHdPToUbVs2VJvv/22mjRpoocffliSFBYWVuyo9sznsLCwC44JDQ1VYGCg8vLyHJaNGjVKEyZMsHoTAQDlhNuE68yZM9W8eXN16NDBoX/OnDn2P//yyy86duyYNm7cqOuvv16//fZbmdQyceJETZkyxf45JCRESUlJZfKzAADexy1OC0+fPl333nuv7rzzzouG2LZt2yRJjRo1kiQlJyerdu3aDmPOfE5OTr7gmIyMjGJHrZJUUFCgzMxMhwYAwKVyebhOnz5dDz74oDp37qyDBw9edHyrVq0kSceOHZMkxcfHq0WLFqpZs6Z9TGRkpDIyMrRz5077mC5dujisJzIyUvHx8dZsBAAAZ3FpuM6cOVN//etf9fjjjyszM1O1a9dW7dq1FRgYKEm6/vrrNWbMGLVu3Vr169fXfffdpwULFmjTpk1KTEyUJK1fv147d+7UwoUL1bJlS3Xr1k1vvPGGZs6cqYKCAknS7Nmzdf3119uv1z777LPq3bu3pk6d6rJtB8oKcw4DrufSa67PPfecJGnTpk0O/VFRUZo/f74KCgrUtWtXDR06VMHBwfr999+1fPlyvfHGG/axNptN9957r2bNmqX4+HhlZ2dr/vz5GjdunH3MwYMH1aNHD02dOlVDhgzRkSNH9NRTT/EYDrwOcw4D7sGl4erj43PB5UeOHNEdd9xx0fUcPnxYPXr0uOCYTZs2qXXr1qUpD/A4zDkMuAe3uVsYgHWYcxhwLZff0AQAgLchXAEAsBjhCgCAxQhXAAAsRrgCAGAxwhUAAIsRrgAAWIznXIErLKBysAKCKjn02U4Xyde3gosqAmA1whW4wgKCKql9n14OMyilHjysxA1xLqwKgJUIV8AFzp1BKSst3YXVALAa11wBALAYR65AGeHaKlB+Ea5AGeHaKlB+Ea5AGeLaKlA+cc0VAACLEa4AAFiMcAUAwGKEKwAAFiNcAQCwGOEKAIDFCFcAACxGuAIAYDHCFQAAixGuAABYjHAFAMBihCsAABYjXAEAsBjhCgCAxQhXAAAsRrgCAGAxwhUAAIsRrgAAWIxwBQDAYoQrUE7YbDZXlwCUGxVdXQCAspefnSNTZFOVWjUc+3NylZ+V7aKqAO9FuALlQGF+vvwrBapdrwcUXDVUkpR9MkPfLf2McAXKAOEKlCPBVUNVpWaNiw8EcFm45goAgMUIVwAALEa4AgBgMcIVAACLEa4AAFiMcAUAwGKEKwAAFiNcAQCwGOEKAIDFCFcAACxGuAIAYDHmFgYuU0DlYAUEVXLos50ukq9vBRdVBMDVCFfgMgUEVVL7Pr3sb5uRpNSDh5W4Ic6FVQFwJcIVsMC5b5vJSkt3YTUAXI1rrgAAWIxwBQDAYoQrAAAWI1wBALAY4QoAgMUIVwAALObScH3llVf0448/6tSpU0pJSdGKFSvUuHFjhzEBAQGaMWOGTpw4oczMTH322WeqVauWw5hrrrlGq1atUnZ2tlJSUvTOO++oQgXHB/g7deqkhIQE5eXlae/everXr1+Zbx8AoHxyabh26tRJM2fOVLt27RQZGSk/Pz+tX79eQUFB9jFTp07Vfffdp0ceeUSdOnVS3bp19fnnn9uX+/r6avXq1fL399dtt92mfv36KSoqSq+99pp9zHXXXafVq1crLi5OrVq10nvvvae5c+eqW7duV3R7AQDlg0snkejevbvD56ioKB0/flxt2rTRli1bVKVKFQ0cOFCPP/644uL+nO2mf//+2r17t9q2batt27apW7duuvHGG9W1a1elpqZqx44dGjt2rN5++21NmDBBhYWFGjRokA4cOKCXXnpJkrR792516NBBw4YN0/r166/4dgMAvJtbXXMNDf1z+ri0tDRJUps2beTv768NGzbYx+zZs0eHDh1SRESEJCkiIkKJiYlKTU21j4mNjVVoaKiaNWtmH3P2Os6MObOOc/n7+yskJMShAQBwqdwmXH18fPTee+9p69at+vXXXyVJYWFhys/PV0ZGhsPYlJQUhYWF2cekpKQUW35m2YXGhIaGKjAwsFgto0aN0qlTp+wtKSnJmo0EAJQLbhOuM2fOVPPmzdWnTx9Xl6KJEyeqSpUq9lavXj1XlwQA8CBuMXH/9OnTde+996pjx44OR4nJyckKCAhQaGiow9Fr7dq1lZycbB9z6623Oqyvdu3a9mVn/nmm7+wxGRkZysvLK1ZPQUGBCgoKrNk4wI3ZbDZXlwB4JZcfuU6fPl0PPvigOnfurIMHDzosS0hIUEFBgbp06WLva9y4serXr6/4+HhJUnx8vFq0aKGaNWvax0RGRiojI0M7d+60jzl7HWfGnFkHUB7lZ+fIFNlUpVaNYi2gcrCrywM8mkuPXGfOnKnHH39cPXv2VGZmpv3o8swR5alTpxQdHa0pU6YoLS1Np06d0vTp0/X9999r27ZtkqT169dr586dWrhwoUaMGKGwsDC98cYbmjlzpv3oc/bs2Ro8eLDefvttffTRR+rcubN69+6tHj16uGzbAVcrzM+Xf6VAtev1gMO7aLNPZui7pZ8pPyvbhdUBns2l4frcc89JkjZt2uTQHxUVpfnz50uShg0bJpvNpuXLlysgIECxsbH270l/nta69957NWvWLMXHxys7O1vz58/XuHHj7GMOHjyoHj16aOrUqRoyZIiOHDmip556isdwABV/Fy2Ay+fScPXx8bnomPz8fA0ePFiDBw8+75jDhw9f9Ch006ZNat26dalrBACgtFx+zRUAAG9DuAIAYDHCFQAAixGuAABYjHAFAMBihCsAABYjXAEAsJhbzC0MeIqAysEKCKpk/2w7XSRf3wourAiAOyJcgVIICKqk9n162acLTD14WIkb4lxcFQB3Q7gCpXT2dIFZaekurgaAO+KaKwAAFiNcAQCwGOEKAIDFCFcAACxGuAIAYDHCFQAAixGuAABYjHAFAMBihCsAABYjXAEAsBjhCqAYm83m6hIAj8bcwgAc5GfnyBTZVKVWjeLLcnKVn5XtgqoAz0K4AnBQmJ8v/0qBatfrAfvbfyQp+2SGvlv6GeEKXALCFUCJzn77D4DS4ZorAAAWI1wBALAY4QoAgMUIVwAALEa4AgBgMcIVAACLEa4AAFiMcAUAwGKEKwAAFiNcAQCwGOEKAIDFCFcAACxGuAIAYDHCFQAAixGuAABYjHAFAMBihCsAABar6OoCAHcUUDlYAUGVHPpsp4vk61vBRRUB8CSEK1CCgKBKat+nl4Krhtr7Ug8eVuKGOBdWBcBTEK7AeQRXDVWVmjXsn7PS0l1YDQBPwjVXAAAsRrgCAGAxp8K1QYMGVtcBAIDXcCpc9+3bp40bN6pv374KCAiwuiYAADyaU+HaunVr/fzzz5oyZYqSk5M1e/Zs3XLLLVbXBgCAR3IqXHfs2KGhQ4eqbt26GjBggOrUqaOtW7cqMTFRw4YNU40aNS6+EgAAvNRl3dBUVFSkFStW6JFHHtHIkSPVqFEjTZo0Sb///rvmz5+vsLAwq+oEAMBjXFa4tmnTRjNnztSxY8f04osvatKkSWrYsKEiIyNVt25dffnll1bVCQCAx3BqEolhw4apf//+atKkidasWaMnn3xSa9askTFGknTw4EFFRUXp4MGDVtYKAIBHcCpcn332WX300UeaN2+ekpOTSxyTmpqqgQMHXlZxAAB4IqfCtXHjxhcdU1hYqAULFjizegAAPJpT11yjoqLUq1evYv29evXSk08+edlFAQDgyZwK11GjRunEiRPF+lNTUzV69OjLLgoAAE/mVLhee+21OnDgQLH+Q4cO6dprr73sogC4J5vN5uoSAI/g1DXX1NRUtWzZUocOHXLoDw8P1x9//GFJYQDcS352jkyRTVVqFZ8kJj8nV/lZ2S6oCnBPTh25fvzxx3r//fd1xx13yNfXV76+vrrzzjs1bdo0LV269JLXc/vtt+urr75SUlKSjDHq2bOnw/KYmBgZYxza2rVrHcZUq1ZNixYtUkZGhtLT0zV37lwFBwc7jGnRooU2b96s3NxcHT58WC+//LIzmw2Ua4X5+fKvFKj2fXqp26CB9ta+Ty8FBFVydXmAW3HqyHXs2LG67rrr9M033+j06dOSJF9fXy1YsKBU11yDg4O1Y8cOffTRR1qxYkWJY9auXav+/fvbP+fn5zssX7x4serUqaPIyEj5+fkpJiZGH374ofr27StJCgkJ0fr167VhwwYNGjRILVq00EcffaSTJ09qzpw5pd10oNw79yXyAIpzKlwLCwvVp08fjR07VuHh4crNzVViYqIOHz5cqvWsW7dO69atu+CY/Px8paSklLisadOm6t69u26++WYlJCRIkv7+979rzZo1eumll3Ts2DH17dtX/v7+GjBggAoLC7Vz5061atVKL774IuEKBVQOLnbUZTtdJF/fCi6qCIA3cCpcz9i7d6/27t1rVS0luuOOO5SSkqL09HRt3LhRY8aMUVpamiQpIiJC6enp9mCVpA0bNshms6lt27b64osvFBERoc2bN6uwsNA+JjY2Vq+88oqqVq2qkydPFvuZ/v7+Dq/SCwkJKbsNhEsFBFVS+z69FFw11N6XevCwEjfEubAqAJ7OqXD19fVVVFSUunTpolq1asnX1/HSbZcuXSwpbt26dfr888914MABNWzYUG+99ZbWrl2riIgI2Ww2hYWFKTU11eE7RUVFSktLs780ICwsrNidzWeOhMPCwkoM11GjRmnChAmWbAPc37mnObPS0l1YDQBv4FS4Tps2TVFRUVq9erV++eUX+5zCVlu2bJn9z7/88ot+/vln/fbbb7rjjju0cePGMvmZkjRx4kRNmTLF/jkkJERJSUll9vMAAN7FqXDt06ePevfuXezO3bJ24MABHT9+XI0aNdLGjRuVnJysWrVqOYypUKGCqlevbp/zODk5WbVr13YYc+bz+eZFLigoUEFBQRlsAQCgPHDqUZyCggLt27fP6louql69errqqqt07NgxSVJ8fLyqVaum1q1b28d07txZvr6+2rZtm31Mx44dVbHi//4/IjIyUrt37y7xlDAAAJfLqXCdPHmyhgwZctk/PDg4WOHh4QoPD5ckNWjQQOHh4brmmmsUHBysd955R23btlX9+vXVuXNnffnll9q3b59iY2MlSbt379batWs1Z84c3XLLLbrttts0Y8YMLV261B7AS5YsUUFBgaKjo3XjjTeqd+/eGjJkiMNpXwAArOTUaeEOHTrozjvvVPfu3fXrr7863IkrSQ8//PAlrefmm2/Wt99+a/88depUSdK8efP07LPPqmXLlurXr5+qVq2qo0ePav369Ro7dqzDKdu+fftqxowZ+uabb2Sz2bR8+XK98MIL9uWnTp1St27dNHPmTCUkJOjEiRN67bXXeAwHAFBmnArXkydPnnfSh9LYtGmTfHx8zrv87rvvvug60tPT7RNGnE9iYqI6duxY6voAAHCGU+E6YMAAq+sAAMBrOHXNVfrzrtwuXbro6aefVuXKlSVJderUKTavLwAA5Y1TR67XXnut1q1bp2uvvVYBAQH6+uuvlZWVpZEjRyogIEDPPvus1XUCAOAxnDpynTZtmn766SdVq1ZNubm59v4VK1ZYNjsTAACeyqkj19tvv1233XZbsbuEDx48qHr16llSGADPwUvUAUdOzy1coULxt4ZcffXVyszMvOyiAHgOXqIOFOdUuK5fv15Dhw7VM888I0kyxig4OFivvvqq1qxZY2mBANzbmZeot+v1gMPbhbJPZui7pZ8RriiXnArX4cOHKzY2Vr/++qsCAwO1ZMkS3XDDDTpx4oQee+wxq2sE4AF4iTrwP06Fa1JSksLDw9WnTx+1bNlSlStXVnR0tBYvXqy8vDyrawQAwKM4/bL0oqIiLV68WIsXL7ayHgAAPJ5T4frEE09ccPnChQudKgYAAG/g9MvSz+bn56egoCAVFBQoJyeHcAUAlGtOTSJRvXp1hxYSEqImTZpo69at3NAEACj3nJ5b+Fz79u3TK6+8UuyoFgCA8sbpG5pKcvr0adWtW9fKVQKWCKgcrICgSg59ttNF8vUtPhkKAFwup8L1vvvuc/js4+OjOnXqaPDgwfruu+8sKQywUkBQJbXv08thkoPUg4eVuCHOhVUB8FZOhesXX3zh8NkYo+PHj2vjxo0aPny4FXUBljt3koOstHQXVgPAmzkVriXNKwwAAP5k2Q1NAADgT04duU6ePPmSx3KaGABQ3jgVrjfddJNuuukm+fn5ac+ePZKkxo0bq6ioSNu3b7ePM8ZYUyUAAB7EqXBduXKlMjMz1a9fP508eVKSVLVqVcXExGjLli2aMmWKlTUCAOBRnLrmOnz4cI0aNcoerJJ08uRJjRkzhtPAAIByz6lwrVKlimrWrFmsv2bNmgoJCbnsogB4B5vN5uoSAJdw6rTwihUrFBMTo+HDh+vHH3+UJLVt21bvvvuuPv/8c0sLBOCZ8rNzZIpsqlKr+AvU83NylZ+V7YKqgCvDqXAdNGiQJk2apCVLlsjPz0/Sn1MfRkdH6+WXX7a0QACeqTA/X/6VAtWu1wMOM2Nln8zQd0s/I1zh1ZwK19zcXD3//PN6+eWX1bBhQ0nS/v37lZOTY2lxADzfuTNjAeXBZU0iUadOHdWpU0d79+4lWAEA+C+n3+e6YcMG/ec//9GaNWtUp04dSVJ0dLQmTZpkaYEAAHgap8J16tSpKiws1LXXXutwxLps2TLdfffdlhUHAIAncuqaa7du3XTXXXcpKSnJoX/v3r2qX7++JYUBAOCpnDpyDQ4OLvEaa/Xq1ZWfn3/ZRQEA4MmcCtctW7boySeftH82xsjHx0cjRoxQXBwvnwYAlG9OnRYeMWKEvvnmG918883y9/fXO++8o2bNmql69epq37691TUCAOBRnDpy/fXXX9W4cWNt3bpVX375pYKDg/X555/rpptu0m+//WZ1jQAAeJRSH7lWrFhR69at06BBg/TWW2+VRU0AAHi0Uh+5nj59Wi1btiyLWgAA8ApOnRZetGiRBg4caHUtAAB4BaduaKpYsaIGDBigrl27KiEhQdnZjhNw805XAEB5VqpwbdCggQ4ePKjmzZtr+/btkqTGjRs7jDHGWFcdAAAeqFThunfvXtWpU0edO3eWJC1dulQvvPCCUlNTy6Q4oLQCKgcrIKiSQ5/tdJF8fSu4qCIA5VGpwtXHx8fhc/fu3RUcHGxpQcDlCAiqpPZ9ejm8PzT14GElbmByEwBXjlPXXM84N2wBd3Du+0Oz0tJdWA2A8qhUdwsbY4pdU+UaKwAAjkp9WnjevHn2yfkDAwM1e/bsYncLP/zww9ZVCACAhylVuM6fP9/h86JFiywtBgAAb1CqcB0wYEBZ1QEAgNdwaoYmAABwfoQrAAAWI1wBALAY4QoAgMUIVwAALEa4ArjibDabq0sAytRlTX8IAKWVn50jU2RTlVo1ii/LyVV+VnYJ3wI8C+EK4IoqzM+Xf6VAtev1gMMLFrJPZui7pZ8RrvAKhCsAlzj3BQuAN+GaKwAAFiNcAQCwmEvD9fbbb9dXX32lpKQkGWPUs2fPYmNeffVVHT16VDk5Ofr666/VqFEjh+XVqlXTokWLlJGRofT0dM2dO7fYC9xbtGihzZs3Kzc3V4cPH9bLL79cptsFACjfXBquwcHB2rFjh55//vkSl48YMUIvvPCCBg0apLZt2yo7O1uxsbEKCAiwj1m8eLGaNWumyMhI3XvvverYsaM+/PBD+/KQkBCtX79ehw4dUps2bfTyyy9rwoQJ+tvf/lbm2wcAKJ9cekPTunXrtG7duvMuHzp0qN544w199dVXkqQnn3xSKSkpeuCBB7Rs2TI1bdpU3bt3180336yEhARJ0t///netWbNGL730ko4dO6a+ffvK399fAwYMUGFhoXbu3KlWrVrpxRdf1Jw5c67IdgIAyhe3vebaoEED1alTRxs2bLD3nTp1Stu2bVNERIQkKSIiQunp6fZglaQNGzbIZrOpbdu29jGbN29WYWGhfUxsbKyaNm2qqlWrlviz/f39FRIS4tAAlD0ml4C3cNtwDQsLkySlpKQ49KekpNiXhYWFKTU11WF5UVGR0tLSHMaUtI6zf8a5Ro0apVOnTtlbUlLS5W8QgAs6e3KJc1tA5eCLrwBwIzznWoKJEydqypQp9s8hISEErJsJqBysgKBKDn2200Xy9a3goopwuZhcAt7EbcM1OTlZklS7dm37n898/ve//20fU6tWLYfvVahQQdWrV7d/Jzk5WbVr13YYc+bz2es9W0FBgQoKCizZDpSNgKBKat+nl8Mv4dSDh5W4Ic6FVcEKTC4Bb+C2p4UPHDigY8eOqUuXLva+kJAQtW3bVvHx8ZKk+Ph4VatWTa1bt7aP6dy5s3x9fbVt2zb7mI4dO6pixf/9f0RkZKR2796tkydPXpmNQZk480v4TAuqwrVxAO7B5Y/ihIeHKzw8XNKfNzGFh4frmmuukSS99957GjNmjO677z41b95cCxYs0NGjR/XFF19Iknbv3q21a9dqzpw5uuWWW3TbbbdpxowZWrp0qY4dOyZJWrJkiQoKChQdHa0bb7xRvXv31pAhQxxO+wIAYCWXnha++eab9e2339o/T506VZI0b9489e/fX++8846Cg4P14YcfqmrVqtq6davuvvtu5efn27/Tt29fzZgxQ998841sNpuWL1+uF154wb781KlT6tatm2bOnKmEhASdOHFCr732Go/hAADKjEvDddOmTfLx8bngmPHjx2v8+PHnXZ6enq6+fftecB2JiYnq2LGjUzUCAFBabnvNFQAAT0W4AgBgMcIVAACLEa4AAFiMcAUAwGKEKwAAFiNcAQCwGOEKAIDFCFcAACxGuAIAYDHCFQAAixGuAABYjHAFAMBihCsAABYjXAG4PZvN5uoSgFJx6ftcAeBi8rNzZIpsqlKrhmN/Tq7ys7JdVBVwYYQr3FpA5WAFBFVy6LOdLpKvbwUXVYQrrTA/X/6VAtWu1wMKrhoqSco+maHvln5GuMJtEa5wawFBldS+Ty/7L1VJSj14WIkb4lxYFVwhuGqoqtSscfGBgBsgXOH2zv2lmpWW7sJqAODiuKEJAACLEa4AAFiMcAUAwGKEKwAAFiNcAQCwGOEKwCMxaxPcGY/iAPA455u1SWLmJrgHwhWAxylp1iaJmZvgPghXAB6LWZvgrrjmCgCAxQhXAAAsRrgCAGAxwhWAV+ERHbgDbmgC4DV4RAfugnAF4DV4RAfugnAF4HV4RAeuxjVXAAAsRrgCAGAxwhUAAIsRrgAAWIxwBQDAYtwtDLcQUDlYAUGVHPpsp4vk61vBRRUBgPMIV7iFgKBKat+nl8OziakHDytxQ5wLqwIA5xCucBvnPpuYlZbuwmrgbZgWEVcS4QrA6zEtIq40whWA12NaRFxphCuAcoNpEXGl8CgOAAAWI1wBALAY4QoAgMW45nqFlTRZglS+7lg8dx8wWQQAb0O4XmElTZZQ3u5YPHcfMFkEAG9DuLoAdyw67gMmiwDgbbjmCgCAxThyBVCuMS2i93GHe1sIVwDlFtMieid3uLeFcAVQbjEtovdy9b0thCuAcs/Vv4jhfbihCQAAi7l1uI4fP17GGIe2a9cu+/KAgADNmDFDJ06cUGZmpj777DPVqlXLYR3XXHONVq1apezsbKWkpOidd95RhQpMWAAAKDtuf1r4l19+UdeuXe2fT58+bf/z1KlT1aNHDz3yyCPKyMjQjBkz9Pnnn6tDhw6SJF9fX61evVrJycm67bbbVKdOHS1YsECFhYX6f//v/13xbQEAlA9uH66nT59WSkpKsf4qVapo4MCBevzxxxUX9+fsPv3799fu3bvVtm1bbdu2Td26ddONN96orl27KjU1VTt27NDYsWP19ttva8KECSosLLzSmwMAKAfc+rSwJN1www1KSkrS/v37tWjRIl1zzTWSpDZt2sjf318bNmywj92zZ48OHTqkiIgISVJERIQSExOVmppqHxMbG6vQ0FA1a9bsvD/T399fISEhDg2lF1A5WFVq1XBolatXYx5hAF7PrY9ct23bpqioKO3Zs0d16tTR+PHjtWXLFjVv3lxhYWHKz89XRkaGw3dSUlIUFhYmSQoLCyt21Hvm85kxJRk1apQmTJhg7caUQyU9a8Y8wgDKA7cO13Xr1tn/nJiYqG3btunQoUPq3bu3cnNzy+znTpw4UVOmTLF/DgkJUVJSUpn9PG927iMOzCMMoDxw+9PCZ8vIyNB//vMfNWrUSMnJyQoICFBoaKjDmNq1ays5OVmSlJycrNq1axdbfmbZ+RQUFCgzM9OhAQBwqTwqXIODg9WwYUMdO3ZMCQkJKigoUJcuXezLGzdurPr16ys+Pl6SFB8frxYtWqhmzZr2MZGRkcrIyNDOnTuveP0AgPLBrU8Lv/vuu1q5cqUOHTqkunXr6tVXX1VRUZE+/vhjnTp1StHR0ZoyZYrS0tJ06tQpTZ8+Xd9//722bdsmSVq/fr127typhQsXasSIEQoLC9Mbb7yhmTNnqqCgwMVbBwDwVm4drldffbU+/vhjXXXVVTp+/Li2bt2qdu3a6cSJE5KkYcOGyWazafny5QoICFBsbKyee+45+/dtNpvuvfdezZo1S/Hx8crOztb8+fM1btw4V20SAKAccOtwfeyxxy64PD8/X4MHD9bgwYPPO+bw4cPq0aOH1aUBAHBeHnXNFQAAT0C4AgBgMbc+LQzPEFA5WAFBlRz6bKeLmIkJQLlFuOKyMRMTADgiXGEJZmKCt7HZbK4uAR6McAWAc+Rn58gU2VSlVo3iy3JylZ+V7YKq4EkIVwA4R2F+vvwrBapdrwccLndkn8zQd0s/I1xxUYQrAJzHuZc7JE4X49IQrgBwiThdjEtFuALAJeJ0MS4V4YpLxvOswJ9KOl0MnI1wxSXjeVYAuDSEK0qF51kB4OKYWxgAAIsRrgAAWIxwBQAL8PwrzsY1VwC4TOd7/jUvO0cF2TkuqgquRLgCwGUq6fnXtKPJ2rb8SwUGBxUbz4QT3o9wBQCLnH03fVZa+nknnNiy5BPC1csRrgBQhs59fI0pFMsHwhUAriCmUCwfCFcAcAGmUPRuPIoDAIDFCFcAACzGaWEUw9tvAODyEK4ohrffAMDlIVzLsQsdofL2GwBwHuFajnGECgBlg3At5zhCBQDrcbcwALgJ3qzjPThyBQA3wLSI3oVwBQA3cKFpEZno3/MQruUAz60CnoOJ/r0D4VoOcFcw4LmY6N8zEa7lBHcFA56Nif49C3cLAwBgMcIVADwUj+64L04LA4AH4kYn90a4eplz7wzmrmDAO3Gjk3sjXL3MuXcGc1cw4N1KutGJ08WuR7h6obP/Y+OuYKB84XSxeyBcAcCLMNOTeyBcAcALMdOTaxGuHoopDQGUhlVHtCX97pEI6HMRrh6KKQ0BOONSj2jPF5Yl/e7hDuXiCFcPxpSGAC5XSUe0FwtLpmK8OMLVTXDrPABXOjcw+Z10eQhXN3ChGw3ysnNUkJ3jgqoAlFfn+510ofs6CGNHhKsbON+NBmlHk7Vt+ZcKDA5yGM+NSwDK0vl+J53vvg7uRC6OcHUjJV1DLc1fcACw0qXe18GztcURrh6AG5cAeILSPFvr7Ze8CFcAQJko7SUvyXtCl3AFAJSpS73kdaHQ9bRrt4QrAMAlLjV0PXGSCsIVAOBWvOE1eoQrAMCteeKjPoQrAMCteeKjPoQrAMAjXMqjPu4yyQ7hCgDwSCUd0brLJDu+ri7gSnruued04MAB5ebm6ocfftAtt9zi6pIAAJfpzBFtlZo1FFQlxNXlSCpH4dq7d29NmTJFr776qlq3bq0dO3YoNjZWNWvWdHVpAAAvU27C9cUXX9ScOXM0b9487dq1S4MGDVJOTo4GDBjg6tIAAF6mXFxz9fPzU5s2bTRx4kR7nzFGGzZsUERERLHx/v7+CggIsH8OCQlx+OflCKlcWbbcfBWeyvxfZ8Hpsusvy3WXpxqp3b363akWT66xHNVuy81XSOXKMrn5uhyXmgPlIlxr1KihihUrKiUlxaE/JSVFTZs2LTZ+1KhRmjBhQrH+pKSksioRAFDW3plq2apCQkKUmZl53uXlIlxLa+LEiZoyZYpDX/Xq1ZWWlnZZ6w0JCVFSUpLq1at3wX8p5Q375fzYNyVjv5wf+6ZkVu6XkJAQHT169IJjykW4njhxQqdPn1bt2rUd+mvXrq3k5ORi4wsKClRQUODQZ+Vf0szMTP7Sl4D9cn7sm5KxX86PfVMyK/bLpXy/XNzQVFhYqISEBHXp0sXe5+Pjoy5duig+Pt6FlQEAvFG5OHKVpClTpmj+/Pn66aef9OOPP2ro0KEKDg5WTEyMq0sDAHghU17a888/bw4ePGjy8vLMDz/8YG699dYr+vP9/f3N+PHjjb+/v8v3hTs19gv7hv3CvvG2/eLz3z8AAACLlItrrgAAXEmEKwAAFiNcAQCwGOEKAIDFCFeLlfa1dr169dKuXbuUm5urn3/+Wd27d79ClV5ZpdkvTz31lDZv3qy0tDSlpaXp66+/9urXAzr7KsRHH31UxhitWLGijCt0jdLul9DQUM2YMUNHjx5VXl6e9uzZw39P/zVkyBDt3r1bOTk5Onz4sKZMmeIwf7o3uP322/XVV18pKSlJxhj17Nnzot/p1KmTEhISlJeXp71796pfv36W1uTyW6S9pfXu3dvk5eWZqKgo85e//MV88MEHJi0tzdSsWbPE8REREaawsNC89NJLpmnTpua1114z+fn5plmzZi7fFlful0WLFplnn33WhIeHmyZNmpiPPvrIpKenm7p167p8W1y9b860+vXrm99//91s2rTJrFixwuXb4er94ufnZ3788UezatUqc9ttt5n69eubjh07mpYtW7p8W1y9bx577DGTm5trHnvsMVO/fn0TGRlpkpKSzOTJk12+LVa2u+++27z++uvmgQceMMYY07NnzwuOv+6660xWVpaZNGmSadq0qXn++edNYWGh6datm1U1uX6neEv74YcfzPTp0+2ffXx8zJEjR8zIkSNLHL906VKzcuVKh774+Hgza9Ysl2+LK/fLuc3X19dkZGSYJ554wuXb4g77xtfX12zdutUMGDDAxMTEeGW4lna/PPPMM2bfvn2mYsWKLq/d3fbN9OnTzYYNGxz6Jk2aZLZs2eLybSmrdinh+o9//MMkJiY69H388cdm7dq1ltTAaWGLnHmt3YYNG+x9F3qtnSRFREQ4jJek2NjY8473RM7sl3MFBQXJz8/vsl+c4G6c3Tfjxo1TamqqPvrooytR5hXnzH65//77FR8fr5kzZyo5OVmJiYkaNWqUfH2961ecM/vm+++/V5s2beynjhs0aKB77rlHa9asuSI1u6uy/v1bbqY/LGulfa2dJIWFhZU4PiwsrMzqvNKc2S/nevvtt3X06NFi/yF4Omf2Tfv27TVw4EC1atXqClToGs7sl+uvv16dO3fW4sWLdc8996hRo0b65z//KT8/P7322mtXouwrwpl98/HHH6tGjRraunWrfHx85Ofnp1mzZjm837o8Ot/v39DQUAUGBiovL++y1u9d/1sHrzNy5Ej16dNHDz74oPLzL+8lx56ucuXKWrhwof72t7/pjz/+cHU5bsXX11epqal6+umntX37dn3yySd68803NWjQIFeX5nKdOnXS6NGj9dxzz6l169Z68MEH1aNHD40ZM8bVpXk1jlwtUtrX2klScnJyqcZ7Imf2yxnDhw/XK6+8oq5duyoxMbEsy3SJ0u6bhg0bqkGDBlq5cqW978xpz8LCQjVp0kS//fZb2RZ9BTjzd+bYsWMqLCyUzWaz9+3atUt16tSRn5+fCgsLy7TmK8WZffP6669r4cKFio6OliT98ssvCg4O1ocffqg333xTxpgyr9sdne/3b0ZGxmUftUocuVrGmdfaxcfHO4yXpMjISK96DZ6zr/t7+eWXNXbsWN19991KSEi4EqVecaXdN7t371bz5s3VqlUre/vqq68UFxenVq1a6ffff7+S5ZcZZ/7OfPfdd2rUqJF8fHzsfY0bN9bRo0e9Jlgl5/ZNUFCQw/90SFJRUZH9u+XVlfj96/I7u7yl9e7d2+Tm5ponn3zSNG3a1MyePdukpaWZWrVqGUlm/vz55q233rKPj4iIMAUFBebFF180TZo0MePHj/faR3FKs19GjBhh8vLyzEMPPWRq165tb8HBwS7fFlfvm3Obt94tXNr9cvXVV5uMjAzz/vvvmxtuuMHcc889Jjk52YwePdrl2+LqfTN+/HiTkZFhHn30UXPdddeZrl27mr1795qlS5e6fFusbMHBwSY8PNyEh4cbY4wZOnSoCQ8PN9dcc42RZN566y0zf/58+/gzj+K8/fbbpkmTJubZZ5/lURx3bhd6rV1cXJyJiYlxGN+rVy+ze/duk5eXZxITE0337t1dvg2u3i8HDhwwJRk/frzLt8PV++bc5q3h6sx+adeunYmPjze5ublm3759ZtSoUcbX19fl2+HqfVOhQgUzbtw4s3fvXpOTk2MOHTpkZsyYYUJDQ12+HVa2Tp06lfh748y+iImJMXFxccW+s337dpOXl2f27dtn+vXrZ1k9vHIOAACLcc0VAACLEa4AAFiMcAUAwGKEKwAAFiNcAQCwGOEKAIDFCFcAACxGuAIAYDHCFcBFxcXFaerUqa4uA/AYhCvg5b766iutXbu2xGUdOnSQMUYtWrS4wlUB3o1wBbxcdHS0IiMjVa9evWLL+vfvr3/9619e+Uo/wJUIV8DLrVq1SsePH1dUVJRDf3BwsB555BF98cUXWrJkiY4cOaLs7Gz9/PPP6tOnzwXXaYxRz549HfrS09PVr18/++err75ay5YtU3p6uv744w998cUXql+/vmXbBbgzwhXwckVFRVqwYEGxcH3kkUdUoUIFLVq0SAkJCerRo4eaN2+uDz/8UAsXLtQtt9zi9M+sWLGiYmNjlZmZqdtvv13t27dXVlaW1q1bJz8/v8vcIsAzuPxVQTQarWxbkyZNjDHGdOrUyd63adMms2DBghLHr1y50rz77rv2z3FxcWbq1Kn2z8YY07NnT4fvpKen21/Z1bdvX7Nr1y6H5X5+fiY7O9tERka6fH/QaGXdOHIFyoE9e/bou+++04ABAyRJDRs2VMeOHRUdHS1fX1+NGTNGP//8s/744w9lZmbqrrvu0rXXXuv0zwsPD1ejRo2UmZlpb2lpaQoMDFTDhg2t2izAbVV0dQEArozo6GhNnz5dzz//vPr37699+/Zp06ZNGjlypIYMGaKhQ4cqMTFR2dnZeu+99+Tv73/eddlsNvn4+Dj0nX26t3LlykpISFDfvn2Lfff48ePWbRTgpghXoJz45JNPNG3aND3++ON68sknNWvWLElS+/bt9eWXX2rx4sWSJB8fHzVu3Fg7d+4877qOHz+uOnXq2D83atRIwcHB9s/bt2/Xo48+qtTUVGVmZpbRFgHui9PCQDmRnZ2tZcuWaeLEiapTp47mzZsnSdq7d68iIyMVERGhpk2b6oMPPlDt2rUvuK6NGzdq8ODBatWqldq0aaPZs2eroKDAvnzx4sU6ceKEvvzyS3Xo0EHXXXedOnXqpGnTppX4SBDgbQhXoByJjo5W9erVFRsbq2PHjkmS3njjDW3fvl2xsbH69ttvlZycrC+++OKC6xk+fLh+//13bdmyRUuWLNGkSZOUk5NjX56bm6uOHTvq8OHD+vzzz7Vr1y5FR0crMDBQp06dKstNBNyCj/68swkAAFiEI1cAACxGuAIAYDHCFQAAixGuAABYjHAFAMBihCsAABYjXAEAsBjhCgCAxQhXAAAsRrgCAGAxwhUAAIv9f3FoOCardnYdAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# feature_config = {\n",
    "#     \"target_features\": ['label'],\n",
    "#     \"numeric_features\": ['turnover_rate', 'pe_ttm', 'ps_ttm', 'pcf_ncf_ttm', 'pb_mrq', 'KMID', 'KLEN', 'KMID2', 'KUP', 'KUP2', 'KLOW', 'KLOW2', 'KSFT', 'KSFT2', 'OPEN0', 'OPEN1', 'OPEN2', 'OPEN3', 'OPEN4', 'HIGH0', 'HIGH1', 'HIGH2', 'HIGH3', 'HIGH4', 'LOW0', 'LOW1', 'LOW2', 'LOW3', 'LOW4', 'CLOSE1', 'CLOSE2', 'CLOSE3', 'CLOSE4', 'VOLUME1', 'VOLUME2', 'VOLUME3', 'VOLUME4', 'ROC5', 'ROC10', 'ROC20', 'ROC30', 'ROC60', 'MAX5', 'MAX10', 'MAX20', 'MAX30', 'MAX60', 'MIN5', 'MIN10', 'MIN20', 'MIN30', 'MIN60', 'MA5', 'MA10', 'MA20', 'MA30', 'MA60', 'STD5', 'STD10', 'STD20', 'STD30', 'STD60', 'BETA5', 'BETA10', 'BETA20', 'BETA30', 'BETA60', 'RSQR5', 'RSQR10', 'RSQR20', 'RSQR30', 'RSQR60', 'RESI5', 'RESI10', 'RESI20', 'RESI30', 'RESI60', 'QTLU5', 'QTLU10', 'QTLU20', 'QTLU30', 'QTLU60', 'QTLD5', 'QTLD10', 'QTLD20', 'QTLD30', 'QTLD60', 'TSRANK5', 'TSRANK10', 'TSRANK20', 'TSRANK30', 'TSRANK60', 'RSV5', 'RSV10', 'RSV20', 'RSV30', 'RSV60', 'IMAX5', 'IMAX10', 'IMAX20', 'IMAX30', 'IMAX60', 'IMIN5', 'IMIN10', 'IMIN20', 'IMIN30', 'IMIN60', 'IMXD5', 'IMXD10', 'IMXD20', 'IMXD30', 'IMXD60', 'CORR5', 'CORR10', 'CORR20', 'CORR30', 'CORR60', 'CORD5', 'CORD10', 'CORD20', 'CORD30', 'CORD60', 'CNTP5', 'CNTP10', 'CNTP20', 'CNTP30', 'CNTP60', 'CNTN5', 'CNTN10', 'CNTN20', 'CNTN30', 'CNTN60', 'CNTD5', 'CNTD10', 'CNTD20', 'CNTD30', 'CNTD60', 'SUMP5', 'SUMP10', 'SUMP20', 'SUMP30', 'SUMP60', 'SUMN5', 'SUMN10', 'SUMN20', 'SUMN30', 'SUMN60', 'SUMD5', 'SUMD10', 'SUMD20', 'SUMD30', 'SUMD60', 'VMA5', 'VMA10', 'VMA20', 'VMA30', 'VMA60', 'VSTD5', 'VSTD10', 'VSTD20', 'VSTD30', 'VSTD60', 'WVMA5', 'WVMA10', 'WVMA20', 'WVMA30', 'WVMA60', 'VSUMP5', 'VSUMP10', 'VSUMP20', 'VSUMP30', 'VSUMP60', 'VSUMN5', 'VSUMN10', 'VSUMN20', 'VSUMN30', 'VSUMN60', 'VSUMD5', 'VSUMD10', 'VSUMD20', 'VSUMD30', 'VSUMD60'],\n",
    "#     \"integer_categorical_features\": ['month'],\n",
    "#     \"string_categorical_features\": ['industry', 'season'],\n",
    "# }\n",
    "plot_series_dist(train_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始将DataFrame转换为DataSet...\n"
     ]
    }
   ],
   "source": [
    "# 转换为tensorflow所使用的dataset\n",
    "print(\"开始将DataFrame转换为DataSet...\")\n",
    "train_ds = df_to_dataset(train_df, feature_columns, label_columns, shuffle=True, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val_df, feature_columns, label_columns, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test_df, feature_columns, label_columns, shuffle=False, batch_size=batch_size)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始模型初始化 & 训练...\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-30 05:06:46.507021: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x14b75c1d5880 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2024-05-30 05:06:46.507173: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2024-05-30 05:06:46.546793: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-05-30 05:06:46.696585: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 15s 191ms/step - loss: 0.4610 - val_loss: 0.0761\n",
      "Epoch 2/500\n",
      "50/50 [==============================] - 5s 91ms/step - loss: 0.2794 - val_loss: 0.0466\n",
      "Epoch 3/500\n",
      "50/50 [==============================] - 5s 97ms/step - loss: 0.2065 - val_loss: 0.0371\n",
      "Epoch 4/500\n",
      "50/50 [==============================] - 5s 94ms/step - loss: 0.1626 - val_loss: 0.0285\n",
      "Epoch 5/500\n",
      "50/50 [==============================] - 5s 93ms/step - loss: 0.1266 - val_loss: 0.0236\n",
      "Epoch 6/500\n",
      "50/50 [==============================] - 4s 90ms/step - loss: 0.0990 - val_loss: 0.0201\n",
      "Epoch 7/500\n",
      "50/50 [==============================] - 5s 94ms/step - loss: 0.0816 - val_loss: 0.0181\n",
      "Epoch 8/500\n",
      "11/50 [=====>........................] - ETA: 3s - loss: 0.0697"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 5s 109ms/step - loss: 0.0707 - val_loss: 0.0168\n",
      "Epoch 9/500\n",
      "50/50 [==============================] - 4s 88ms/step - loss: 0.0611 - val_loss: 0.0160\n",
      "Epoch 10/500\n",
      "50/50 [==============================] - 5s 93ms/step - loss: 0.0535 - val_loss: 0.0154\n",
      "Epoch 11/500\n",
      "50/50 [==============================] - 4s 84ms/step - loss: 0.0484 - val_loss: 0.0150\n",
      "Epoch 12/500\n",
      "50/50 [==============================] - 5s 90ms/step - loss: 0.0424 - val_loss: 0.0146\n",
      "Epoch 13/500\n",
      "50/50 [==============================] - 4s 81ms/step - loss: 0.0384 - val_loss: 0.0143\n",
      "Epoch 14/500\n",
      "50/50 [==============================] - 4s 83ms/step - loss: 0.0348 - val_loss: 0.0140\n",
      "Epoch 15/500\n",
      "50/50 [==============================] - 4s 85ms/step - loss: 0.0322 - val_loss: 0.0138\n",
      "Epoch 16/500\n",
      "50/50 [==============================] - 5s 103ms/step - loss: 0.0298 - val_loss: 0.0135\n",
      "Epoch 17/500\n",
      "50/50 [==============================] - 5s 91ms/step - loss: 0.0282 - val_loss: 0.0133\n",
      "Epoch 18/500\n",
      "50/50 [==============================] - 5s 102ms/step - loss: 0.0256 - val_loss: 0.0131\n",
      "Epoch 19/500\n",
      "50/50 [==============================] - 4s 78ms/step - loss: 0.0241 - val_loss: 0.0130\n",
      "Epoch 20/500\n",
      "50/50 [==============================] - 4s 79ms/step - loss: 0.0228 - val_loss: 0.0128\n",
      "Epoch 21/500\n",
      "50/50 [==============================] - 5s 91ms/step - loss: 0.0216 - val_loss: 0.0127\n",
      "Epoch 22/500\n",
      "50/50 [==============================] - 4s 87ms/step - loss: 0.0206 - val_loss: 0.0126\n",
      "Epoch 23/500\n",
      "50/50 [==============================] - 4s 83ms/step - loss: 0.0196 - val_loss: 0.0124\n",
      "Epoch 24/500\n",
      "50/50 [==============================] - 6s 116ms/step - loss: 0.0190 - val_loss: 0.0124\n",
      "Epoch 25/500\n",
      "50/50 [==============================] - 4s 86ms/step - loss: 0.0184 - val_loss: 0.0123\n",
      "Epoch 26/500\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.0178 - val_loss: 0.0122\n",
      "Epoch 27/500\n",
      "50/50 [==============================] - 5s 99ms/step - loss: 0.0173 - val_loss: 0.0121\n",
      "Epoch 28/500\n",
      "50/50 [==============================] - 5s 91ms/step - loss: 0.0170 - val_loss: 0.0120\n",
      "Epoch 29/500\n",
      "50/50 [==============================] - 4s 90ms/step - loss: 0.0166 - val_loss: 0.0120\n",
      "Epoch 30/500\n",
      "50/50 [==============================] - 4s 86ms/step - loss: 0.0164 - val_loss: 0.0119\n",
      "Epoch 31/500\n",
      "50/50 [==============================] - 4s 89ms/step - loss: 0.0161 - val_loss: 0.0118\n",
      "Epoch 32/500\n",
      "50/50 [==============================] - 5s 107ms/step - loss: 0.0160 - val_loss: 0.0118\n",
      "Epoch 33/500\n",
      "50/50 [==============================] - 4s 87ms/step - loss: 0.0158 - val_loss: 0.0118\n",
      "Epoch 34/500\n",
      "50/50 [==============================] - 4s 85ms/step - loss: 0.0155 - val_loss: 0.0117\n",
      "Epoch 35/500\n",
      "50/50 [==============================] - 5s 91ms/step - loss: 0.0154 - val_loss: 0.0117\n",
      "Epoch 36/500\n",
      "50/50 [==============================] - 4s 85ms/step - loss: 0.0153 - val_loss: 0.0117\n",
      "Epoch 37/500\n",
      "50/50 [==============================] - 4s 86ms/step - loss: 0.0152 - val_loss: 0.0117\n",
      "Epoch 38/500\n",
      "50/50 [==============================] - 4s 80ms/step - loss: 0.0152 - val_loss: 0.0116\n",
      "Epoch 39/500\n",
      "50/50 [==============================] - 4s 77ms/step - loss: 0.0149 - val_loss: 0.0117\n",
      "Epoch 40/500\n",
      "50/50 [==============================] - 4s 73ms/step - loss: 0.0149 - val_loss: 0.0117\n",
      "Epoch 41/500\n",
      "50/50 [==============================] - 5s 94ms/step - loss: 0.0148 - val_loss: 0.0116\n",
      "Epoch 42/500\n",
      "50/50 [==============================] - 5s 106ms/step - loss: 0.0147 - val_loss: 0.0116\n",
      "Epoch 43/500\n",
      "50/50 [==============================] - 5s 104ms/step - loss: 0.0146 - val_loss: 0.0116\n",
      "Epoch 44/500\n",
      "50/50 [==============================] - 5s 98ms/step - loss: 0.0146 - val_loss: 0.0116\n",
      "Epoch 45/500\n",
      "50/50 [==============================] - 4s 89ms/step - loss: 0.0145 - val_loss: 0.0116\n",
      "Epoch 46/500\n",
      "50/50 [==============================] - 5s 98ms/step - loss: 0.0144 - val_loss: 0.0116\n",
      "Epoch 47/500\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.0143 - val_loss: 0.0116\n",
      "Epoch 48/500\n",
      "50/50 [==============================] - 5s 101ms/step - loss: 0.0143 - val_loss: 0.0115\n",
      "Epoch 49/500\n",
      "50/50 [==============================] - 4s 75ms/step - loss: 0.0141 - val_loss: 0.0116\n",
      "Epoch 50/500\n",
      "50/50 [==============================] - 4s 84ms/step - loss: 0.0141 - val_loss: 0.0116\n",
      "Epoch 51/500\n",
      "50/50 [==============================] - 5s 92ms/step - loss: 0.0140 - val_loss: 0.0116\n",
      "Epoch 52/500\n",
      "50/50 [==============================] - 4s 79ms/step - loss: 0.0139 - val_loss: 0.0116\n",
      "Epoch 53/500\n",
      "50/50 [==============================] - 4s 75ms/step - loss: 0.0139 - val_loss: 0.0118\n",
      "Epoch 54/500\n",
      "50/50 [==============================] - 5s 93ms/step - loss: 0.0138 - val_loss: 0.0116\n",
      "Epoch 55/500\n",
      "50/50 [==============================] - 5s 96ms/step - loss: 0.0137 - val_loss: 0.0117\n",
      "Epoch 56/500\n",
      "50/50 [==============================] - 4s 77ms/step - loss: 0.0137 - val_loss: 0.0116\n",
      "Epoch 57/500\n",
      "50/50 [==============================] - 4s 88ms/step - loss: 0.0136 - val_loss: 0.0117\n",
      "Epoch 58/500\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0136Restoring model weights from the end of the best epoch: 48.\n",
      "50/50 [==============================] - 4s 81ms/step - loss: 0.0136 - val_loss: 0.0117\n",
      "Epoch 58: early stopping\n"
     ]
    }
   ],
   "source": [
    "# 准备模型训练\n",
    "print(\"开始模型初始化 & 训练...\")\n",
    "from models.single_task.model_moe import QuantModel\n",
    "model_config = {\n",
    "        \"seed\": 1024,\n",
    "        \"feature_use_embedding\": False,\n",
    "        \"feature_embedding_dims\": 4,\n",
    "        \"numeric_features_with_boundaries\": {k: pd.qcut(train_df[k], q=20, retbins=True, duplicates='drop')[1].tolist() for k in feature_config.get('numeric_features', [])},\n",
    "        \"integer_categorical_features_with_vocab\": {k: list(train_df[k].unique()) for k in feature_config.get('integer_categorical_features', [])},\n",
    "        \"string_categorical_features_with_vocab\": {k: list(train_df[k].unique()) for k in feature_config.get('string_categorical_features', [])},\n",
    "    }\n",
    "model = QuantModel(config=model_config)\n",
    "\n",
    "initial_learning_rate = 5e-4\n",
    "\n",
    "# lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "#     initial_learning_rate,\n",
    "#     decay_steps=5 * (len(train_df) // batch_size), # 每5个batch进行一次调整\n",
    "#     decay_rate=0.9,\n",
    "#     staircase=True)\n",
    "model.compile(\n",
    "    # optimizer=tf.keras.optimizers.Adam(lr_schedule),\n",
    "    optimizer=tf.keras.optimizers.Adam(initial_learning_rate),\n",
    "    # loss=tf.keras.losses.MeanSquaredError(),\n",
    "    # loss=tf.keras.losses.MeanAbsoluteError(),\n",
    "    loss=tf.keras.losses.Huber(),\n",
    "    # metrics=[\n",
    "    #     # tf.keras.metrics.MeanSquaredError(),\n",
    "    #     # tf.keras.metrics.MeanAbsoluteError(),\n",
    "    # ],\n",
    "    )\n",
    "\n",
    "EPOCHS = 500\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    verbose=1,\n",
    "    patience=10,\n",
    "    mode='min',\n",
    "    restore_best_weights=True)\n",
    "\n",
    "baseline_history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks = [early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'val_loss'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_metrics(baseline_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(f'./tf_models/{benchmark}/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始保存回测预测结果...\n",
      "59/59 [==============================] - 7s 108ms/step\n"
     ]
    }
   ],
   "source": [
    "# 输出回测预测\n",
    "print(\"开始保存回测预测结果...\")\n",
    "model_pred_result = model.predict(test_ds)\n",
    "output_df = test_data[['code', 'code_name', 'datetime']]\n",
    "output_df['label'] = test_df['label']\n",
    "output_df['label_pred'] = model_pred_result\n",
    "output_df = output_df.rename(columns={\n",
    "    'code': 'stock_code',\n",
    "    'code_name': 'stock_name'\n",
    "})\n",
    "output_df.to_pickle(f'../../Offline/backtest/backtest_data/test/{benchmark}_{test_start_date}_回归任务_v6.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_pickle('../../Offline/backtest/backtest_data/test/000016_2019-01-01_回归任务_v5.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_prediction(model_prediction):\n",
    "    def get_stock_for_buy(group):\n",
    "        # group = group[group[\"label_pred\"] > self.params.buy_pred_upper_bound]  # 使用模型预测打分的分布（> 0.9的quantile）进行买入过滤\n",
    "        select_n = group.nlargest(3, \"label_pred\")\n",
    "        return select_n.to_dict(\"records\")\n",
    "\n",
    "    def get_stock_for_sell(group):\n",
    "        # group = group[group[\"label_pred\"] < self.params.sell_pred_lower_bound]  # 使用模型预测打分的分布（< 0.1的quantile）进行卖出过滤\n",
    "        select_n = group.nsmallest(3, \"label_pred\")\n",
    "        return select_n.to_dict(\"records\")\n",
    "\n",
    "    stock_for_buy = model_prediction.groupby(\"datetime\").apply(get_stock_for_buy).to_dict()\n",
    "    stock_for_sell = model_prediction.groupby(\"datetime\").apply(get_stock_for_sell).to_dict()\n",
    "    return stock_for_buy, stock_for_sell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_for_buy, stock_for_sell = get_model_prediction(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_for_buy['2019-01-02']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
