{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import akshare as ak\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.options.display.max_rows=None\n",
    "pd.options.display.max_columns=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['688981', '688041', '601988', '601601', '600150']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 获取中证50（000016）的股票列表\n",
    "stock_code_list = ak.index_stock_cons('000016')['品种代码'].to_list()\n",
    "stock_code_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:04<00:00, 10.29it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_code</th>\n",
       "      <th>stock_name</th>\n",
       "      <th>total_shares</th>\n",
       "      <th>circulating_shares</th>\n",
       "      <th>total_market_cap</th>\n",
       "      <th>circulating_market_cap</th>\n",
       "      <th>industry</th>\n",
       "      <th>listing_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>688981</td>\n",
       "      <td>中芯国际</td>\n",
       "      <td>7.946658e+09</td>\n",
       "      <td>1.973609e+09</td>\n",
       "      <td>3.496529e+11</td>\n",
       "      <td>8.683880e+10</td>\n",
       "      <td>半导体</td>\n",
       "      <td>20200716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>688041</td>\n",
       "      <td>海光信息</td>\n",
       "      <td>2.324338e+09</td>\n",
       "      <td>8.805572e+08</td>\n",
       "      <td>1.783232e+11</td>\n",
       "      <td>6.755635e+10</td>\n",
       "      <td>半导体</td>\n",
       "      <td>20220812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>601988</td>\n",
       "      <td>中国银行</td>\n",
       "      <td>2.943878e+11</td>\n",
       "      <td>2.107655e+11</td>\n",
       "      <td>1.268811e+12</td>\n",
       "      <td>9.083994e+11</td>\n",
       "      <td>银行</td>\n",
       "      <td>20060705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>601601</td>\n",
       "      <td>中国太保</td>\n",
       "      <td>9.620341e+09</td>\n",
       "      <td>6.845041e+09</td>\n",
       "      <td>2.503213e+11</td>\n",
       "      <td>1.781080e+11</td>\n",
       "      <td>保险</td>\n",
       "      <td>20071225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>600150</td>\n",
       "      <td>中国船舶</td>\n",
       "      <td>4.472429e+09</td>\n",
       "      <td>4.472429e+09</td>\n",
       "      <td>1.404343e+11</td>\n",
       "      <td>1.404343e+11</td>\n",
       "      <td>船舶制造</td>\n",
       "      <td>19980520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stock_code stock_name  total_shares  circulating_shares  total_market_cap  \\\n",
       "0     688981       中芯国际  7.946658e+09        1.973609e+09      3.496529e+11   \n",
       "1     688041       海光信息  2.324338e+09        8.805572e+08      1.783232e+11   \n",
       "2     601988       中国银行  2.943878e+11        2.107655e+11      1.268811e+12   \n",
       "3     601601       中国太保  9.620341e+09        6.845041e+09      2.503213e+11   \n",
       "4     600150       中国船舶  4.472429e+09        4.472429e+09      1.404343e+11   \n",
       "\n",
       "   circulating_market_cap industry  listing_date  \n",
       "0            8.683880e+10      半导体      20200716  \n",
       "1            6.755635e+10      半导体      20220812  \n",
       "2            9.083994e+11       银行      20060705  \n",
       "3            1.781080e+11       保险      20071225  \n",
       "4            1.404343e+11     船舶制造      19980520  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. 获取这些股票的个股信息\n",
    "all_stock_individual_info = pd.DataFrame([ak.stock_individual_info_em(symbol=stock_code).set_index('item').to_dict()['value'] for stock_code in tqdm(stock_code_list)]).rename(columns={\n",
    "                    \"总市值\": \"total_market_cap\",\n",
    "                    \"流通市值\": \"circulating_market_cap\",\n",
    "                    \"行业\": \"industry\",\n",
    "                    \"上市时间\": \"listing_date\",\n",
    "                    \"股票代码\": \"stock_code\",\n",
    "                    \"股票简称\": \"stock_name\",\n",
    "                    \"总股本\": \"total_shares\",\n",
    "                    \"流通股\": \"circulating_shares\",\n",
    "                })\n",
    "all_stock_individual_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:14<00:00,  3.55it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_code</th>\n",
       "      <th>datetime</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>volume</th>\n",
       "      <th>turnover</th>\n",
       "      <th>amplitude</th>\n",
       "      <th>change_pct</th>\n",
       "      <th>change_amount</th>\n",
       "      <th>turnover_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>688981</td>\n",
       "      <td>2020-07-16</td>\n",
       "      <td>95.00</td>\n",
       "      <td>82.92</td>\n",
       "      <td>95.00</td>\n",
       "      <td>80.00</td>\n",
       "      <td>5522480</td>\n",
       "      <td>4.797912e+10</td>\n",
       "      <td>54.62</td>\n",
       "      <td>201.97</td>\n",
       "      <td>55.46</td>\n",
       "      <td>53.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>688981</td>\n",
       "      <td>2020-07-17</td>\n",
       "      <td>79.00</td>\n",
       "      <td>77.06</td>\n",
       "      <td>84.90</td>\n",
       "      <td>75.00</td>\n",
       "      <td>2195971</td>\n",
       "      <td>1.739782e+10</td>\n",
       "      <td>11.94</td>\n",
       "      <td>-7.07</td>\n",
       "      <td>-5.86</td>\n",
       "      <td>21.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>688981</td>\n",
       "      <td>2020-07-20</td>\n",
       "      <td>77.19</td>\n",
       "      <td>79.17</td>\n",
       "      <td>80.51</td>\n",
       "      <td>70.02</td>\n",
       "      <td>2286412</td>\n",
       "      <td>1.700981e+10</td>\n",
       "      <td>13.61</td>\n",
       "      <td>2.74</td>\n",
       "      <td>2.11</td>\n",
       "      <td>21.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>688981</td>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>78.30</td>\n",
       "      <td>78.63</td>\n",
       "      <td>82.89</td>\n",
       "      <td>77.77</td>\n",
       "      <td>1619190</td>\n",
       "      <td>1.298126e+10</td>\n",
       "      <td>6.47</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>15.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>688981</td>\n",
       "      <td>2020-07-22</td>\n",
       "      <td>77.80</td>\n",
       "      <td>79.57</td>\n",
       "      <td>81.78</td>\n",
       "      <td>77.20</td>\n",
       "      <td>1339817</td>\n",
       "      <td>1.068559e+10</td>\n",
       "      <td>5.82</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.94</td>\n",
       "      <td>12.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stock_code    datetime   open  close   high    low   volume      turnover  \\\n",
       "0     688981  2020-07-16  95.00  82.92  95.00  80.00  5522480  4.797912e+10   \n",
       "1     688981  2020-07-17  79.00  77.06  84.90  75.00  2195971  1.739782e+10   \n",
       "2     688981  2020-07-20  77.19  79.17  80.51  70.02  2286412  1.700981e+10   \n",
       "3     688981  2020-07-21  78.30  78.63  82.89  77.77  1619190  1.298126e+10   \n",
       "4     688981  2020-07-22  77.80  79.57  81.78  77.20  1339817  1.068559e+10   \n",
       "\n",
       "   amplitude  change_pct  change_amount  turnover_rate  \n",
       "0      54.62      201.97          55.46          53.09  \n",
       "1      11.94       -7.07          -5.86          21.11  \n",
       "2      13.61        2.74           2.11          21.98  \n",
       "3       6.47       -0.68          -0.54          15.57  \n",
       "4       5.82        1.20           0.94          12.88  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. 获取这些股票的历史数据\n",
    "all_stock_history_info = []\n",
    "for stock_code in tqdm(stock_code_list):\n",
    "    stock_history_info = ak.stock_zh_a_hist(symbol=stock_code, adjust='hfq').rename(\n",
    "            columns={\n",
    "                \"日期\": \"datetime\",\n",
    "                \"开盘\": \"open\",\n",
    "                \"最高\": \"high\",\n",
    "                \"最低\": \"low\",\n",
    "                \"收盘\": \"close\",\n",
    "                \"成交量\": \"volume\",\n",
    "                \"成交额\": \"turnover\",\n",
    "                \"振幅\": \"amplitude\",\n",
    "                \"涨跌幅\": \"change_pct\",\n",
    "                \"涨跌额\": \"change_amount\",\n",
    "                \"换手率\": \"turnover_rate\",\n",
    "            }\n",
    "        )\n",
    "    stock_history_info.insert(0, \"stock_code\", stock_code)\n",
    "    all_stock_history_info.append(stock_history_info)\n",
    "all_stock_history_info = pd.concat(all_stock_history_info)\n",
    "all_stock_history_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_code</th>\n",
       "      <th>datetime</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>600028</td>\n",
       "      <td>2001-08-22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>600028</td>\n",
       "      <td>2001-08-23</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>600028</td>\n",
       "      <td>2001-08-27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>600028</td>\n",
       "      <td>2001-08-28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>600028</td>\n",
       "      <td>2001-08-29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stock_code    datetime  target\n",
       "10     600028  2001-08-22       0\n",
       "11     600028  2001-08-23       2\n",
       "12     600028  2001-08-27       0\n",
       "13     600028  2001-08-28       0\n",
       "14     600028  2001-08-29       0"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. 构建label\n",
    "all_stock_label_info = all_stock_history_info[['stock_code', 'datetime', 'close']]\n",
    "all_stock_label_info = all_stock_label_info.sort_values(by=[\"stock_code\", \"datetime\"])\n",
    "# 计算日收益率 & 历史窗口期（10天）内的平均收益率&标准差\n",
    "all_stock_label_info[\"daily_return\"] = all_stock_label_info.groupby(\"stock_code\")[\"close\"].pct_change()\n",
    "all_stock_label_info[\"mean_return\"] = all_stock_label_info.groupby(\"stock_code\")[\"daily_return\"].transform(lambda x: x.rolling(10).mean())\n",
    "all_stock_label_info[\"std_return\"] = all_stock_label_info.groupby(\"stock_code\")[\"daily_return\"].transform(lambda x: x.rolling(10).std())\n",
    "# 计算未来5天的收益率\n",
    "all_stock_label_info[\"close_in_5_days\"] = all_stock_label_info.groupby(\"stock_code\")[\"close\"].shift(-5)\n",
    "all_stock_label_info[\"return_5_days\"] = all_stock_label_info[\"close_in_5_days\"] / all_stock_label_info[\"close\"] - 1\n",
    "# 构建label列\n",
    "all_stock_label_info[\"target\"] = 0  # 默认设置为0\n",
    "all_stock_label_info.loc[all_stock_label_info[\"return_5_days\"] > all_stock_label_info[\"mean_return\"] + 2 * all_stock_label_info[\"std_return\"], \"target\"] = 1\n",
    "all_stock_label_info.loc[all_stock_label_info[\"return_5_days\"] < all_stock_label_info[\"mean_return\"] - 2 * all_stock_label_info[\"std_return\"], \"target\"] = 2\n",
    "# 删除有NaN值的行，因为历史统计和未来数据可能不完整\n",
    "all_stock_label_info.dropna(subset=[\"mean_return\", \"std_return\", \"close_in_5_days\"], inplace=True)\n",
    "# 构建Label表\n",
    "all_stock_label_info = all_stock_label_info[[\"stock_code\", \"datetime\", \"target\"]]\n",
    "all_stock_label_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_code</th>\n",
       "      <th>datetime</th>\n",
       "      <th>target</th>\n",
       "      <th>industry</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>volume</th>\n",
       "      <th>turnover</th>\n",
       "      <th>amplitude</th>\n",
       "      <th>change_pct</th>\n",
       "      <th>change_amount</th>\n",
       "      <th>turnover_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600028</td>\n",
       "      <td>2001-08-22</td>\n",
       "      <td>0</td>\n",
       "      <td>石油行业</td>\n",
       "      <td>4.24</td>\n",
       "      <td>4.14</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.13</td>\n",
       "      <td>781415</td>\n",
       "      <td>324714000.0</td>\n",
       "      <td>2.83</td>\n",
       "      <td>-2.36</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>5.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>600028</td>\n",
       "      <td>2001-08-23</td>\n",
       "      <td>2</td>\n",
       "      <td>石油行业</td>\n",
       "      <td>4.12</td>\n",
       "      <td>4.11</td>\n",
       "      <td>4.13</td>\n",
       "      <td>4.02</td>\n",
       "      <td>353094</td>\n",
       "      <td>143967000.0</td>\n",
       "      <td>2.66</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>2.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600028</td>\n",
       "      <td>2001-08-27</td>\n",
       "      <td>0</td>\n",
       "      <td>石油行业</td>\n",
       "      <td>4.05</td>\n",
       "      <td>3.96</td>\n",
       "      <td>4.06</td>\n",
       "      <td>3.91</td>\n",
       "      <td>338673</td>\n",
       "      <td>134824000.0</td>\n",
       "      <td>3.65</td>\n",
       "      <td>-3.65</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>2.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>600028</td>\n",
       "      <td>2001-08-28</td>\n",
       "      <td>0</td>\n",
       "      <td>石油行业</td>\n",
       "      <td>3.93</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.01</td>\n",
       "      <td>3.91</td>\n",
       "      <td>261038</td>\n",
       "      <td>103591000.0</td>\n",
       "      <td>2.53</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>600028</td>\n",
       "      <td>2001-08-29</td>\n",
       "      <td>0</td>\n",
       "      <td>石油行业</td>\n",
       "      <td>4.01</td>\n",
       "      <td>3.97</td>\n",
       "      <td>4.03</td>\n",
       "      <td>3.97</td>\n",
       "      <td>127005</td>\n",
       "      <td>50647000.0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stock_code    datetime  target industry  open  close  high   low  volume  \\\n",
       "0     600028  2001-08-22       0     石油行业  4.24   4.14  4.25  4.13  781415   \n",
       "1     600028  2001-08-23       2     石油行业  4.12   4.11  4.13  4.02  353094   \n",
       "2     600028  2001-08-27       0     石油行业  4.05   3.96  4.06  3.91  338673   \n",
       "3     600028  2001-08-28       0     石油行业  3.93   4.00  4.01  3.91  261038   \n",
       "4     600028  2001-08-29       0     石油行业  4.01   3.97  4.03  3.97  127005   \n",
       "\n",
       "      turnover  amplitude  change_pct  change_amount  turnover_rate  \n",
       "0  324714000.0       2.83       -2.36          -0.10           5.07  \n",
       "1  143967000.0       2.66       -0.72          -0.03           2.29  \n",
       "2  134824000.0       3.65       -3.65          -0.15           2.20  \n",
       "3  103591000.0       2.53        1.01           0.04           1.70  \n",
       "4   50647000.0       1.50       -0.75          -0.03           0.82  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. label表join特征表\n",
    "wide_table_info = all_stock_label_info.merge(all_stock_individual_info[['stock_code', 'industry']], how='left').merge(all_stock_history_info, on=[\"stock_code\", \"datetime\"], how=\"left\")\n",
    "wide_table_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.0\n"
     ]
    }
   ],
   "source": [
    "# 使用tensorflow处理原始数据\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 选择固定时间区间的数据\n",
    "train_start_date = pd.to_datetime('2000-01-01')\n",
    "train_end_date = pd.to_datetime('2020-12-31')\n",
    "val_start_date = pd.to_datetime('2021-01-01')\n",
    "val_end_date = pd.to_datetime('2021-12-31')\n",
    "test_start_date = pd.to_datetime('2022-01-01')\n",
    "test_end_date = pd.to_datetime('2022-12-31')\n",
    "\n",
    "train_data = wide_table_info[(pd.to_datetime(wide_table_info['datetime']) >= train_start_date) & (pd.to_datetime(wide_table_info['datetime']) <= train_end_date)]\n",
    "val_data = wide_table_info[(pd.to_datetime(wide_table_info['datetime']) >= val_start_date) & (pd.to_datetime(wide_table_info['datetime']) <= val_end_date)]\n",
    "test_data = wide_table_info[(pd.to_datetime(wide_table_info['datetime']) >= test_start_date) & (pd.to_datetime(wide_table_info['datetime']) <= test_end_date)]\n",
    "\n",
    "train_data = train_data[['target', 'industry', 'open', 'close', 'high', 'low', 'volume', 'turnover', 'amplitude','change_pct', 'change_amount', 'turnover_rate']]\n",
    "validation_data = val_data[['target', 'industry', 'open', 'close', 'high', 'low', 'volume', 'turnover', 'amplitude','change_pct', 'change_amount', 'turnover_rate']]\n",
    "test_data = test_data[['target', 'industry', 'open', 'close', 'high', 'low', 'volume', 'turnover', 'amplitude','change_pct', 'change_amount', 'turnover_rate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "Total: 151865, Normal: 92334,Positive: 32386, Negative:27145 \n",
      "\n",
      "Validation:\n",
      "Total: 11619, Normal: 7303,Positive: 2278, Negative:2038 \n",
      "\n",
      "Test:\n",
      "Total: 11936, Normal: 7484,Positive: 2191, Negative:2261 \n",
      "\n",
      "Weight for class 0: 0.82\n",
      "Weight for class 1: 2.34\n",
      "Weight for class 2: 2.80\n"
     ]
    }
   ],
   "source": [
    "train_0, train_1, train_2 = np.bincount(train_data['target'])\n",
    "train_total = train_0 + train_1 + train_2\n",
    "print('Train:\\nTotal: {}, Normal: {},Positive: {}, Negative:{} \\n'.format(train_total, train_0, train_1, train_2))\n",
    "\n",
    "val_0, val_1, val_2 = np.bincount(validation_data['target'])\n",
    "val_total = val_0 + val_1 + val_2\n",
    "print('Validation:\\nTotal: {}, Normal: {},Positive: {}, Negative:{} \\n'.format(val_total, val_0, val_1, val_2))\n",
    "\n",
    "test_0, test_1, test_2 = np.bincount(test_data['target'])\n",
    "test_total = test_0 + test_1 + test_2\n",
    "print('Test:\\nTotal: {}, Normal: {},Positive: {}, Negative:{} \\n'.format(test_total, test_0, test_1, test_2))\n",
    "\n",
    "\n",
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "# The sum of the weights of all examples stays the same.\n",
    "weight_for_0 = (1 / train_0) * (train_total / 2.0)\n",
    "weight_for_1 = (1 / train_1) * (train_total / 2.0)\n",
    "weight_for_2 = (1 / train_2) * (train_total / 2.0)\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1, 2: weight_for_2}\n",
    "\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))\n",
    "print('Weight for class 2: {:.2f}'.format(weight_for_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numeric_boundaries(series, num_bins=20):\n",
    "    return pd.qcut(series, num_bins, retbins=True)[1].tolist()\n",
    "\n",
    "TARGET_FEATURE_NAME = \"target\"\n",
    "TARGET_FEATURE_LABELS = [\"0\", \"1\", \"2\"]\n",
    "TARGET_FEATURE_LENGTH = len(TARGET_FEATURE_LABELS)\n",
    "\n",
    "# 连续特征分桶\n",
    "NUMERIC_FEATURES_WITH_BOUNDARIES = {\n",
    "    'open': get_numeric_boundaries(train_data['open']),\n",
    "    'close': get_numeric_boundaries(train_data['close']),\n",
    "    'high': get_numeric_boundaries(train_data['high']),\n",
    "    'low': get_numeric_boundaries(train_data['low']),\n",
    "    'volume': get_numeric_boundaries(train_data['volume']),\n",
    "    'turnover': get_numeric_boundaries(train_data['turnover']),\n",
    "    'amplitude': get_numeric_boundaries(train_data['amplitude']),\n",
    "    'change_pct': get_numeric_boundaries(train_data['change_pct']),\n",
    "    'change_amount': get_numeric_boundaries(train_data['change_amount']),\n",
    "    'turnover_rate': get_numeric_boundaries(train_data['turnover_rate'])\n",
    "}\n",
    "NUMERIC_FEATURE_NAMES = list(NUMERIC_FEATURES_WITH_BOUNDARIES.keys())\n",
    "\n",
    "# 离散特征embedding\n",
    "CATEGORICAL_FEATURES_WITH_VOCABULARY = {\n",
    "    \"industry\": sorted(list(train_data[\"industry\"].unique())),\n",
    "}\n",
    "CATEGORICAL_FEATURE_NAMES = list(CATEGORICAL_FEATURES_WITH_VOCABULARY.keys())\n",
    "\n",
    "FEATURE_NAMES = NUMERIC_FEATURE_NAMES + CATEGORICAL_FEATURE_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "  dataframe = dataframe.copy()\n",
    "  labels = dataframe.pop(TARGET_FEATURE_NAME)\n",
    "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "  ds = ds.batch(batch_size)\n",
    "  return ds\n",
    "\n",
    "train_ds = df_to_dataset(train_data)\n",
    "val_ds = df_to_dataset(test_data)\n",
    "test_ds = df_to_dataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_inputs():\n",
    "    inputs = {}\n",
    "    for feature_name in FEATURE_NAMES:\n",
    "        if feature_name in NUMERIC_FEATURE_NAMES:\n",
    "            inputs[feature_name] = tf.keras.layers.Input(\n",
    "                name=feature_name, shape=(), dtype=\"float32\"\n",
    "            )\n",
    "        else:\n",
    "            inputs[feature_name] = tf.keras.layers.Input(\n",
    "                name=feature_name, shape=(), dtype=\"string\"\n",
    "            )\n",
    "    return inputs\n",
    "\n",
    "def encode_inputs(inputs):\n",
    "    encoded_features = []\n",
    "    embedding_dim = 4\n",
    "    for feature_name in inputs:\n",
    "        if feature_name in NUMERIC_FEATURE_NAMES: # 处理连续特征\n",
    "            embedding_size = len(NUMERIC_FEATURES_WITH_BOUNDARIES[feature_name]) * 2\n",
    "            embedding = tf.keras.layers.Embedding(\n",
    "                input_dim=embedding_size, output_dim=embedding_dim\n",
    "            )\n",
    "            lookup_layer = tf.keras.layers.Discretization(bin_boundaries=NUMERIC_FEATURES_WITH_BOUNDARIES[feature_name],output_mode='int')\n",
    "            encoded_feature = embedding(lookup_layer(inputs[feature_name]))\n",
    "        elif feature_name in CATEGORICAL_FEATURE_NAMES: # 处理类别特征\n",
    "            embedding_size = len(CATEGORICAL_FEATURES_WITH_VOCABULARY[feature_name]) * 2\n",
    "            embedding = tf.keras.layers.Embedding(\n",
    "                input_dim=embedding_size, output_dim=embedding_dim\n",
    "            )\n",
    "            lookup_layer = tf.keras.layers.Hashing(num_bins=embedding_size)\n",
    "            encoded_feature = embedding(lookup_layer(inputs[feature_name]))\n",
    "        \n",
    "        # print(encoded_feature)\n",
    "        encoded_features.append(encoded_feature)\n",
    "    \n",
    "    all_features = tf.keras.layers.concatenate(encoded_features)\n",
    "    return all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 5e-3\n",
    "NUM_EPOCH = 50\n",
    "\n",
    "def run_experiment(model, train_ds, val_ds, test_ds):\n",
    "    optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=LEARNING_RATE)\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=metrics,\n",
    "    )\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_sparse_categorical_accuracy',\n",
    "        verbose=1,\n",
    "        patience=10,\n",
    "        mode='max',\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    print(\"Start training the model...\")\n",
    "    history = model.fit(\n",
    "        train_ds, \n",
    "        epochs=NUM_EPOCH, \n",
    "        validation_data=val_ds, \n",
    "        verbose=2,\n",
    "        callbacks=[early_stopping],\n",
    "        class_weight=class_weight\n",
    "    )\n",
    "    print(\"Model training finished\")\n",
    "\n",
    "    # loss, auc = model.evaluate(test_ds, verbose=0)\n",
    "    # print(f\"Test AUC::{round(auc * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_rate = 0.2\n",
    "hidden_units = [64, 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training the model...\n",
      "Epoch 1/20\n",
      "4746/4746 - 4s - loss: 1.6707 - sparse_categorical_accuracy: 0.3124 - val_loss: 1.0877 - val_sparse_categorical_accuracy: 0.3660 - 4s/epoch - 939us/step\n",
      "Epoch 2/20\n",
      "4746/4746 - 4s - loss: 1.6441 - sparse_categorical_accuracy: 0.3202 - val_loss: 1.1016 - val_sparse_categorical_accuracy: 0.2666 - 4s/epoch - 794us/step\n",
      "Epoch 3/20\n",
      "4746/4746 - 4s - loss: 1.6419 - sparse_categorical_accuracy: 0.3321 - val_loss: 1.0973 - val_sparse_categorical_accuracy: 0.3288 - 4s/epoch - 797us/step\n",
      "Epoch 4/20\n",
      "4746/4746 - 4s - loss: 1.6400 - sparse_categorical_accuracy: 0.3355 - val_loss: 1.1016 - val_sparse_categorical_accuracy: 0.2805 - 4s/epoch - 796us/step\n",
      "Epoch 5/20\n",
      "4746/4746 - 4s - loss: 1.6392 - sparse_categorical_accuracy: 0.3363 - val_loss: 1.0998 - val_sparse_categorical_accuracy: 0.2874 - 4s/epoch - 793us/step\n",
      "Epoch 6/20\n",
      "4746/4746 - 4s - loss: 1.6374 - sparse_categorical_accuracy: 0.3379 - val_loss: 1.1015 - val_sparse_categorical_accuracy: 0.2721 - 4s/epoch - 795us/step\n",
      "Epoch 7/20\n",
      "4746/4746 - 4s - loss: 1.6368 - sparse_categorical_accuracy: 0.3324 - val_loss: 1.0844 - val_sparse_categorical_accuracy: 0.3567 - 4s/epoch - 801us/step\n",
      "Epoch 8/20\n",
      "4746/4746 - 4s - loss: 1.6358 - sparse_categorical_accuracy: 0.3327 - val_loss: 1.0900 - val_sparse_categorical_accuracy: 0.3263 - 4s/epoch - 794us/step\n",
      "Epoch 9/20\n",
      "4746/4746 - 4s - loss: 1.6347 - sparse_categorical_accuracy: 0.3350 - val_loss: 1.1082 - val_sparse_categorical_accuracy: 0.2517 - 4s/epoch - 791us/step\n",
      "Epoch 10/20\n",
      "4746/4746 - 4s - loss: 1.6347 - sparse_categorical_accuracy: 0.3325 - val_loss: 1.0968 - val_sparse_categorical_accuracy: 0.2987 - 4s/epoch - 794us/step\n",
      "Epoch 11/20\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "4746/4746 - 4s - loss: 1.6332 - sparse_categorical_accuracy: 0.3312 - val_loss: 1.1031 - val_sparse_categorical_accuracy: 0.2523 - 4s/epoch - 795us/step\n",
      "Epoch 11: early stopping\n",
      "Model training finished\n"
     ]
    }
   ],
   "source": [
    "def create_baseline_model(output_bias=None):\n",
    "    inputs = create_model_inputs()\n",
    "    features = encode_inputs(inputs)\n",
    "\n",
    "    for units in hidden_units:\n",
    "        features = tf.keras.layers.Dense(units)(features)\n",
    "        features = tf.keras.layers.BatchNormalization()(features)\n",
    "        features = tf.keras.layers.ReLU()(features)\n",
    "        features = tf.keras.layers.Dropout(dropout_rate)(features)\n",
    "\n",
    "    # outputs = tf.keras.layers.Dense(units=1, activation=\"sigmoid\")(features)\n",
    "    outputs = tf.keras.layers.Dense(units=TARGET_FEATURE_LENGTH, activation=\"softmax\")(features)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "baseline_model = create_baseline_model()\n",
    "# tf.keras.utils.plot_model(baseline_model, show_shapes=True, rankdir=\"LR\")\n",
    "run_experiment(baseline_model, train_ds, val_ds, test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training the model...\n",
      "Epoch 1/20\n",
      "4746/4746 - 6s - loss: 1.6681 - sparse_categorical_accuracy: 0.3398 - val_loss: 1.1178 - val_sparse_categorical_accuracy: 0.2932 - 6s/epoch - 1ms/step\n",
      "Epoch 2/20\n",
      "4746/4746 - 5s - loss: 1.6443 - sparse_categorical_accuracy: 0.3438 - val_loss: 1.1131 - val_sparse_categorical_accuracy: 0.2723 - 5s/epoch - 955us/step\n",
      "Epoch 3/20\n",
      "4746/4746 - 5s - loss: 1.6425 - sparse_categorical_accuracy: 0.3458 - val_loss: 1.0958 - val_sparse_categorical_accuracy: 0.3335 - 5s/epoch - 965us/step\n",
      "Epoch 4/20\n",
      "4746/4746 - 5s - loss: 1.6409 - sparse_categorical_accuracy: 0.3446 - val_loss: 1.0939 - val_sparse_categorical_accuracy: 0.3311 - 5s/epoch - 958us/step\n",
      "Epoch 5/20\n",
      "4746/4746 - 5s - loss: 1.6398 - sparse_categorical_accuracy: 0.3436 - val_loss: 1.1007 - val_sparse_categorical_accuracy: 0.3138 - 5s/epoch - 968us/step\n",
      "Epoch 6/20\n",
      "4746/4746 - 5s - loss: 1.6381 - sparse_categorical_accuracy: 0.3452 - val_loss: 1.0999 - val_sparse_categorical_accuracy: 0.2998 - 5s/epoch - 964us/step\n",
      "Epoch 7/20\n",
      "4746/4746 - 5s - loss: 1.6364 - sparse_categorical_accuracy: 0.3419 - val_loss: 1.1153 - val_sparse_categorical_accuracy: 0.2637 - 5s/epoch - 982us/step\n",
      "Epoch 8/20\n",
      "4746/4746 - 5s - loss: 1.6363 - sparse_categorical_accuracy: 0.3393 - val_loss: 1.1134 - val_sparse_categorical_accuracy: 0.2625 - 5s/epoch - 964us/step\n",
      "Epoch 9/20\n",
      "4746/4746 - 5s - loss: 1.6351 - sparse_categorical_accuracy: 0.3448 - val_loss: 1.1002 - val_sparse_categorical_accuracy: 0.3118 - 5s/epoch - 954us/step\n",
      "Epoch 10/20\n",
      "4746/4746 - 5s - loss: 1.6341 - sparse_categorical_accuracy: 0.3436 - val_loss: 1.0853 - val_sparse_categorical_accuracy: 0.3626 - 5s/epoch - 962us/step\n",
      "Epoch 11/20\n",
      "4746/4746 - 5s - loss: 1.6338 - sparse_categorical_accuracy: 0.3440 - val_loss: 1.0841 - val_sparse_categorical_accuracy: 0.3405 - 5s/epoch - 978us/step\n",
      "Epoch 12/20\n",
      "4746/4746 - 5s - loss: 1.6331 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.1041 - val_sparse_categorical_accuracy: 0.3057 - 5s/epoch - 957us/step\n",
      "Epoch 13/20\n",
      "4746/4746 - 5s - loss: 1.6325 - sparse_categorical_accuracy: 0.3419 - val_loss: 1.1179 - val_sparse_categorical_accuracy: 0.2736 - 5s/epoch - 961us/step\n",
      "Epoch 14/20\n",
      "4746/4746 - 5s - loss: 1.6319 - sparse_categorical_accuracy: 0.3406 - val_loss: 1.1119 - val_sparse_categorical_accuracy: 0.2787 - 5s/epoch - 966us/step\n",
      "Epoch 15/20\n",
      "4746/4746 - 5s - loss: 1.6308 - sparse_categorical_accuracy: 0.3438 - val_loss: 1.1023 - val_sparse_categorical_accuracy: 0.3018 - 5s/epoch - 962us/step\n",
      "Epoch 16/20\n",
      "4746/4746 - 5s - loss: 1.6308 - sparse_categorical_accuracy: 0.3386 - val_loss: 1.1042 - val_sparse_categorical_accuracy: 0.2974 - 5s/epoch - 960us/step\n",
      "Epoch 17/20\n",
      "4746/4746 - 5s - loss: 1.6298 - sparse_categorical_accuracy: 0.3420 - val_loss: 1.1048 - val_sparse_categorical_accuracy: 0.2870 - 5s/epoch - 986us/step\n",
      "Epoch 18/20\n",
      "4746/4746 - 5s - loss: 1.6294 - sparse_categorical_accuracy: 0.3390 - val_loss: 1.0928 - val_sparse_categorical_accuracy: 0.3164 - 5s/epoch - 968us/step\n",
      "Epoch 19/20\n",
      "4746/4746 - 5s - loss: 1.6288 - sparse_categorical_accuracy: 0.3435 - val_loss: 1.1020 - val_sparse_categorical_accuracy: 0.2905 - 5s/epoch - 958us/step\n",
      "Epoch 20/20\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "4746/4746 - 5s - loss: 1.6283 - sparse_categorical_accuracy: 0.3405 - val_loss: 1.1034 - val_sparse_categorical_accuracy: 0.2932 - 5s/epoch - 963us/step\n",
      "Epoch 20: early stopping\n",
      "Model training finished\n"
     ]
    }
   ],
   "source": [
    "def create_wide_and_deep_model():\n",
    "    inputs = create_model_inputs()\n",
    "    wide = encode_inputs(inputs)\n",
    "    wide = tf.keras.layers.BatchNormalization()(wide)\n",
    "\n",
    "    deep = encode_inputs(inputs)\n",
    "    for units in hidden_units:\n",
    "        deep = tf.keras.layers.Dense(units)(deep)\n",
    "        deep = tf.keras.layers.BatchNormalization()(deep)\n",
    "        deep = tf.keras.layers.ReLU()(deep)\n",
    "        deep = tf.keras.layers.Dropout(dropout_rate)(deep)\n",
    "\n",
    "    merged = tf.keras.layers.concatenate([wide, deep])\n",
    "    # outputs = tf.keras.layers.Dense(units=1)(merged)\n",
    "    outputs = tf.keras.layers.Dense(units=TARGET_FEATURE_LENGTH, activation=\"softmax\")(merged)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "wide_and_deep_model = create_wide_and_deep_model()\n",
    "# keras.utils.plot_model(wide_and_deep_model, show_shapes=True, rankdir=\"LR\")\n",
    "\n",
    "run_experiment(wide_and_deep_model,train_ds, val_ds, test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./hh_quant_tf_wdl_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./hh_quant_tf_wdl_model/assets\n"
     ]
    }
   ],
   "source": [
    "wide_and_deep_model.save('./hh_quant_tf_wdl_model')\n",
    "reloaded_model = tf.keras.models.load_model('./hh_quant_tf_wdl_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = df_to_dataset(test_data.iloc[:100, :], shuffle=False, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/10 [==>...........................] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = reloaded_model.predict(samples)\n",
    "prob = tf.nn.softmax(tf.squeeze(predictions))\n",
    "\n",
    "# print(\n",
    "#     \"This particular pet had a %.4f percent probability \"\n",
    "#     \"of getting adopted.\" % (100 * prob)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 2, 1, 1, 2, 0, 0, 0, 1, 1, 1, 2, 0, 2, 1, 0, 0, 0, 1,\n",
       "       2, 0, 0, 0, 0, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 2, 1, 1, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 2, 2, 1, 2, 1, 1, 1, 1,\n",
       "       1, 2, 1, 2, 1, 1, 2, 1, 0, 1, 1, 2])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob.numpy().argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
